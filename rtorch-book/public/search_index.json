[
["logistic-regression.html", "Chapter 6 Logistic Regression 6.1 Example 1: MNIST handwritten digits", " Chapter 6 Logistic Regression library(rTorch) nn &lt;- torch$nn transforms &lt;- torchvision$transforms torch$set_default_dtype(torch$float) 6.1 Example 1: MNIST handwritten digits 6.1.1 Hyperparameters # Hyper-parameters input_size &lt;- 784L num_classes &lt;- 10L num_epochs &lt;- 5L batch_size &lt;- 100L learning_rate &lt;- 0.001 6.1.2 Read datasets # MNIST dataset (images and labels) # IDX format local_folder &lt;- &#39;../datasets/raw_data&#39; train_dataset = torchvision$datasets$MNIST(root=local_folder, train=TRUE, transform=transforms$ToTensor(), download=TRUE) test_dataset = torchvision$datasets$MNIST(root=local_folder, train=FALSE, transform=transforms$ToTensor()) # Data loader (input pipeline) train_loader = torch$utils$data$DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=TRUE) test_loader = torch$utils$data$DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=FALSE) class(train_loader) #&gt; [1] &quot;torch.utils.data.dataloader.DataLoader&quot; #&gt; [2] &quot;python.builtin.object&quot; length(train_loader) #&gt; [1] 2 6.1.3 Define the model # Logistic regression model model = nn$Linear(input_size, num_classes) # Loss and optimizer # nn.CrossEntropyLoss() computes softmax internally criterion = nn$CrossEntropyLoss() optimizer = torch$optim$SGD(model$parameters(), lr=learning_rate) print(model) #&gt; Linear(in_features=784, out_features=10, bias=True) 6.1.4 Training # Train the model iter_train_loader &lt;- iterate(train_loader) total_step &lt;-length(iter_train_loader) for (epoch in 1:num_epochs) { i &lt;- 0 for (obj in iter_train_loader) { images &lt;- obj[[1]] # tensor torch.Size([64, 3, 28, 28]) labels &lt;- obj[[2]] # tensor torch.Size([64]), labels from 0 to 9 # cat(i, &quot;\\t&quot;); print(images$shape) # Reshape images to (batch_size, input_size) images &lt;- images$reshape(-1L, 28L*28L) # images &lt;- torch$as_tensor(images$reshape(-1L, 28L*28L), dtype=torch$double) # Forward pass outputs &lt;- model(images) loss &lt;- criterion(outputs, labels) # Backward and optimize optimizer$zero_grad() loss$backward() optimizer$step() if ((i+1) %% 100 == 0) { cat(sprintf(&#39;Epoch [%d/%d], Step [%d/%d], Loss: %f \\n&#39;, epoch+1, num_epochs, i+1, total_step, loss$item())) } i &lt;- i + 1 } } #&gt; Epoch [2/5], Step [100/600], Loss: 2.235316 #&gt; Epoch [2/5], Step [200/600], Loss: 2.109781 #&gt; Epoch [2/5], Step [300/600], Loss: 2.036314 #&gt; Epoch [2/5], Step [400/600], Loss: 1.931807 #&gt; Epoch [2/5], Step [500/600], Loss: 1.868896 #&gt; Epoch [2/5], Step [600/600], Loss: 1.747006 #&gt; Epoch [3/5], Step [100/600], Loss: 1.763265 #&gt; Epoch [3/5], Step [200/600], Loss: 1.659977 #&gt; Epoch [3/5], Step [300/600], Loss: 1.627226 #&gt; Epoch [3/5], Step [400/600], Loss: 1.555589 #&gt; Epoch [3/5], Step [500/600], Loss: 1.499040 #&gt; Epoch [3/5], Step [600/600], Loss: 1.404531 #&gt; Epoch [4/5], Step [100/600], Loss: 1.464802 #&gt; Epoch [4/5], Step [200/600], Loss: 1.360672 #&gt; Epoch [4/5], Step [300/600], Loss: 1.368912 #&gt; Epoch [4/5], Step [400/600], Loss: 1.314911 #&gt; Epoch [4/5], Step [500/600], Loss: 1.259371 #&gt; Epoch [4/5], Step [600/600], Loss: 1.184559 #&gt; Epoch [5/5], Step [100/600], Loss: 1.270667 #&gt; Epoch [5/5], Step [200/600], Loss: 1.160586 #&gt; Epoch [5/5], Step [300/600], Loss: 1.197894 #&gt; Epoch [5/5], Step [400/600], Loss: 1.154198 #&gt; Epoch [5/5], Step [500/600], Loss: 1.098713 #&gt; Epoch [5/5], Step [600/600], Loss: 1.036009 #&gt; Epoch [6/5], Step [100/600], Loss: 1.138094 #&gt; Epoch [6/5], Step [200/600], Loss: 1.021111 #&gt; Epoch [6/5], Step [300/600], Loss: 1.078781 #&gt; Epoch [6/5], Step [400/600], Loss: 1.041601 #&gt; Epoch [6/5], Step [500/600], Loss: 0.985859 #&gt; Epoch [6/5], Step [600/600], Loss: 0.930320 6.1.5 Prediction # Adjust weights and reset gradients iter_test_loader &lt;- iterate(test_loader) with(torch$no_grad(), { correct &lt;- 0 total &lt;- 0 for (obj in iter_test_loader) { images &lt;- obj[[1]] # tensor torch.Size([64, 3, 28, 28]) labels &lt;- obj[[2]] # tensor torch.Size([64]), labels from 0 to 9 images = images$reshape(-1L, 28L*28L) # images &lt;- torch$as_tensor(images$reshape(-1L, 28L*28L), dtype=torch$double) outputs = model(images) .predicted = torch$max(outputs$data, 1L) predicted &lt;- .predicted[1L] total = total + labels$size(0L) correct = correct + sum((predicted$numpy() == labels$numpy())) } cat(sprintf(&#39;Accuracy of the model on the 10000 test images: %f %%&#39;, (100 * correct / total))) }) #&gt; Accuracy of the model on the 10000 test images: 83.050000 % 6.1.6 Save the model # Save the model checkpoint torch$save(model$state_dict(), &#39;model.ckpt&#39;) "]
]

<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Linear Algebra with Torch | A Minimal rTorch Tutorial</title>
  <meta name="description" content="This is a minimal tutorial of using the rTorch package to have fun while doing machine learning. This book was produced with bookdown." />
  <meta name="generator" content="bookdown 0.12 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Linear Algebra with Torch | A Minimal rTorch Tutorial" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal tutorial of using the rTorch package to have fun while doing machine learning. This book was produced with bookdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Linear Algebra with Torch | A Minimal rTorch Tutorial" />
  
  <meta name="twitter:description" content="This is a minimal tutorial of using the rTorch package to have fun while doing machine learning. This book was produced with bookdown." />
  

<meta name="author" content="Alfonso R. Reyes" />


<meta name="date" content="2019-08-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="tensors.html">
<link rel="next" href="linear-regression.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal rTorch Tutorial</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#installation"><i class="fa fa-check"></i><b>2.1</b> Installation</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#matrices-and-linear-algebra"><i class="fa fa-check"></i><b>2.2</b> Matrices and Linear Algebra</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="lessons-learned.html"><a href="lessons-learned.html"><i class="fa fa-check"></i><b>3</b> Lessons Learned</a><ul>
<li class="chapter" data-level="3.1" data-path="lessons-learned.html"><a href="lessons-learned.html#enumeration"><i class="fa fa-check"></i><b>3.1</b> Enumeration</a></li>
<li class="chapter" data-level="3.2" data-path="lessons-learned.html"><a href="lessons-learned.html#how-to-iterate-a-generator"><i class="fa fa-check"></i><b>3.2</b> How to iterate a generator</a><ul>
<li class="chapter" data-level="3.2.1" data-path="lessons-learned.html"><a href="lessons-learned.html#using-enumerate-and-iterate"><i class="fa fa-check"></i><b>3.2.1</b> Using <code>enumerate</code> and <code>iterate</code></a></li>
<li class="chapter" data-level="3.2.2" data-path="lessons-learned.html"><a href="lessons-learned.html#using-a-for-loop"><i class="fa fa-check"></i><b>3.2.2</b> Using a <code>for-loop</code></a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="lessons-learned.html"><a href="lessons-learned.html#zero-gradient"><i class="fa fa-check"></i><b>3.3</b> Zero gradient</a></li>
<li class="chapter" data-level="3.4" data-path="lessons-learned.html"><a href="lessons-learned.html#transform-a-tensor"><i class="fa fa-check"></i><b>3.4</b> Transform a tensor</a></li>
<li class="chapter" data-level="3.5" data-path="lessons-learned.html"><a href="lessons-learned.html#build-a-model-class"><i class="fa fa-check"></i><b>3.5</b> Build a model class</a></li>
<li class="chapter" data-level="3.6" data-path="lessons-learned.html"><a href="lessons-learned.html#convert-a-tensor-to-numpy-object"><i class="fa fa-check"></i><b>3.6</b> Convert a tensor to numpy object</a></li>
<li class="chapter" data-level="3.7" data-path="lessons-learned.html"><a href="lessons-learned.html#convert-a-numpy-object-to-an-r-object"><i class="fa fa-check"></i><b>3.7</b> Convert a numpy object to an R object</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="tensors.html"><a href="tensors.html"><i class="fa fa-check"></i><b>4</b> Tensors</a><ul>
<li class="chapter" data-level="4.1" data-path="tensors.html"><a href="tensors.html#r-code"><i class="fa fa-check"></i><b>4.1</b> R code</a><ul>
<li class="chapter" data-level="4.1.1" data-path="tensors.html"><a href="tensors.html#load-the-libraries"><i class="fa fa-check"></i><b>4.1.1</b> Load the libraries</a></li>
<li class="chapter" data-level="4.1.2" data-path="tensors.html"><a href="tensors.html#datasets"><i class="fa fa-check"></i><b>4.1.2</b> Datasets</a></li>
<li class="chapter" data-level="4.1.3" data-path="tensors.html"><a href="tensors.html#run-the-model"><i class="fa fa-check"></i><b>4.1.3</b> Run the model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="linear-algebra.html"><a href="linear-algebra.html"><i class="fa fa-check"></i><b>5</b> Linear Algebra with Torch</a><ul>
<li class="chapter" data-level="5.1" data-path="linear-algebra.html"><a href="linear-algebra.html#scalars"><i class="fa fa-check"></i><b>5.1</b> Scalars</a></li>
<li class="chapter" data-level="5.2" data-path="linear-algebra.html"><a href="linear-algebra.html#vectors"><i class="fa fa-check"></i><b>5.2</b> Vectors</a></li>
<li class="chapter" data-level="5.3" data-path="linear-algebra.html"><a href="linear-algebra.html#matrices"><i class="fa fa-check"></i><b>5.3</b> Matrices</a></li>
<li class="chapter" data-level="5.4" data-path="linear-algebra.html"><a href="linear-algebra.html#d-tensors"><i class="fa fa-check"></i><b>5.4</b> 3D+ tensors</a></li>
<li class="chapter" data-level="5.5" data-path="linear-algebra.html"><a href="linear-algebra.html#transpose-of-a-matrix"><i class="fa fa-check"></i><b>5.5</b> Transpose of a matrix</a></li>
<li class="chapter" data-level="5.6" data-path="linear-algebra.html"><a href="linear-algebra.html#vectors-special-case-of-a-matrix"><i class="fa fa-check"></i><b>5.6</b> Vectors, special case of a matrix</a></li>
<li class="chapter" data-level="5.7" data-path="linear-algebra.html"><a href="linear-algebra.html#tensor-addition"><i class="fa fa-check"></i><b>5.7</b> Tensor addition</a></li>
<li class="chapter" data-level="5.8" data-path="linear-algebra.html"><a href="linear-algebra.html#add-a-scalar-to-a-tensor"><i class="fa fa-check"></i><b>5.8</b> Add a scalar to a tensor</a></li>
<li class="chapter" data-level="5.9" data-path="linear-algebra.html"><a href="linear-algebra.html#multiplying-tensors"><i class="fa fa-check"></i><b>5.9</b> Multiplying tensors</a></li>
<li class="chapter" data-level="5.10" data-path="linear-algebra.html"><a href="linear-algebra.html#dot-product"><i class="fa fa-check"></i><b>5.10</b> Dot product</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>6</b> Linear Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="linear-regression.html"><a href="linear-regression.html#case-1-simple-linear-regression"><i class="fa fa-check"></i><b>6.1</b> Case 1: simple linear regression</a></li>
<li class="chapter" data-level="6.2" data-path="linear-regression.html"><a href="linear-regression.html#creating-the-network-model"><i class="fa fa-check"></i><b>6.2</b> Creating the network model</a></li>
<li class="chapter" data-level="6.3" data-path="linear-regression.html"><a href="linear-regression.html#datasets-1"><i class="fa fa-check"></i><b>6.3</b> Datasets</a><ul>
<li class="chapter" data-level="6.3.1" data-path="linear-regression.html"><a href="linear-regression.html#converting-from-numpy-to-tensor"><i class="fa fa-check"></i><b>6.3.1</b> Converting from numpy to tensor</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="linear-regression.html"><a href="linear-regression.html#optimizer-and-loss"><i class="fa fa-check"></i><b>6.4</b> Optimizer and Loss</a></li>
<li class="chapter" data-level="6.5" data-path="linear-regression.html"><a href="linear-regression.html#training"><i class="fa fa-check"></i><b>6.5</b> Training</a></li>
<li class="chapter" data-level="6.6" data-path="linear-regression.html"><a href="linear-regression.html#result"><i class="fa fa-check"></i><b>6.6</b> Result</a></li>
<li class="chapter" data-level="6.7" data-path="linear-regression.html"><a href="linear-regression.html#case-2-rainfall"><i class="fa fa-check"></i><b>6.7</b> Case 2: Rainfall</a></li>
<li class="chapter" data-level="6.8" data-path="linear-regression.html"><a href="linear-regression.html#select-device"><i class="fa fa-check"></i><b>6.8</b> Select device</a></li>
<li class="chapter" data-level="6.9" data-path="linear-regression.html"><a href="linear-regression.html#training-data"><i class="fa fa-check"></i><b>6.9</b> Training data</a></li>
<li class="chapter" data-level="6.10" data-path="linear-regression.html"><a href="linear-regression.html#convert-to-tensors"><i class="fa fa-check"></i><b>6.10</b> Convert to tensors</a></li>
<li class="chapter" data-level="6.11" data-path="linear-regression.html"><a href="linear-regression.html#build-the-model"><i class="fa fa-check"></i><b>6.11</b> Build the model</a></li>
<li class="chapter" data-level="6.12" data-path="linear-regression.html"><a href="linear-regression.html#generate-predictions"><i class="fa fa-check"></i><b>6.12</b> Generate predictions</a></li>
<li class="chapter" data-level="6.13" data-path="linear-regression.html"><a href="linear-regression.html#loss-function"><i class="fa fa-check"></i><b>6.13</b> Loss Function</a></li>
<li class="chapter" data-level="6.14" data-path="linear-regression.html"><a href="linear-regression.html#compute-gradients"><i class="fa fa-check"></i><b>6.14</b> Compute Gradients</a></li>
<li class="chapter" data-level="6.15" data-path="linear-regression.html"><a href="linear-regression.html#adjust-weights-and-biases-using-gradient-descent"><i class="fa fa-check"></i><b>6.15</b> Adjust weights and biases using gradient descent</a></li>
<li class="chapter" data-level="6.16" data-path="linear-regression.html"><a href="linear-regression.html#train-for-multiple-epochs"><i class="fa fa-check"></i><b>6.16</b> Train for multiple epochs</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>7</b> Logistic Regression</a><ul>
<li class="chapter" data-level="7.0.1" data-path="logistic-regression.html"><a href="logistic-regression.html#hyperparameters"><i class="fa fa-check"></i><b>7.0.1</b> Hyperparameters</a></li>
<li class="chapter" data-level="7.0.2" data-path="logistic-regression.html"><a href="logistic-regression.html#read-datasets"><i class="fa fa-check"></i><b>7.0.2</b> Read datasets</a></li>
<li class="chapter" data-level="7.0.3" data-path="logistic-regression.html"><a href="logistic-regression.html#define-the-model"><i class="fa fa-check"></i><b>7.0.3</b> Define the model</a></li>
<li class="chapter" data-level="7.0.4" data-path="logistic-regression.html"><a href="logistic-regression.html#training-1"><i class="fa fa-check"></i><b>7.0.4</b> Training</a></li>
<li class="chapter" data-level="7.0.5" data-path="logistic-regression.html"><a href="logistic-regression.html#prediction"><i class="fa fa-check"></i><b>7.0.5</b> Prediction</a></li>
<li class="chapter" data-level="7.0.6" data-path="logistic-regression.html"><a href="logistic-regression.html#save-the-model"><i class="fa fa-check"></i><b>7.0.6</b> Save the model</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>8</b> Neural Networks</a><ul>
<li class="chapter" data-level="8.1" data-path="neural-networks.html"><a href="neural-networks.html#in-r"><i class="fa fa-check"></i><b>8.1</b> In R</a><ul>
<li class="chapter" data-level="8.1.1" data-path="neural-networks.html"><a href="neural-networks.html#select-device-1"><i class="fa fa-check"></i><b>8.1.1</b> Select device</a></li>
<li class="chapter" data-level="8.1.2" data-path="neural-networks.html"><a href="neural-networks.html#create-datasets"><i class="fa fa-check"></i><b>8.1.2</b> Create datasets</a></li>
<li class="chapter" data-level="8.1.3" data-path="neural-networks.html"><a href="neural-networks.html#define-the-model-1"><i class="fa fa-check"></i><b>8.1.3</b> Define the model</a></li>
<li class="chapter" data-level="8.1.4" data-path="neural-networks.html"><a href="neural-networks.html#loss-function-1"><i class="fa fa-check"></i><b>8.1.4</b> Loss function</a></li>
<li class="chapter" data-level="8.1.5" data-path="neural-networks.html"><a href="neural-networks.html#iterate-through-batches"><i class="fa fa-check"></i><b>8.1.5</b> Iterate through batches</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="datasets-in-pytorch.html"><a href="datasets-in-pytorch.html"><i class="fa fa-check"></i><b>9</b> Datasets in PyTorch</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Minimal rTorch Tutorial</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear_algebra" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Linear Algebra with Torch</h1>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb43-1" data-line-number="1"><span class="kw">library</span>(rTorch)</a></code></pre></div>
<div id="scalars" class="section level2">
<h2><span class="header-section-number">5.1</span> Scalars</h2>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" data-line-number="1">torch<span class="op">$</span><span class="kw">scalar_tensor</span>(<span class="fl">2.78654</span>)</a></code></pre></div>
<pre><code>## tensor(2.7865)</code></pre>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" data-line-number="1">torch<span class="op">$</span><span class="kw">scalar_tensor</span>(0L)</a></code></pre></div>
<pre><code>## tensor(0.)</code></pre>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" data-line-number="1">torch<span class="op">$</span><span class="kw">scalar_tensor</span>(1L)</a></code></pre></div>
<pre><code>## tensor(1.)</code></pre>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb50-1" data-line-number="1">torch<span class="op">$</span><span class="kw">scalar_tensor</span>(<span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## tensor(1.)</code></pre>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" data-line-number="1">torch<span class="op">$</span><span class="kw">scalar_tensor</span>(<span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## tensor(0.)</code></pre>
</div>
<div id="vectors" class="section level2">
<h2><span class="header-section-number">5.2</span> Vectors</h2>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" data-line-number="1">v &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb54-2" data-line-number="2">torch<span class="op">$</span><span class="kw">as_tensor</span>(v)</a></code></pre></div>
<pre><code>## tensor([0., 1., 2., 3., 4., 5.])</code></pre>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" data-line-number="1"><span class="co"># row-vector</span></a>
<a class="sourceLine" id="cb56-2" data-line-number="2">(mr &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">nrow=</span><span class="dv">1</span>))</a></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
## [1,]    1    2    3    4    5    6    7    8    9    10</code></pre>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb58-1" data-line-number="1">torch<span class="op">$</span><span class="kw">as_tensor</span>(mr)</a></code></pre></div>
<pre><code>## tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]], dtype=torch.int32)</code></pre>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb60-1" data-line-number="1">torch<span class="op">$</span><span class="kw">as_tensor</span>(mr)<span class="op">$</span>shape</a></code></pre></div>
<pre><code>## torch.Size([1, 10])</code></pre>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb62-1" data-line-number="1"><span class="co"># column-vector</span></a>
<a class="sourceLine" id="cb62-2" data-line-number="2">(mc &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">ncol=</span><span class="dv">1</span>))</a></code></pre></div>
<pre><code>##       [,1]
##  [1,]    1
##  [2,]    2
##  [3,]    3
##  [4,]    4
##  [5,]    5
##  [6,]    6
##  [7,]    7
##  [8,]    8
##  [9,]    9
## [10,]   10</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb64-1" data-line-number="1">torch<span class="op">$</span><span class="kw">as_tensor</span>(mc)</a></code></pre></div>
<pre><code>## tensor([[ 1],
##         [ 2],
##         [ 3],
##         [ 4],
##         [ 5],
##         [ 6],
##         [ 7],
##         [ 8],
##         [ 9],
##         [10]], dtype=torch.int32)</code></pre>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb66-1" data-line-number="1">torch<span class="op">$</span><span class="kw">as_tensor</span>(mc)<span class="op">$</span>shape</a></code></pre></div>
<pre><code>## torch.Size([10, 1])</code></pre>
</div>
<div id="matrices" class="section level2">
<h2><span class="header-section-number">5.3</span> Matrices</h2>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb68-1" data-line-number="1">(m1 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">24</span>, <span class="dt">nrow =</span> <span class="dv">3</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>))</a></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
## [1,]    1    2    3    4    5    6    7    8
## [2,]    9   10   11   12   13   14   15   16
## [3,]   17   18   19   20   21   22   23   24</code></pre>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb70-1" data-line-number="1">(t1 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(m1))</a></code></pre></div>
<pre><code>## tensor([[ 1,  2,  3,  4,  5,  6,  7,  8],
##         [ 9, 10, 11, 12, 13, 14, 15, 16],
##         [17, 18, 19, 20, 21, 22, 23, 24]], dtype=torch.int32)</code></pre>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb72-1" data-line-number="1">torch<span class="op">$</span><span class="kw">as_tensor</span>(m1)<span class="op">$</span>shape</a></code></pre></div>
<pre><code>## torch.Size([3, 8])</code></pre>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb74-1" data-line-number="1">torch<span class="op">$</span><span class="kw">as_tensor</span>(m1)<span class="op">$</span><span class="kw">size</span>()</a></code></pre></div>
<pre><code>## torch.Size([3, 8])</code></pre>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb76-1" data-line-number="1"><span class="kw">dim</span>(torch<span class="op">$</span><span class="kw">as_tensor</span>(m1))</a></code></pre></div>
<pre><code>## [1] 3 8</code></pre>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" data-line-number="1"><span class="kw">length</span>(torch<span class="op">$</span><span class="kw">as_tensor</span>(m1))</a></code></pre></div>
<pre><code>## [1] 24</code></pre>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" data-line-number="1">(m2 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">99</span>, <span class="dt">ncol =</span> <span class="dv">10</span>))</a></code></pre></div>
<pre><code>##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
##  [1,]    0   10   20   30   40   50   60   70   80    90
##  [2,]    1   11   21   31   41   51   61   71   81    91
##  [3,]    2   12   22   32   42   52   62   72   82    92
##  [4,]    3   13   23   33   43   53   63   73   83    93
##  [5,]    4   14   24   34   44   54   64   74   84    94
##  [6,]    5   15   25   35   45   55   65   75   85    95
##  [7,]    6   16   26   36   46   56   66   76   86    96
##  [8,]    7   17   27   37   47   57   67   77   87    97
##  [9,]    8   18   28   38   48   58   68   78   88    98
## [10,]    9   19   29   39   49   59   69   79   89    99</code></pre>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" data-line-number="1">(t2 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(m2))</a></code></pre></div>
<pre><code>## tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90],
##         [ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91],
##         [ 2, 12, 22, 32, 42, 52, 62, 72, 82, 92],
##         [ 3, 13, 23, 33, 43, 53, 63, 73, 83, 93],
##         [ 4, 14, 24, 34, 44, 54, 64, 74, 84, 94],
##         [ 5, 15, 25, 35, 45, 55, 65, 75, 85, 95],
##         [ 6, 16, 26, 36, 46, 56, 66, 76, 86, 96],
##         [ 7, 17, 27, 37, 47, 57, 67, 77, 87, 97],
##         [ 8, 18, 28, 38, 48, 58, 68, 78, 88, 98],
##         [ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]], dtype=torch.int32)</code></pre>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" data-line-number="1">t2<span class="op">$</span>shape</a></code></pre></div>
<pre><code>## torch.Size([10, 10])</code></pre>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" data-line-number="1"><span class="kw">dim</span>(torch<span class="op">$</span><span class="kw">as_tensor</span>(m2))</a></code></pre></div>
<pre><code>## [1] 10 10</code></pre>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb88-1" data-line-number="1">m1[<span class="dv">1</span>, <span class="dv">1</span>]</a></code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb90-1" data-line-number="1">m2[<span class="dv">1</span>, <span class="dv">1</span>]</a></code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb92-1" data-line-number="1">t1[<span class="dv">1</span>, <span class="dv">1</span>]</a></code></pre></div>
<pre><code>## tensor(1, dtype=torch.int32)</code></pre>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb94-1" data-line-number="1">t2[<span class="dv">1</span>, <span class="dv">1</span>]</a></code></pre></div>
<pre><code>## tensor(0, dtype=torch.int32)</code></pre>
</div>
<div id="d-tensors" class="section level2">
<h2><span class="header-section-number">5.4</span> 3D+ tensors</h2>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb96-1" data-line-number="1"><span class="co"># RGB color image has three axes </span></a>
<a class="sourceLine" id="cb96-2" data-line-number="2">(img &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">rand</span>(3L, 28L, 28L))</a></code></pre></div>
<pre><code>## tensor([[[0.5548, 0.9973, 0.6722,  ..., 0.4775, 0.6007, 0.4875],
##          [0.1537, 0.6212, 0.6013,  ..., 0.2184, 0.3347, 0.5631],
##          [0.0460, 0.1544, 0.4286,  ..., 0.9303, 0.4223, 0.5124],
##          ...,
##          [0.9737, 0.0102, 0.8282,  ..., 0.5079, 0.3078, 0.0924],
##          [0.3454, 0.9608, 0.2808,  ..., 0.2469, 0.3147, 0.4546],
##          [0.3443, 0.8095, 0.7795,  ..., 0.5723, 0.8290, 0.3287]],
## 
##         [[0.6399, 0.2090, 0.0342,  ..., 0.3827, 0.3678, 0.9032],
##          [0.5105, 0.7987, 0.6801,  ..., 0.3994, 0.0647, 0.3114],
##          [0.3356, 0.4653, 0.1321,  ..., 0.3684, 0.5010, 0.4759],
##          ...,
##          [0.0171, 0.2603, 0.7928,  ..., 0.6749, 0.5378, 0.5613],
##          [0.7369, 0.1967, 0.8680,  ..., 0.1407, 0.8730, 0.0515],
##          [0.2829, 0.9587, 0.6520,  ..., 0.0570, 0.3087, 0.0332]],
## 
##         [[0.4107, 0.7514, 0.7483,  ..., 0.5357, 0.1396, 0.1590],
##          [0.0334, 0.1690, 0.8897,  ..., 0.2856, 0.0397, 0.6905],
##          [0.9382, 0.2469, 0.5983,  ..., 0.2219, 0.5791, 0.4991],
##          ...,
##          [0.4591, 0.3552, 0.2316,  ..., 0.0053, 0.4699, 0.0691],
##          [0.0557, 0.5610, 0.8311,  ..., 0.9081, 0.7571, 0.6281],
##          [0.3794, 0.2286, 0.5723,  ..., 0.6046, 0.7877, 0.6717]]])</code></pre>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb98-1" data-line-number="1">img<span class="op">$</span>shape</a></code></pre></div>
<pre><code>## torch.Size([3, 28, 28])</code></pre>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb100-1" data-line-number="1">img[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]</a></code></pre></div>
<pre><code>## tensor(0.5548)</code></pre>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb102-1" data-line-number="1">img[<span class="dv">3</span>, <span class="dv">28</span>, <span class="dv">28</span>]</a></code></pre></div>
<pre><code>## tensor(0.6717)</code></pre>
</div>
<div id="transpose-of-a-matrix" class="section level2">
<h2><span class="header-section-number">5.5</span> Transpose of a matrix</h2>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb104-1" data-line-number="1">(m3 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">25</span>, <span class="dt">ncol =</span> <span class="dv">5</span>))</a></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    6   11   16   21
## [2,]    2    7   12   17   22
## [3,]    3    8   13   18   23
## [4,]    4    9   14   19   24
## [5,]    5   10   15   20   25</code></pre>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb106-1" data-line-number="1"><span class="co"># transpose</span></a>
<a class="sourceLine" id="cb106-2" data-line-number="2">tm3 &lt;-<span class="st"> </span><span class="kw">t</span>(m3)</a>
<a class="sourceLine" id="cb106-3" data-line-number="3">tm3</a></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    2    3    4    5
## [2,]    6    7    8    9   10
## [3,]   11   12   13   14   15
## [4,]   16   17   18   19   20
## [5,]   21   22   23   24   25</code></pre>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb108-1" data-line-number="1">(t3 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(m3))</a></code></pre></div>
<pre><code>## tensor([[ 1,  6, 11, 16, 21],
##         [ 2,  7, 12, 17, 22],
##         [ 3,  8, 13, 18, 23],
##         [ 4,  9, 14, 19, 24],
##         [ 5, 10, 15, 20, 25]], dtype=torch.int32)</code></pre>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb110-1" data-line-number="1">tt3 &lt;-<span class="st"> </span>t3<span class="op">$</span><span class="kw">transpose</span>(<span class="dt">dim0 =</span> 0L, <span class="dt">dim1 =</span> 1L)</a>
<a class="sourceLine" id="cb110-2" data-line-number="2">tt3</a></code></pre></div>
<pre><code>## tensor([[ 1,  2,  3,  4,  5],
##         [ 6,  7,  8,  9, 10],
##         [11, 12, 13, 14, 15],
##         [16, 17, 18, 19, 20],
##         [21, 22, 23, 24, 25]], dtype=torch.int32)</code></pre>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb112-1" data-line-number="1">tm3 <span class="op">==</span><span class="st"> </span>tt3<span class="op">$</span><span class="kw">numpy</span>()   <span class="co"># convert first the tensor to numpy</span></a></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4] [,5]
## [1,] TRUE TRUE TRUE TRUE TRUE
## [2,] TRUE TRUE TRUE TRUE TRUE
## [3,] TRUE TRUE TRUE TRUE TRUE
## [4,] TRUE TRUE TRUE TRUE TRUE
## [5,] TRUE TRUE TRUE TRUE TRUE</code></pre>
</div>
<div id="vectors-special-case-of-a-matrix" class="section level2">
<h2><span class="header-section-number">5.6</span> Vectors, special case of a matrix</h2>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb114-1" data-line-number="1">m2 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">99</span>, <span class="dt">ncol =</span> <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb114-2" data-line-number="2">(t2 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(m2))</a></code></pre></div>
<pre><code>## tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90],
##         [ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91],
##         [ 2, 12, 22, 32, 42, 52, 62, 72, 82, 92],
##         [ 3, 13, 23, 33, 43, 53, 63, 73, 83, 93],
##         [ 4, 14, 24, 34, 44, 54, 64, 74, 84, 94],
##         [ 5, 15, 25, 35, 45, 55, 65, 75, 85, 95],
##         [ 6, 16, 26, 36, 46, 56, 66, 76, 86, 96],
##         [ 7, 17, 27, 37, 47, 57, 67, 77, 87, 97],
##         [ 8, 18, 28, 38, 48, 58, 68, 78, 88, 98],
##         [ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]], dtype=torch.int32)</code></pre>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb116-1" data-line-number="1"><span class="co"># in R</span></a>
<a class="sourceLine" id="cb116-2" data-line-number="2">(v1 &lt;-<span class="st"> </span>m2[, <span class="dv">1</span>])</a></code></pre></div>
<pre><code>##  [1] 0 1 2 3 4 5 6 7 8 9</code></pre>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb118-1" data-line-number="1">(v2 &lt;-<span class="st"> </span>m2[<span class="dv">10</span>, ])</a></code></pre></div>
<pre><code>##  [1]  9 19 29 39 49 59 69 79 89 99</code></pre>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb120-1" data-line-number="1"><span class="co"># PyTorch</span></a>
<a class="sourceLine" id="cb120-2" data-line-number="2"></a>
<a class="sourceLine" id="cb120-3" data-line-number="3">t2c &lt;-<span class="st"> </span>t2[, <span class="dv">1</span>]</a>
<a class="sourceLine" id="cb120-4" data-line-number="4">t2r &lt;-<span class="st"> </span>t2[<span class="dv">10</span>, ]</a>
<a class="sourceLine" id="cb120-5" data-line-number="5"></a>
<a class="sourceLine" id="cb120-6" data-line-number="6">t2c</a></code></pre></div>
<pre><code>## tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32)</code></pre>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb122-1" data-line-number="1">t2r</a></code></pre></div>
<pre><code>## tensor([ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99], dtype=torch.int32)</code></pre>
<p>In vectors, the vector and its transpose are equal.</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb124-1" data-line-number="1">tt2r &lt;-<span class="st"> </span>t2r<span class="op">$</span><span class="kw">transpose</span>(<span class="dt">dim0 =</span> 0L, <span class="dt">dim1 =</span> 0L)</a>
<a class="sourceLine" id="cb124-2" data-line-number="2">tt2r</a></code></pre></div>
<pre><code>## tensor([ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99], dtype=torch.int32)</code></pre>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb126-1" data-line-number="1"><span class="co"># a tensor of booleans. is vector equal to its transposed?</span></a>
<a class="sourceLine" id="cb126-2" data-line-number="2">t2r <span class="op">==</span><span class="st"> </span>tt2r</a></code></pre></div>
<pre><code>## tensor([True, True, True, True, True, True, True, True, True, True],
##        dtype=torch.bool)</code></pre>
</div>
<div id="tensor-addition" class="section level2">
<h2><span class="header-section-number">5.7</span> Tensor addition</h2>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb128-1" data-line-number="1">(<span class="dt">x =</span> torch<span class="op">$</span><span class="kw">ones</span>(5L, 4L))</a></code></pre></div>
<pre><code>## tensor([[1., 1., 1., 1.],
##         [1., 1., 1., 1.],
##         [1., 1., 1., 1.],
##         [1., 1., 1., 1.],
##         [1., 1., 1., 1.]])</code></pre>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb130-1" data-line-number="1">(<span class="dt">y =</span> torch<span class="op">$</span><span class="kw">ones</span>(5L, 4L))</a></code></pre></div>
<pre><code>## tensor([[1., 1., 1., 1.],
##         [1., 1., 1., 1.],
##         [1., 1., 1., 1.],
##         [1., 1., 1., 1.],
##         [1., 1., 1., 1.]])</code></pre>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb132-1" data-line-number="1">x <span class="op">+</span><span class="st"> </span>y</a></code></pre></div>
<pre><code>## tensor([[2., 2., 2., 2.],
##         [2., 2., 2., 2.],
##         [2., 2., 2., 2.],
##         [2., 2., 2., 2.],
##         [2., 2., 2., 2.]])</code></pre>
<p><span class="math display">\[A + B = B + A\]</span></p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb134-1" data-line-number="1">x <span class="op">+</span><span class="st"> </span>y <span class="op">==</span><span class="st"> </span>y <span class="op">+</span><span class="st"> </span>x</a></code></pre></div>
<pre><code>## tensor([[True, True, True, True],
##         [True, True, True, True],
##         [True, True, True, True],
##         [True, True, True, True],
##         [True, True, True, True]], dtype=torch.bool)</code></pre>
</div>
<div id="add-a-scalar-to-a-tensor" class="section level2">
<h2><span class="header-section-number">5.8</span> Add a scalar to a tensor</h2>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb136-1" data-line-number="1">s &lt;-<span class="st"> </span><span class="fl">0.5</span>    <span class="co"># scalar</span></a>
<a class="sourceLine" id="cb136-2" data-line-number="2">x <span class="op">+</span><span class="st"> </span>s</a></code></pre></div>
<pre><code>## tensor([[1.5000, 1.5000, 1.5000, 1.5000],
##         [1.5000, 1.5000, 1.5000, 1.5000],
##         [1.5000, 1.5000, 1.5000, 1.5000],
##         [1.5000, 1.5000, 1.5000, 1.5000],
##         [1.5000, 1.5000, 1.5000, 1.5000]])</code></pre>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb138-1" data-line-number="1"><span class="co"># scalar multiplying two tensors</span></a>
<a class="sourceLine" id="cb138-2" data-line-number="2">s <span class="op">*</span><span class="st"> </span>(x <span class="op">+</span><span class="st"> </span>y)</a></code></pre></div>
<pre><code>## tensor([[1., 1., 1., 1.],
##         [1., 1., 1., 1.],
##         [1., 1., 1., 1.],
##         [1., 1., 1., 1.],
##         [1., 1., 1., 1.]])</code></pre>
</div>
<div id="multiplying-tensors" class="section level2">
<h2><span class="header-section-number">5.9</span> Multiplying tensors</h2>
<p><span class="math display">\[A * B = B * A\]</span></p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb140-1" data-line-number="1">(<span class="dt">x =</span> torch<span class="op">$</span><span class="kw">ones</span>(5L, 4L))</a></code></pre></div>
<pre><code>## tensor([[1., 1., 1., 1.],
##         [1., 1., 1., 1.],
##         [1., 1., 1., 1.],
##         [1., 1., 1., 1.],
##         [1., 1., 1., 1.]])</code></pre>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb142-1" data-line-number="1">(<span class="dt">y =</span> torch<span class="op">$</span><span class="kw">ones</span>(5L, 4L))</a></code></pre></div>
<pre><code>## tensor([[1., 1., 1., 1.],
##         [1., 1., 1., 1.],
##         [1., 1., 1., 1.],
##         [1., 1., 1., 1.],
##         [1., 1., 1., 1.]])</code></pre>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb144-1" data-line-number="1">(<span class="dt">z =</span> <span class="dv">2</span> <span class="op">*</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span><span class="dv">4</span> <span class="op">*</span><span class="st"> </span>y)</a></code></pre></div>
<pre><code>## tensor([[6., 6., 6., 6.],
##         [6., 6., 6., 6.],
##         [6., 6., 6., 6.],
##         [6., 6., 6., 6.],
##         [6., 6., 6., 6.]])</code></pre>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb146-1" data-line-number="1">x <span class="op">*</span><span class="st"> </span>y <span class="op">==</span><span class="st"> </span>y <span class="op">*</span><span class="st"> </span>x</a></code></pre></div>
<pre><code>## tensor([[True, True, True, True],
##         [True, True, True, True],
##         [True, True, True, True],
##         [True, True, True, True],
##         [True, True, True, True]], dtype=torch.bool)</code></pre>
</div>
<div id="dot-product" class="section level2">
<h2><span class="header-section-number">5.10</span> Dot product</h2>
<p><span class="math display">\[dot(a,b)_{i,j,k,a,b,c} = \sum_m a_{i,j,k,m}b_{a,b,m,c}\]</span></p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb148-1" data-line-number="1">torch<span class="op">$</span><span class="kw">dot</span>(torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)), torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>)))</a></code></pre></div>
<pre><code>## tensor(7.)</code></pre>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb150-1" data-line-number="1">a &lt;-<span class="st"> </span>np<span class="op">$</span><span class="kw">array</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">list</span>(<span class="dv">3</span>, <span class="dv">4</span>)))</a>
<a class="sourceLine" id="cb150-2" data-line-number="2">a</a></code></pre></div>
<pre><code>##      [,1] [,2]
## [1,]    1    2
## [2,]    3    4</code></pre>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb152-1" data-line-number="1">b &lt;-<span class="st"> </span>np<span class="op">$</span><span class="kw">array</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">list</span>(<span class="dv">3</span>, <span class="dv">4</span>)))</a>
<a class="sourceLine" id="cb152-2" data-line-number="2">b</a></code></pre></div>
<pre><code>##      [,1] [,2]
## [1,]    1    2
## [2,]    3    4</code></pre>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb154-1" data-line-number="1">np<span class="op">$</span><span class="kw">dot</span>(a, b)</a></code></pre></div>
<pre><code>##      [,1] [,2]
## [1,]    7   10
## [2,]   15   22</code></pre>
<p><code>torch.dot()</code> treats both a and b as 1D vectors (irrespective of their original shape) and computes their inner product.</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb156-1" data-line-number="1">at &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(a)</a>
<a class="sourceLine" id="cb156-2" data-line-number="2">bt &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(b)</a>
<a class="sourceLine" id="cb156-3" data-line-number="3"></a>
<a class="sourceLine" id="cb156-4" data-line-number="4">torch<span class="op">$</span><span class="kw">dot</span>(at, bt)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: dot: Expected 1-D argument self, but got 2-D</code></pre>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb158-1" data-line-number="1"><span class="co"># at %.*% bt</span></a></code></pre></div>
<p>If we perform the same dot product operation in Python, we get the same error:</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb159-1" data-line-number="1"><span class="im">import</span> torch</a>
<a class="sourceLine" id="cb159-2" data-line-number="2"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb159-3" data-line-number="3"></a>
<a class="sourceLine" id="cb159-4" data-line-number="4">a <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>]])</a>
<a class="sourceLine" id="cb159-5" data-line-number="5">a</a></code></pre></div>
<pre><code>## array([[1, 2],
##        [3, 4]])</code></pre>
<div class="sourceCode" id="cb161"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb161-1" data-line-number="1">b <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>]])</a>
<a class="sourceLine" id="cb161-2" data-line-number="2">b</a></code></pre></div>
<pre><code>## array([[1, 2],
##        [3, 4]])</code></pre>
<div class="sourceCode" id="cb163"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb163-1" data-line-number="1">np.dot(a, b)</a></code></pre></div>
<pre><code>## array([[ 7, 10],
##        [15, 22]])</code></pre>
<div class="sourceCode" id="cb165"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb165-1" data-line-number="1">at <span class="op">=</span> torch.as_tensor(a)</a>
<a class="sourceLine" id="cb165-2" data-line-number="2">bt <span class="op">=</span> torch.as_tensor(b)</a>
<a class="sourceLine" id="cb165-3" data-line-number="3"></a>
<a class="sourceLine" id="cb165-4" data-line-number="4">at</a></code></pre></div>
<pre><code>## tensor([[1, 2],
##         [3, 4]])</code></pre>
<div class="sourceCode" id="cb167"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb167-1" data-line-number="1">bt</a></code></pre></div>
<pre><code>## tensor([[1, 2],
##         [3, 4]])</code></pre>
<div class="sourceCode" id="cb169"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb169-1" data-line-number="1">torch.dot(at, bt)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: dot: Expected 1-D argument self, but got 2-D
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</code></pre>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb171-1" data-line-number="1">a &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">list</span>(<span class="dv">3</span>, <span class="dv">4</span>)))</a>
<a class="sourceLine" id="cb171-2" data-line-number="2">b &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">c</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">4</span>)))</a>
<a class="sourceLine" id="cb171-3" data-line-number="3">c &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">11</span>, <span class="dv">12</span>), <span class="kw">list</span>(<span class="dv">13</span>, <span class="dv">14</span>)))</a>
<a class="sourceLine" id="cb171-4" data-line-number="4"></a>
<a class="sourceLine" id="cb171-5" data-line-number="5">a</a></code></pre></div>
<pre><code>## tensor([[1., 2.],
##         [3., 4.]])</code></pre>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb173-1" data-line-number="1">b</a></code></pre></div>
<pre><code>## tensor([1., 2., 3., 4.])</code></pre>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb175-1" data-line-number="1">torch<span class="op">$</span><span class="kw">dot</span>(a, b)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: dot: Expected 1-D argument self, but got 2-D</code></pre>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb177-1" data-line-number="1"><span class="co"># this is another way of performing dot product in PyTorch</span></a>
<a class="sourceLine" id="cb177-2" data-line-number="2"><span class="co"># a$dot(a)</span></a></code></pre></div>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb178-1" data-line-number="1">o1 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(2L, 2L)</a>
<a class="sourceLine" id="cb178-2" data-line-number="2">o2 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(2L, 2L)</a>
<a class="sourceLine" id="cb178-3" data-line-number="3"></a>
<a class="sourceLine" id="cb178-4" data-line-number="4">o1</a></code></pre></div>
<pre><code>## tensor([[1., 1.],
##         [1., 1.]])</code></pre>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb180-1" data-line-number="1">o2</a></code></pre></div>
<pre><code>## tensor([[1., 1.],
##         [1., 1.]])</code></pre>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb182-1" data-line-number="1">torch<span class="op">$</span><span class="kw">dot</span>(o1, o2)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: dot: Expected 1-D argument self, but got 2-D</code></pre>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb184-1" data-line-number="1">o1<span class="op">$</span><span class="kw">dot</span>(o2)</a></code></pre></div>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: dot: Expected 1-D argument self, but got 2-D</code></pre>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb186-1" data-line-number="1"><span class="co"># 1D tensors work fine</span></a>
<a class="sourceLine" id="cb186-2" data-line-number="2">r =<span class="st"> </span>torch<span class="op">$</span><span class="kw">dot</span>(torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(4L, 2L, 4L)), torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(3L, 4L, 1L)))</a>
<a class="sourceLine" id="cb186-3" data-line-number="3">r</a></code></pre></div>
<pre><code>## tensor(24.)</code></pre>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb188-1" data-line-number="1"><span class="co">## mm and matmul seem to address the dot product we are looking for in tensors</span></a>
<a class="sourceLine" id="cb188-2" data-line-number="2">a =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(2L, 3L)</a>
<a class="sourceLine" id="cb188-3" data-line-number="3">b =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(3L, 4L)</a>
<a class="sourceLine" id="cb188-4" data-line-number="4"></a>
<a class="sourceLine" id="cb188-5" data-line-number="5">a<span class="op">$</span><span class="kw">mm</span>(b)</a></code></pre></div>
<pre><code>## tensor([[ 0.6558,  0.7177,  0.0362, -0.1869],
##         [-0.1548, -0.7869,  0.0805,  0.3147]])</code></pre>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb190-1" data-line-number="1">a<span class="op">$</span><span class="kw">matmul</span>(b)</a></code></pre></div>
<pre><code>## tensor([[ 0.6558,  0.7177,  0.0362, -0.1869],
##         [-0.1548, -0.7869,  0.0805,  0.3147]])</code></pre>
<p>Here is agood explanation: <a href="https://stackoverflow.com/a/44525687/5270873" class="uri">https://stackoverflow.com/a/44525687/5270873</a></p>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb192-1" data-line-number="1">abt &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">mm</span>(a, b)<span class="op">$</span><span class="kw">transpose</span>(<span class="dt">dim0=</span>0L, <span class="dt">dim1=</span>1L)</a>
<a class="sourceLine" id="cb192-2" data-line-number="2">abt</a></code></pre></div>
<pre><code>## tensor([[ 0.6558, -0.1548],
##         [ 0.7177, -0.7869],
##         [ 0.0362,  0.0805],
##         [-0.1869,  0.3147]])</code></pre>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb194-1" data-line-number="1">at &lt;-<span class="st"> </span>a<span class="op">$</span><span class="kw">transpose</span>(<span class="dt">dim0=</span>0L, <span class="dt">dim1=</span>1L)</a>
<a class="sourceLine" id="cb194-2" data-line-number="2">bt &lt;-<span class="st"> </span>b<span class="op">$</span><span class="kw">transpose</span>(<span class="dt">dim0=</span>0L, <span class="dt">dim1=</span>1L)</a>
<a class="sourceLine" id="cb194-3" data-line-number="3"></a>
<a class="sourceLine" id="cb194-4" data-line-number="4">btat &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">matmul</span>(bt, at)</a>
<a class="sourceLine" id="cb194-5" data-line-number="5">btat</a></code></pre></div>
<pre><code>## tensor([[ 0.6558, -0.1548],
##         [ 0.7177, -0.7869],
##         [ 0.0362,  0.0805],
##         [-0.1869,  0.3147]])</code></pre>
<p><span class="math display">\[(A B)^T = B^T A^T\]</span></p>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb196-1" data-line-number="1">torch<span class="op">$</span><span class="kw">allclose</span>(abt, btat, <span class="dt">rtol=</span><span class="fl">0.0001</span>)</a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="tensors.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="linear-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["rtorch-book.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

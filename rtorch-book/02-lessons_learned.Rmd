# Lessons Learned

Here is a review of existing methods.

```{r}
library(rTorch)
```

## Enumeration

```{r}

x_train = array(c(3.3, 4.4, 5.5, 6.71, 6.93, 4.168, 
                  9.779, 6.182, 7.59, 2.167, 7.042,
                  10.791, 5.313, 7.997, 3.1), dim = c(15,1))

x_train <- r_to_py(x_train)
x_train = torch$from_numpy(x_train)         # convert to tensor
x_train = x_train$type(torch$FloatTensor)   # make it a a FloatTensor

x_train
```


```{r}
x_train$nelement()    # number of elements in the tensor
```


## How to iterate a generator

### Using `enumerate` and `iterate`

```{r}
py = import_builtins()

xx = py$enumerate(x_train)
xit = iterate(xx, simplify = TRUE)
xit
```

### Using a `for-loop`
```{r}

```

## Zero gradient
The zero gradient was one of the most difficult to implement in R.


## Transform a tensor
Explain how transform a tensor back and forth to `numpy`.
Why is this important?


## Build a model class
PyTorch classes cannot not directly instantiated from `R`. We need an intermediate step to create a class. For this, we use `reticulate` functions that will read the class implementation in `Python` code.

### Examples

## Convert a tensor to `numpy` object
This is a frequent operation. I have found that this is necessary when 

* a numpy function is not implemented in PyTorch
* We need to convert a tensor to R
* Perform a boolean operation that is not directly available in PyTorch.


## Convert a `numpy` object to an `R` object
This is mainly required for these reasons:

1. Create a data structure in R
2. Plot using r-base or ggplot2
3. Perform an analysis on parts of a tensor
4. Use R statistical functions that are not available in PyTorch.




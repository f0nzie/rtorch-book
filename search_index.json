[
["index.html", "A Minimal rTorch Tutorial Chapter 1 Prerequisites {-} Installation Python Anaconda", " A Minimal rTorch Tutorial Alfonso R. Reyes 2019-09-10 Chapter 1 Prerequisites {-} You need two things to get rTorch working: Install Python Anaconda. Preferrably, for 64-bits, and above Python 3.6+. Install R, Rtools and RStudio. Install rTorch from CRAN or GitHub. Note. It is not mandatory to have a previously created Python environment with Anaconda, where PyTorch and TorchVision have already been installed. This step is optional. You could also get it installed directly from the R console, in very similar fashion as in R-TensorFlow using the function install_pytorch. This book is available online via GitHub Pages, or you can also build it from source from its repository. Installation rTorch is available via CRAN or GitHub. The rTorch package can be installed from CRAN or Github. From CRAN: install.packages(&quot;rTorch&quot;) From GitHub, install rTorch with: devtools::install_github(&quot;f0nzie/rTorch&quot;) Python Anaconda Before start running rTorch, install a Python Anaconda environment first. Example Create a conda environment from the terminal with conda create -n myenv python=3.7 Activate the new environment with conda activate myenv Install the PyTorch related packages with: conda install python=3.6.6 pytorch-cpu torchvision-cpu matplotlib pandas -c pytorch The last part -c pytorch specifies the conda channel to download the PyTorch packages. Your installation may not work if you don’t indicate the channel. Now, you can load rTorch in R or RStudio. Automatic installation I use the idea from automatic installation in r-tensorflow, to create the function rTorch::install_pytorch(). This function will allow you to install a conda environment complete with all PyTorch requirements. Note. matplotlib and pandas are not really necessary for rTorch to work, but I was asked if matplotlib or pandas would work with PyTorch. So, I decided to install them for testing and experimentation. They both work. "],
["intro.html", "Chapter 2 Introduction 2.1 Motivation 2.2 How do we start using rTorch 2.3 What can you do with rTorch", " Chapter 2 Introduction 2.1 Motivation Why do we want a package of something that is already working well, such as PyTorch? There are several reasons, but the main one is to bring another machine learning framework to R. Probably it just me but I feel PyTorch very comfortable to work with. Feels pretty much like everything else in Python. I have tried other frameworks in R. The closest that matches a natural language like PyTorch, is MXnet. Unfortunately, it is the hardest to install and maintain after updates. Yes. I could have worked directly with PyTorch in a native Python environment, such as Jupyter or PyCharm but it very hard to quit RMarkdown once you get used to it. It is the real thing in regards to literate programming. It does not only contributes to improving the quality of the code but establishes a workflow for a better understanding of the subject by your intended readers (Knuth 1983), in what is been called the literate programming paradigm (Cordes and Brown 1991). This has the additional benefit of giving the ability to write combination of Python and R code together in the same document. There will times when it is better to create a class in Python; and other times where R will be more convenient to handle a data structure. 2.2 How do we start using rTorch Start using rTorch is very simple. The installation instructions are shown in Chapter 1. After installing the minimum system requirements, you just call it with: library(rTorch) transforms &lt;- torchvision$transforms There are several way of testing that rTorch is up and running. Let’s see some of them: 2.2.1 Getting the PyTorch version rTorch::torch_version() #&gt; [1] &quot;1.1&quot; 2.2.2 PyTorch configuration This will show the PyTorch version and the current version of Python installed, as well as the paths where they reside. rTorch::torch_config() #&gt; PyTorch v1.1.0 (~/anaconda3/envs/r-torch/lib/python3.6/site-packages/torch) #&gt; Python v3.6 (~/anaconda3/envs/r-torch/bin/python) 2.3 What can you do with rTorch Practically, you can do everything you could with PyTorch within the R ecosystem. Additionally to the rTorch module, from where you can extract methods, functions and classes, there are available two more modules: torchvision and np, which is short for numpy. 2.3.1 The torchvision module This is an example of using the torchvision module. With torchvision we could download any of the datasets available. In this case, we will be downloading the training dataset of the MNIST handwritten digits. There are 60,000 images in the training set. local_folder &lt;- &#39;../datasets/mnist_digits&#39; train_dataset = torchvision$datasets$MNIST(root = local_folder, train = TRUE, transform = transforms$ToTensor(), download = TRUE) train_dataset #&gt; Dataset MNIST #&gt; Number of datapoints: 60000 #&gt; Root location: ../datasets/mnist_digits #&gt; Split: Train You can do similarly for the test dataset if you set the flag train = FALSE. The test dataset has only 10,000 images. test_dataset = torchvision$datasets$MNIST(root = local_folder, train = FALSE, transform = transforms$ToTensor()) test_dataset #&gt; Dataset MNIST #&gt; Number of datapoints: 10000 #&gt; Root location: ../datasets/mnist_digits #&gt; Split: Test 2.3.2 np: the numpy module numpy is automaticaly installed when PyTorch is. There is some interdependence between both. Anytime that we need to do some transformation that is not available in PyTorch, we will use numpy. There are several operations that we could perform with numpy: Create an array # do some array manipulations with NumPy a &lt;- np$array(c(1:4)) a #&gt; [1] 1 2 3 4 np$reshape(np$arange(0, 9), c(3L, 3L)) #&gt; [,1] [,2] [,3] #&gt; [1,] 0 1 2 #&gt; [2,] 3 4 5 #&gt; [3,] 6 7 8 np$array(list( list(73, 67, 43), list(87, 134, 58), list(102, 43, 37), list(73, 67, 43), list(91, 88, 64), list(102, 43, 37), list(69, 96, 70), list(91, 88, 64), list(102, 43, 37), list(69, 96, 70) ), dtype=&#39;float32&#39;) #&gt; [,1] [,2] [,3] #&gt; [1,] 73 67 43 #&gt; [2,] 87 134 58 #&gt; [3,] 102 43 37 #&gt; [4,] 73 67 43 #&gt; [5,] 91 88 64 #&gt; [6,] 102 43 37 #&gt; [7,] 69 96 70 #&gt; [8,] 91 88 64 #&gt; [9,] 102 43 37 #&gt; [10,] 69 96 70 Reshape an array For the same test dataset that we loaded above, we will show the image of the handwritten digit and its label or class. Before plotting the image, we need to: Extract the image and label from the dataset Convert the tensor to a numpy array Reshape the tensor as a 2D array Plot the digit and its label rotate &lt;- function(x) t(apply(x, 2, rev)) # function to rotate the matrix # label for the image label &lt;- test_dataset[0][[2]] label #&gt; [1] 7 # convert tensor to numpy array .show_img &lt;- test_dataset[0][[1]]$numpy() dim(.show_img) #&gt; [1] 1 28 28 # reshape 3D array to 2D show_img &lt;- np$reshape(.show_img, c(28L, 28L)) dim(show_img) #&gt; [1] 28 28 # show in grays and rotate image(rotate(show_img), col = gray.colors(64)) title(label) Generate a random array # set the seed np$random$seed(123L) # generate a random array x = np$random$rand(100L) # calculate the y array y = np$sin(x) * np$power(x, 3L) + 3L * x + np$random$rand(100L) * 0.8 plot(x, y) Convert a numpy array to a PyTorch tensor This is a very common operation that I have seen in examples using PyTorch. Creating the array in numpy. and then convert it to a tensor. # input array x = np$array(rbind( c(0,0,1), c(0,1,1), c(1,0,1), c(1,1,1))) # the numpy array x #&gt; [,1] [,2] [,3] #&gt; [1,] 0 0 1 #&gt; [2,] 0 1 1 #&gt; [3,] 1 0 1 #&gt; [4,] 1 1 1 # convert the numpy array to float X &lt;- np$float32(x) # convert the numpy array to a float tensor X &lt;- torch$FloatTensor(X) X #&gt; tensor([[0., 0., 1.], #&gt; [0., 1., 1.], #&gt; [1., 0., 1.], #&gt; [1., 1., 1.]]) 2.3.3 Python built-in functions To access the Python built-in functions we make use of the package reticulate and the function import_builtins(). py_bi &lt;- import_builtins() Length of a dataset py_bi$len(train_dataset) #&gt; [1] 60000 py_bi$len(test_dataset) #&gt; [1] 10000 Iterators # iterate through training dataset enum_train_dataset &lt;- py_bi$enumerate(train_dataset) cat(sprintf(&quot;%8s %8s \\n&quot;, &quot;index&quot;, &quot;label&quot;)) #&gt; index label for (i in 1:py_bi$len(train_dataset)) { obj &lt;- reticulate::iter_next(enum_train_dataset) idx &lt;- obj[[1]] # index number cat(sprintf(&quot;%8d %5d \\n&quot;, idx, obj[[2]][[2]])) if (i &gt;= 100) break # print only 100 labels } #&gt; 0 5 #&gt; 1 0 #&gt; 2 4 #&gt; 3 1 #&gt; 4 9 #&gt; 5 2 #&gt; 6 1 #&gt; 7 3 #&gt; 8 1 #&gt; 9 4 #&gt; 10 3 #&gt; 11 5 #&gt; 12 3 #&gt; 13 6 #&gt; 14 1 #&gt; 15 7 #&gt; 16 2 #&gt; 17 8 #&gt; 18 6 #&gt; 19 9 #&gt; 20 4 #&gt; 21 0 #&gt; 22 9 #&gt; 23 1 #&gt; 24 1 #&gt; 25 2 #&gt; 26 4 #&gt; 27 3 #&gt; 28 2 #&gt; 29 7 #&gt; 30 3 #&gt; 31 8 #&gt; 32 6 #&gt; 33 9 #&gt; 34 0 #&gt; 35 5 #&gt; 36 6 #&gt; 37 0 #&gt; 38 7 #&gt; 39 6 #&gt; 40 1 #&gt; 41 8 #&gt; 42 7 #&gt; 43 9 #&gt; 44 3 #&gt; 45 9 #&gt; 46 8 #&gt; 47 5 #&gt; 48 9 #&gt; 49 3 #&gt; 50 3 #&gt; 51 0 #&gt; 52 7 #&gt; 53 4 #&gt; 54 9 #&gt; 55 8 #&gt; 56 0 #&gt; 57 9 #&gt; 58 4 #&gt; 59 1 #&gt; 60 4 #&gt; 61 4 #&gt; 62 6 #&gt; 63 0 #&gt; 64 4 #&gt; 65 5 #&gt; 66 6 #&gt; 67 1 #&gt; 68 0 #&gt; 69 0 #&gt; 70 1 #&gt; 71 7 #&gt; 72 1 #&gt; 73 6 #&gt; 74 3 #&gt; 75 0 #&gt; 76 2 #&gt; 77 1 #&gt; 78 1 #&gt; 79 7 #&gt; 80 9 #&gt; 81 0 #&gt; 82 2 #&gt; 83 6 #&gt; 84 7 #&gt; 85 8 #&gt; 86 3 #&gt; 87 9 #&gt; 88 0 #&gt; 89 4 #&gt; 90 6 #&gt; 91 7 #&gt; 92 4 #&gt; 93 6 #&gt; 94 8 #&gt; 95 0 #&gt; 96 7 #&gt; 97 8 #&gt; 98 3 #&gt; 99 1 Types and instances # get the class of the object py_bi$type(train_dataset) #&gt; &lt;class &#39;torchvision.datasets.mnist.MNIST&#39;&gt; # is train_dataset a torchvision dataset class py_bi$isinstance(train_dataset, torchvision$datasets$mnist$MNIST) #&gt; [1] TRUE References "],
["lessons-learned.html", "Chapter 3 Lessons Learned 3.1 Calling objects from PyTorch 3.2 Call a module from PyTorch 3.3 Show the attributes (methods) of a class or PyTorch object 3.4 Enumeration 3.5 How to iterate 3.6 Zero gradient 3.7 Transform a tensor 3.8 Build a model class 3.9 Convert a tensor to numpy object 3.10 Convert a numpy object to an R object", " Chapter 3 Lessons Learned This chapter will explain the main differences between PyTorch and rTorch. Most of the things work directly in PyTorch but we need to be aware of some minor differences when working with rTorch. Here is a review of existing methods. library(rTorch) 3.1 Calling objects from PyTorch We use the dollar sign or $ to call a class, function or method from the torch module. torch$tensor #&gt; &lt;built-in method tensor of type&gt; 3.2 Call a module from PyTorch # these are the equivalents of import module nn &lt;- torch$nn transforms &lt;- torchvision$transforms dsets &lt;- torchvision$datasets Then we can proceed to extract classes, methods and functions from the nn, transforms, and dsets objects. 3.3 Show the attributes (methods) of a class or PyTorch object Sometimes we are interested in knowing the internal components of a class. In that case, we use the reticulate function py_list_attributes(). local_folder &lt;- &#39;../datasets/mnist_digits&#39; train_dataset = torchvision$datasets$MNIST(root = local_folder, train = TRUE, transform = transforms$ToTensor(), download = TRUE) train_dataset #&gt; Dataset MNIST #&gt; Number of datapoints: 60000 #&gt; Root location: ../datasets/mnist_digits #&gt; Split: Train reticulate::py_list_attributes(train_dataset) #&gt; [1] &quot;__add__&quot; &quot;__class__&quot; #&gt; [3] &quot;__delattr__&quot; &quot;__dict__&quot; #&gt; [5] &quot;__dir__&quot; &quot;__doc__&quot; #&gt; [7] &quot;__eq__&quot; &quot;__format__&quot; #&gt; [9] &quot;__ge__&quot; &quot;__getattribute__&quot; #&gt; [11] &quot;__getitem__&quot; &quot;__gt__&quot; #&gt; [13] &quot;__hash__&quot; &quot;__init__&quot; #&gt; [15] &quot;__init_subclass__&quot; &quot;__le__&quot; #&gt; [17] &quot;__len__&quot; &quot;__lt__&quot; #&gt; [19] &quot;__module__&quot; &quot;__ne__&quot; #&gt; [21] &quot;__new__&quot; &quot;__reduce__&quot; #&gt; [23] &quot;__reduce_ex__&quot; &quot;__repr__&quot; #&gt; [25] &quot;__setattr__&quot; &quot;__sizeof__&quot; #&gt; [27] &quot;__str__&quot; &quot;__subclasshook__&quot; #&gt; [29] &quot;__weakref__&quot; &quot;_check_exists&quot; #&gt; [31] &quot;_format_transform_repr&quot; &quot;_repr_indent&quot; #&gt; [33] &quot;class_to_idx&quot; &quot;classes&quot; #&gt; [35] &quot;data&quot; &quot;download&quot; #&gt; [37] &quot;extra_repr&quot; &quot;extract_gzip&quot; #&gt; [39] &quot;processed_folder&quot; &quot;raw_folder&quot; #&gt; [41] &quot;root&quot; &quot;target_transform&quot; #&gt; [43] &quot;targets&quot; &quot;test_data&quot; #&gt; [45] &quot;test_file&quot; &quot;test_labels&quot; #&gt; [47] &quot;train&quot; &quot;train_data&quot; #&gt; [49] &quot;train_labels&quot; &quot;training_file&quot; #&gt; [51] &quot;transform&quot; &quot;transforms&quot; #&gt; [53] &quot;urls&quot; Knowing the internal methods of a class could be useful when we want to refer to a specific property of such class. For example, from the list above, we know that the object train_dataset has an attribute __len__. We can call it like this: train_dataset$`__len__`() #&gt; [1] 60000 3.4 Enumeration x_train = array(c(3.3, 4.4, 5.5, 6.71, 6.93, 4.168, 9.779, 6.182, 7.59, 2.167, 7.042, 10.791, 5.313, 7.997, 3.1), dim = c(15,1)) x_train &lt;- r_to_py(x_train) x_train &lt;- torch$from_numpy(x_train) # convert to tensor x_train &lt;- x_train$type(torch$FloatTensor) # make it a a FloatTensor x_train #&gt; tensor([[ 3.3000], #&gt; [ 4.4000], #&gt; [ 5.5000], #&gt; [ 6.7100], #&gt; [ 6.9300], #&gt; [ 4.1680], #&gt; [ 9.7790], #&gt; [ 6.1820], #&gt; [ 7.5900], #&gt; [ 2.1670], #&gt; [ 7.0420], #&gt; [10.7910], #&gt; [ 5.3130], #&gt; [ 7.9970], #&gt; [ 3.1000]]) x_train$nelement() # number of elements in the tensor #&gt; [1] 15 3.5 How to iterate 3.5.1 Using enumerate and iterate py = import_builtins() enum_x_train = py$enumerate(x_train) enum_x_train #&gt; &lt;enumerate&gt; py$len(x_train) #&gt; [1] 15 xit = iterate(enum_x_train, simplify = TRUE) xit #&gt; [[1]] #&gt; [[1]][[1]] #&gt; [1] 0 #&gt; #&gt; [[1]][[2]] #&gt; tensor([3.3000]) #&gt; #&gt; #&gt; [[2]] #&gt; [[2]][[1]] #&gt; [1] 1 #&gt; #&gt; [[2]][[2]] #&gt; tensor([4.4000]) #&gt; #&gt; #&gt; [[3]] #&gt; [[3]][[1]] #&gt; [1] 2 #&gt; #&gt; [[3]][[2]] #&gt; tensor([5.5000]) #&gt; #&gt; #&gt; [[4]] #&gt; [[4]][[1]] #&gt; [1] 3 #&gt; #&gt; [[4]][[2]] #&gt; tensor([6.7100]) #&gt; #&gt; #&gt; [[5]] #&gt; [[5]][[1]] #&gt; [1] 4 #&gt; #&gt; [[5]][[2]] #&gt; tensor([6.9300]) #&gt; #&gt; #&gt; [[6]] #&gt; [[6]][[1]] #&gt; [1] 5 #&gt; #&gt; [[6]][[2]] #&gt; tensor([4.1680]) #&gt; #&gt; #&gt; [[7]] #&gt; [[7]][[1]] #&gt; [1] 6 #&gt; #&gt; [[7]][[2]] #&gt; tensor([9.7790]) #&gt; #&gt; #&gt; [[8]] #&gt; [[8]][[1]] #&gt; [1] 7 #&gt; #&gt; [[8]][[2]] #&gt; tensor([6.1820]) #&gt; #&gt; #&gt; [[9]] #&gt; [[9]][[1]] #&gt; [1] 8 #&gt; #&gt; [[9]][[2]] #&gt; tensor([7.5900]) #&gt; #&gt; #&gt; [[10]] #&gt; [[10]][[1]] #&gt; [1] 9 #&gt; #&gt; [[10]][[2]] #&gt; tensor([2.1670]) #&gt; #&gt; #&gt; [[11]] #&gt; [[11]][[1]] #&gt; [1] 10 #&gt; #&gt; [[11]][[2]] #&gt; tensor([7.0420]) #&gt; #&gt; #&gt; [[12]] #&gt; [[12]][[1]] #&gt; [1] 11 #&gt; #&gt; [[12]][[2]] #&gt; tensor([10.7910]) #&gt; #&gt; #&gt; [[13]] #&gt; [[13]][[1]] #&gt; [1] 12 #&gt; #&gt; [[13]][[2]] #&gt; tensor([5.3130]) #&gt; #&gt; #&gt; [[14]] #&gt; [[14]][[1]] #&gt; [1] 13 #&gt; #&gt; [[14]][[2]] #&gt; tensor([7.9970]) #&gt; #&gt; #&gt; [[15]] #&gt; [[15]][[1]] #&gt; [1] 14 #&gt; #&gt; [[15]][[2]] #&gt; tensor([3.1000]) 3.5.2 Using a for-loop to iterate # reset the iterator enum_x_train = py$enumerate(x_train) for (i in 1:py$len(x_train)) { obj &lt;- iter_next(enum_x_train) # next item cat(obj[[1]], &quot;\\t&quot;) # 1st part or index print(obj[[2]]) # 2nd part or tensor } #&gt; 0 tensor([3.3000]) #&gt; 1 tensor([4.4000]) #&gt; 2 tensor([5.5000]) #&gt; 3 tensor([6.7100]) #&gt; 4 tensor([6.9300]) #&gt; 5 tensor([4.1680]) #&gt; 6 tensor([9.7790]) #&gt; 7 tensor([6.1820]) #&gt; 8 tensor([7.5900]) #&gt; 9 tensor([2.1670]) #&gt; 10 tensor([7.0420]) #&gt; 11 tensor([10.7910]) #&gt; 12 tensor([5.3130]) #&gt; 13 tensor([7.9970]) #&gt; 14 tensor([3.1000]) We will find very frequently this kind of iterators when we read a dataset using torchvision. There are different ways to iterate through these objects. 3.6 Zero gradient The zero gradient was one of the most difficult to implement in R if we don’t pay attention to the content of the objects carrying the weights and biases. This happens when the algorithm written in PyTorch is not immediately translatable to rTorch. This can be appreciated in this example. 3.6.1 Version in Python import numpy as np import torch torch.manual_seed(0) # reproducible # Input (temp, rainfall, humidity) #&gt; &lt;torch._C.Generator object at 0x7feb1dfc4df0&gt; inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70]], dtype=&#39;float32&#39;) # Targets (apples, oranges) targets = np.array([[56, 70], [81, 101], [119, 133], [22, 37], [103, 119]], dtype=&#39;float32&#39;) # Convert inputs and targets to tensors inputs = torch.from_numpy(inputs) targets = torch.from_numpy(targets) # random weights and biases w = torch.randn(2, 3, requires_grad=True) b = torch.randn(2, requires_grad=True) # function for the model def model(x): wt = w.t() mm = x @ w.t() return x @ w.t() + b # @ represents matrix multiplication in PyTorch # MSE loss function def mse(t1, t2): diff = t1 - t2 return torch.sum(diff * diff) / diff.numel() # Running all together # Train for 100 epochs for i in range(100): preds = model(inputs) loss = mse(preds, targets) loss.backward() with torch.no_grad(): w -= w.grad * 0.00001 b -= b.grad * 0.00001 w_gz = w.grad.zero_() b_gz = b.grad.zero_() # Calculate loss preds = model(inputs) loss = mse(preds, targets) print(&quot;Loss: &quot;, loss) # predictions #&gt; Loss: tensor(1270.1234, grad_fn=&lt;DivBackward0&gt;) print(&quot;\\nPredictions:&quot;) #&gt; #&gt; Predictions: preds # Targets #&gt; tensor([[ 69.3122, 80.2639], #&gt; [ 73.7528, 97.2381], #&gt; [118.3933, 124.7628], #&gt; [ 89.6111, 93.0286], #&gt; [ 47.3014, 80.6467]], grad_fn=&lt;AddBackward0&gt;) print(&quot;\\nTargets:&quot;) #&gt; #&gt; Targets: targets #&gt; tensor([[ 56., 70.], #&gt; [ 81., 101.], #&gt; [119., 133.], #&gt; [ 22., 37.], #&gt; [103., 119.]]) 3.6.2 Version in R library(rTorch) torch$manual_seed(0) #&gt; &lt;torch._C.Generator&gt; device = torch$device(&#39;cpu&#39;) # Input (temp, rainfall, humidity) inputs = np$array(list(list(73, 67, 43), list(91, 88, 64), list(87, 134, 58), list(102, 43, 37), list(69, 96, 70)), dtype=&#39;float32&#39;) # Targets (apples, oranges) targets = np$array(list(list(56, 70), list(81, 101), list(119, 133), list(22, 37), list(103, 119)), dtype=&#39;float32&#39;) # Convert inputs and targets to tensors inputs = torch$from_numpy(inputs) targets = torch$from_numpy(targets) # random numbers for weights and biases. Then convert to double() torch$set_default_dtype(torch$float64) w = torch$randn(2L, 3L, requires_grad=TRUE) #$double() b = torch$randn(2L, requires_grad=TRUE) #$double() model &lt;- function(x) { wt &lt;- w$t() return(torch$add(torch$mm(x, wt), b)) } # MSE loss mse = function(t1, t2) { diff &lt;- torch$sub(t1, t2) mul &lt;- torch$sum(torch$mul(diff, diff)) return(torch$div(mul, diff$numel())) } # Running all together # Adjust weights and reset gradients for (i in 1:100) { preds = model(inputs) loss = mse(preds, targets) loss$backward() with(torch$no_grad(), { w$data &lt;- torch$sub(w$data, torch$mul(w$grad, torch$scalar_tensor(1e-5))) b$data &lt;- torch$sub(b$data, torch$mul(b$grad, torch$scalar_tensor(1e-5))) w$grad$zero_() b$grad$zero_() }) } # Calculate loss preds = model(inputs) loss = mse(preds, targets) cat(&quot;Loss: &quot;); print(loss) #&gt; Loss: #&gt; tensor(1270.1237, grad_fn=&lt;DivBackward0&gt;) # predictions cat(&quot;\\nPredictions:\\n&quot;) #&gt; #&gt; Predictions: preds #&gt; tensor([[ 69.3122, 80.2639], #&gt; [ 73.7528, 97.2381], #&gt; [118.3933, 124.7628], #&gt; [ 89.6111, 93.0286], #&gt; [ 47.3013, 80.6467]], grad_fn=&lt;AddBackward0&gt;) # Targets cat(&quot;\\nTargets:\\n&quot;) #&gt; #&gt; Targets: targets #&gt; tensor([[ 56., 70.], #&gt; [ 81., 101.], #&gt; [119., 133.], #&gt; [ 22., 37.], #&gt; [103., 119.]]) Notice that while in Python the tensor operation, gradient of the weights times the Learning Rate, \\[w = -w + \\nabla w \\; \\alpha\\] is a very straight forwward and clean code: w -= w.grad * 1e-5 In R shows a little bit more convoluted: w$data &lt;- torch$sub(w$data, torch$mul(w$grad, torch$scalar_tensor(1e-5))) 3.7 Transform a tensor Explain how transform a tensor back and forth to numpy. Why is this important? 3.8 Build a model class PyTorch classes cannot not directly instantiated from R. We need an intermediate step to create a class. For this, we use reticulate functions that will read the class implementation in Python code. 3.8.1 Example 1 3.8.2 Example 2 3.9 Convert a tensor to numpy object This is a frequent operation. I have found that this is necessary when a numpy function is not implemented in PyTorch We need to convert a tensor to R Perform a Boolean operation that is not directly available in PyTorch. 3.10 Convert a numpy object to an R object This is mainly required for these reasons: Create a data structure in R Plot using r-base or ggplot2 Perform an analysis on parts of a tensor Use R statistical functions that are not available in PyTorch. "],
["tensors.html", "Chapter 4 Tensors 4.1 Arithmetic of tensors 4.2 Boolean operations 4.3 Slicing 4.4 Example", " Chapter 4 Tensors We describe the most important PyTorch methods in this chapter. 4.1 Arithmetic of tensors 4.2 Boolean operations 4.3 Slicing 4.4 Example The following example was converted from PyTorch to rTorch to show differences and similarities of both approaches. The original source can be found here: Source: https://github.com/jcjohnson/pytorch-examples#pytorch-tensors 4.4.1 Load the libraries library(rTorch) device = torch$device(&#39;cpu&#39;) # device = torch.device(&#39;cuda&#39;) # Uncomment this to run on GPU torch$manual_seed(0) #&gt; &lt;torch._C.Generator&gt; N is batch size; D_in is input dimension; H is hidden dimension; D_out is output dimension. 4.4.2 Datasets We will create a random dataset for a two layer neural network. N &lt;- 64L; D_in &lt;- 1000L; H &lt;- 100L; D_out &lt;- 10L # Create random Tensors to hold inputs and outputs x &lt;- torch$randn(N, D_in, device=device) y &lt;- torch$randn(N, D_out, device=device) # Randomly initialize weights w1 &lt;- torch$randn(D_in, H, device=device) # layer 1 w2 &lt;- torch$randn(H, D_out, device=device) # layer 2 4.4.3 Run the model learning_rate = 1e-6 # loop for (t in 1:50) { # Forward pass: compute predicted y h &lt;- x$mm(w1) h_relu &lt;- h$clamp(min=0) y_pred &lt;- h_relu$mm(w2) # Compute and print loss; loss is a scalar, and is stored in a PyTorch Tensor # of shape (); we can get its value as a Python number with loss.item(). loss &lt;- (torch$sub(y_pred, y))$pow(2)$sum() cat(t, &quot;\\t&quot;) cat(loss$item(), &quot;\\n&quot;) # Backprop to compute gradients of w1 and w2 with respect to loss grad_y_pred &lt;- torch$mul(torch$scalar_tensor(2.0), torch$sub(y_pred, y)) grad_w2 &lt;- h_relu$t()$mm(grad_y_pred) grad_h_relu &lt;- grad_y_pred$mm(w2$t()) grad_h &lt;- grad_h_relu$clone() # grad_h[h &lt; 0] = 0 mask &lt;- grad_h$lt(0) # print(mask) # negatives &lt;- torch$masked_select(grad_h, mask) # print(negatives) # negatives &lt;- 0.0 torch$masked_select(grad_h, mask)$fill_(0.0) # print(grad_h) grad_w1 &lt;- x$t()$mm(grad_h) # Update weights using gradient descent w1 &lt;- torch$sub(w1, torch$mul(learning_rate, grad_w1)) w2 &lt;- torch$sub(w2, torch$mul(learning_rate, grad_w2)) } #&gt; 1 29428666 #&gt; 2 22572578 #&gt; 3 20474034 #&gt; 4 19486618 #&gt; 5 1.8e+07 #&gt; 6 15345387 #&gt; 7 1.2e+07 #&gt; 8 8557820 #&gt; 9 5777508 #&gt; 10 3791835 #&gt; 11 2494379 #&gt; 12 1679618 #&gt; 13 1176170 #&gt; 14 858874 #&gt; 15 654740 #&gt; 16 517359 #&gt; 17 421628 #&gt; 18 351479 #&gt; 19 298321 #&gt; 20 256309 #&gt; 21 222513 #&gt; 22 194530 #&gt; 23 171048 #&gt; 24 151092 #&gt; 25 134001 #&gt; 26 119256 #&gt; 27 106431 #&gt; 28 95220 #&gt; 29 85393 #&gt; 30 76739 #&gt; 31 69099 #&gt; 32 62340 #&gt; 33 56344 #&gt; 34 51009 #&gt; 35 46249 #&gt; 36 41992 #&gt; 37 38182 #&gt; 38 34770 #&gt; 39 31705 #&gt; 40 28946 #&gt; 41 26458 #&gt; 42 24211 #&gt; 43 22179 #&gt; 44 20334 #&gt; 45 18659 #&gt; 46 17138 #&gt; 47 15753 #&gt; 48 14494 #&gt; 49 13347 #&gt; 50 12301 "],
["linearalgebra.html", "Chapter 5 Linear Algebra with Torch 5.1 Scalars 5.2 Vectors 5.3 Matrices 5.4 3D+ tensors 5.5 Transpose of a matrix 5.6 Vectors, special case of a matrix 5.7 Tensor arithmetic 5.8 Add a scalar to a tensor 5.9 Multiplying tensors 5.10 Dot product", " Chapter 5 Linear Algebra with Torch The following are basic operations of Linear Algebra using PyTorch. library(rTorch) 5.1 Scalars torch$scalar_tensor(2.78654) #&gt; tensor(2.7865) torch$scalar_tensor(0L) #&gt; tensor(0.) torch$scalar_tensor(1L) #&gt; tensor(1.) torch$scalar_tensor(TRUE) #&gt; tensor(1.) torch$scalar_tensor(FALSE) #&gt; tensor(0.) 5.2 Vectors v &lt;- c(0, 1, 2, 3, 4, 5) torch$as_tensor(v) #&gt; tensor([0., 1., 2., 3., 4., 5.]) # row-vector (mr &lt;- matrix(1:10, nrow=1)) #&gt; [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] #&gt; [1,] 1 2 3 4 5 6 7 8 9 10 torch$as_tensor(mr) #&gt; tensor([[ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]], dtype=torch.int32) torch$as_tensor(mr)$shape #&gt; torch.Size([1, 10]) # column-vector (mc &lt;- matrix(1:10, ncol=1)) #&gt; [,1] #&gt; [1,] 1 #&gt; [2,] 2 #&gt; [3,] 3 #&gt; [4,] 4 #&gt; [5,] 5 #&gt; [6,] 6 #&gt; [7,] 7 #&gt; [8,] 8 #&gt; [9,] 9 #&gt; [10,] 10 torch$as_tensor(mc) #&gt; tensor([[ 1], #&gt; [ 2], #&gt; [ 3], #&gt; [ 4], #&gt; [ 5], #&gt; [ 6], #&gt; [ 7], #&gt; [ 8], #&gt; [ 9], #&gt; [10]], dtype=torch.int32) torch$as_tensor(mc)$shape #&gt; torch.Size([10, 1]) 5.3 Matrices (m1 &lt;- matrix(1:24, nrow = 3, byrow = TRUE)) #&gt; [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] #&gt; [1,] 1 2 3 4 5 6 7 8 #&gt; [2,] 9 10 11 12 13 14 15 16 #&gt; [3,] 17 18 19 20 21 22 23 24 (t1 &lt;- torch$as_tensor(m1)) #&gt; tensor([[ 1, 2, 3, 4, 5, 6, 7, 8], #&gt; [ 9, 10, 11, 12, 13, 14, 15, 16], #&gt; [17, 18, 19, 20, 21, 22, 23, 24]], dtype=torch.int32) torch$as_tensor(m1)$shape #&gt; torch.Size([3, 8]) torch$as_tensor(m1)$size() #&gt; torch.Size([3, 8]) dim(torch$as_tensor(m1)) #&gt; [1] 3 8 length(torch$as_tensor(m1)) #&gt; [1] 24 (m2 &lt;- matrix(0:99, ncol = 10)) #&gt; [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] #&gt; [1,] 0 10 20 30 40 50 60 70 80 90 #&gt; [2,] 1 11 21 31 41 51 61 71 81 91 #&gt; [3,] 2 12 22 32 42 52 62 72 82 92 #&gt; [4,] 3 13 23 33 43 53 63 73 83 93 #&gt; [5,] 4 14 24 34 44 54 64 74 84 94 #&gt; [6,] 5 15 25 35 45 55 65 75 85 95 #&gt; [7,] 6 16 26 36 46 56 66 76 86 96 #&gt; [8,] 7 17 27 37 47 57 67 77 87 97 #&gt; [9,] 8 18 28 38 48 58 68 78 88 98 #&gt; [10,] 9 19 29 39 49 59 69 79 89 99 (t2 &lt;- torch$as_tensor(m2)) #&gt; tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90], #&gt; [ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91], #&gt; [ 2, 12, 22, 32, 42, 52, 62, 72, 82, 92], #&gt; [ 3, 13, 23, 33, 43, 53, 63, 73, 83, 93], #&gt; [ 4, 14, 24, 34, 44, 54, 64, 74, 84, 94], #&gt; [ 5, 15, 25, 35, 45, 55, 65, 75, 85, 95], #&gt; [ 6, 16, 26, 36, 46, 56, 66, 76, 86, 96], #&gt; [ 7, 17, 27, 37, 47, 57, 67, 77, 87, 97], #&gt; [ 8, 18, 28, 38, 48, 58, 68, 78, 88, 98], #&gt; [ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]], dtype=torch.int32) t2$shape #&gt; torch.Size([10, 10]) dim(torch$as_tensor(m2)) #&gt; [1] 10 10 m1[1, 1] #&gt; [1] 1 m2[1, 1] #&gt; [1] 0 t1[1, 1] #&gt; tensor(1, dtype=torch.int32) t2[1, 1] #&gt; tensor(0, dtype=torch.int32) 5.4 3D+ tensors # RGB color image has three axes (img &lt;- torch$rand(3L, 28L, 28L)) #&gt; tensor([[[0.9278, 0.9369, 0.2749, ..., 0.0856, 0.6586, 0.8358], #&gt; [0.2048, 0.0242, 0.4602, ..., 0.7814, 0.4846, 0.7815], #&gt; [0.7370, 0.3234, 0.6227, ..., 0.1888, 0.1228, 0.4435], #&gt; ..., #&gt; [0.0438, 0.9457, 0.4114, ..., 0.7345, 0.5027, 0.4656], #&gt; [0.5554, 0.1018, 0.1432, ..., 0.5931, 0.8554, 0.6607], #&gt; [0.1600, 0.2951, 0.9883, ..., 0.8358, 0.1291, 0.3361]], #&gt; #&gt; [[0.1447, 0.5004, 0.3292, ..., 0.8661, 0.9246, 0.1373], #&gt; [0.8583, 0.4895, 0.5789, ..., 0.5106, 0.3631, 0.9259], #&gt; [0.8406, 0.7410, 0.4269, ..., 0.7172, 0.7712, 0.3490], #&gt; ..., #&gt; [0.6005, 0.3802, 0.6549, ..., 0.8336, 0.0384, 0.6042], #&gt; [0.6359, 0.9466, 0.4340, ..., 0.0607, 0.4640, 0.0983], #&gt; [0.3668, 0.7872, 0.4365, ..., 0.6790, 0.8020, 0.7676]], #&gt; #&gt; [[0.8941, 0.1069, 0.3020, ..., 0.4772, 0.4869, 0.9425], #&gt; [0.3964, 0.9879, 0.9531, ..., 0.2790, 0.3065, 0.7527], #&gt; [0.6645, 0.7087, 0.7506, ..., 0.3208, 0.9739, 0.3434], #&gt; ..., #&gt; [0.8963, 0.1034, 0.4310, ..., 0.8036, 0.2360, 0.0219], #&gt; [0.9534, 0.9838, 0.5987, ..., 0.3069, 0.9105, 0.1694], #&gt; [0.3805, 0.3730, 0.7320, ..., 0.8799, 0.8117, 0.4939]]]) img$shape #&gt; torch.Size([3, 28, 28]) img[1, 1, 1] #&gt; tensor(0.9278) img[3, 28, 28] #&gt; tensor(0.4939) 5.5 Transpose of a matrix (m3 &lt;- matrix(1:25, ncol = 5)) #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 1 6 11 16 21 #&gt; [2,] 2 7 12 17 22 #&gt; [3,] 3 8 13 18 23 #&gt; [4,] 4 9 14 19 24 #&gt; [5,] 5 10 15 20 25 # transpose tm3 &lt;- t(m3) tm3 #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 1 2 3 4 5 #&gt; [2,] 6 7 8 9 10 #&gt; [3,] 11 12 13 14 15 #&gt; [4,] 16 17 18 19 20 #&gt; [5,] 21 22 23 24 25 (t3 &lt;- torch$as_tensor(m3)) #&gt; tensor([[ 1, 6, 11, 16, 21], #&gt; [ 2, 7, 12, 17, 22], #&gt; [ 3, 8, 13, 18, 23], #&gt; [ 4, 9, 14, 19, 24], #&gt; [ 5, 10, 15, 20, 25]], dtype=torch.int32) tt3 &lt;- t3$transpose(dim0 = 0L, dim1 = 1L) tt3 #&gt; tensor([[ 1, 2, 3, 4, 5], #&gt; [ 6, 7, 8, 9, 10], #&gt; [11, 12, 13, 14, 15], #&gt; [16, 17, 18, 19, 20], #&gt; [21, 22, 23, 24, 25]], dtype=torch.int32) tm3 == tt3$numpy() # convert first the tensor to numpy #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] TRUE TRUE TRUE TRUE TRUE #&gt; [2,] TRUE TRUE TRUE TRUE TRUE #&gt; [3,] TRUE TRUE TRUE TRUE TRUE #&gt; [4,] TRUE TRUE TRUE TRUE TRUE #&gt; [5,] TRUE TRUE TRUE TRUE TRUE 5.6 Vectors, special case of a matrix m2 &lt;- matrix(0:99, ncol = 10) (t2 &lt;- torch$as_tensor(m2)) #&gt; tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90], #&gt; [ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91], #&gt; [ 2, 12, 22, 32, 42, 52, 62, 72, 82, 92], #&gt; [ 3, 13, 23, 33, 43, 53, 63, 73, 83, 93], #&gt; [ 4, 14, 24, 34, 44, 54, 64, 74, 84, 94], #&gt; [ 5, 15, 25, 35, 45, 55, 65, 75, 85, 95], #&gt; [ 6, 16, 26, 36, 46, 56, 66, 76, 86, 96], #&gt; [ 7, 17, 27, 37, 47, 57, 67, 77, 87, 97], #&gt; [ 8, 18, 28, 38, 48, 58, 68, 78, 88, 98], #&gt; [ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]], dtype=torch.int32) # in R (v1 &lt;- m2[, 1]) #&gt; [1] 0 1 2 3 4 5 6 7 8 9 (v2 &lt;- m2[10, ]) #&gt; [1] 9 19 29 39 49 59 69 79 89 99 # PyTorch t2c &lt;- t2[, 1] t2r &lt;- t2[10, ] t2c #&gt; tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) t2r #&gt; tensor([ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99], dtype=torch.int32) In vectors, the vector and its transpose are equal. tt2r &lt;- t2r$transpose(dim0 = 0L, dim1 = 0L) tt2r #&gt; tensor([ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99], dtype=torch.int32) # a tensor of booleans. is vector equal to its transposed? t2r == tt2r #&gt; tensor([True, True, True, True, True, True, True, True, True, True], #&gt; dtype=torch.bool) 5.7 Tensor arithmetic (x = torch$ones(5L, 4L)) #&gt; tensor([[1., 1., 1., 1.], #&gt; [1., 1., 1., 1.], #&gt; [1., 1., 1., 1.], #&gt; [1., 1., 1., 1.], #&gt; [1., 1., 1., 1.]]) (y = torch$ones(5L, 4L)) #&gt; tensor([[1., 1., 1., 1.], #&gt; [1., 1., 1., 1.], #&gt; [1., 1., 1., 1.], #&gt; [1., 1., 1., 1.], #&gt; [1., 1., 1., 1.]]) x + y #&gt; tensor([[2., 2., 2., 2.], #&gt; [2., 2., 2., 2.], #&gt; [2., 2., 2., 2.], #&gt; [2., 2., 2., 2.], #&gt; [2., 2., 2., 2.]]) \\[A + B = B + A\\] x + y == y + x #&gt; tensor([[True, True, True, True], #&gt; [True, True, True, True], #&gt; [True, True, True, True], #&gt; [True, True, True, True], #&gt; [True, True, True, True]], dtype=torch.bool) 5.8 Add a scalar to a tensor s &lt;- 0.5 # scalar x + s #&gt; tensor([[1.5000, 1.5000, 1.5000, 1.5000], #&gt; [1.5000, 1.5000, 1.5000, 1.5000], #&gt; [1.5000, 1.5000, 1.5000, 1.5000], #&gt; [1.5000, 1.5000, 1.5000, 1.5000], #&gt; [1.5000, 1.5000, 1.5000, 1.5000]]) # scalar multiplying two tensors s * (x + y) #&gt; tensor([[1., 1., 1., 1.], #&gt; [1., 1., 1., 1.], #&gt; [1., 1., 1., 1.], #&gt; [1., 1., 1., 1.], #&gt; [1., 1., 1., 1.]]) 5.9 Multiplying tensors \\[A * B = B * A\\] (x = torch$ones(5L, 4L)) #&gt; tensor([[1., 1., 1., 1.], #&gt; [1., 1., 1., 1.], #&gt; [1., 1., 1., 1.], #&gt; [1., 1., 1., 1.], #&gt; [1., 1., 1., 1.]]) (y = torch$ones(5L, 4L)) #&gt; tensor([[1., 1., 1., 1.], #&gt; [1., 1., 1., 1.], #&gt; [1., 1., 1., 1.], #&gt; [1., 1., 1., 1.], #&gt; [1., 1., 1., 1.]]) (z = 2 * x + 4 * y) #&gt; tensor([[6., 6., 6., 6.], #&gt; [6., 6., 6., 6.], #&gt; [6., 6., 6., 6.], #&gt; [6., 6., 6., 6.], #&gt; [6., 6., 6., 6.]]) x * y == y * x #&gt; tensor([[True, True, True, True], #&gt; [True, True, True, True], #&gt; [True, True, True, True], #&gt; [True, True, True, True], #&gt; [True, True, True, True]], dtype=torch.bool) 5.10 Dot product \\[dot(a,b)_{i,j,k,a,b,c} = \\sum_m a_{i,j,k,m}b_{a,b,m,c}\\] torch$dot(torch$tensor(c(2, 3)), torch$tensor(c(2, 1))) #&gt; tensor(7.) a &lt;- np$array(list(list(1, 2), list(3, 4))) a #&gt; [,1] [,2] #&gt; [1,] 1 2 #&gt; [2,] 3 4 b &lt;- np$array(list(list(1, 2), list(3, 4))) b #&gt; [,1] [,2] #&gt; [1,] 1 2 #&gt; [2,] 3 4 np$dot(a, b) #&gt; [,1] [,2] #&gt; [1,] 7 10 #&gt; [2,] 15 22 torch.dot() treats both a and b as 1D vectors (irrespective of their original shape) and computes their inner product. at &lt;- torch$as_tensor(a) bt &lt;- torch$as_tensor(b) torch$dot(at, bt) #&gt; Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: dot: Expected 1-D argument self, but got 2-D # at %.*% bt If we perform the same dot product operation in Python, we get the same error: import torch import numpy as np a = np.array([[1, 2], [3, 4]]) a #&gt; array([[1, 2], #&gt; [3, 4]]) b = np.array([[1, 2], [3, 4]]) b #&gt; array([[1, 2], #&gt; [3, 4]]) np.dot(a, b) #&gt; array([[ 7, 10], #&gt; [15, 22]]) at = torch.as_tensor(a) bt = torch.as_tensor(b) at #&gt; tensor([[1, 2], #&gt; [3, 4]]) bt #&gt; tensor([[1, 2], #&gt; [3, 4]]) torch.dot(at, bt) #&gt; Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: dot: Expected 1-D argument self, but got 2-D #&gt; #&gt; Detailed traceback: #&gt; File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt; a &lt;- torch$Tensor(list(list(1, 2), list(3, 4))) b &lt;- torch$Tensor(c(c(1, 2), c(3, 4))) c &lt;- torch$Tensor(list(list(11, 12), list(13, 14))) a #&gt; tensor([[1., 2.], #&gt; [3., 4.]]) b #&gt; tensor([1., 2., 3., 4.]) torch$dot(a, b) #&gt; Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: dot: Expected 1-D argument self, but got 2-D # this is another way of performing dot product in PyTorch # a$dot(a) o1 &lt;- torch$ones(2L, 2L) o2 &lt;- torch$ones(2L, 2L) o1 #&gt; tensor([[1., 1.], #&gt; [1., 1.]]) o2 #&gt; tensor([[1., 1.], #&gt; [1., 1.]]) torch$dot(o1, o2) #&gt; Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: dot: Expected 1-D argument self, but got 2-D o1$dot(o2) #&gt; Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: dot: Expected 1-D argument self, but got 2-D # 1D tensors work fine r = torch$dot(torch$Tensor(list(4L, 2L, 4L)), torch$Tensor(list(3L, 4L, 1L))) r #&gt; tensor(24.) ## mm and matmul seem to address the dot product we are looking for in tensors a = torch$randn(2L, 3L) b = torch$randn(3L, 4L) a$mm(b) #&gt; tensor([[ 0.4831, 5.2706, -0.1190, 0.8763], #&gt; [ 2.2925, 1.7585, 2.0201, -0.2098]]) a$matmul(b) #&gt; tensor([[ 0.4831, 5.2706, -0.1190, 0.8763], #&gt; [ 2.2925, 1.7585, 2.0201, -0.2098]]) Here is agood explanation: https://stackoverflow.com/a/44525687/5270873 abt &lt;- torch$mm(a, b)$transpose(dim0=0L, dim1=1L) abt #&gt; tensor([[ 0.4831, 2.2925], #&gt; [ 5.2706, 1.7585], #&gt; [-0.1190, 2.0201], #&gt; [ 0.8763, -0.2098]]) at &lt;- a$transpose(dim0=0L, dim1=1L) bt &lt;- b$transpose(dim0=0L, dim1=1L) btat &lt;- torch$matmul(bt, at) btat #&gt; tensor([[ 0.4831, 2.2925], #&gt; [ 5.2706, 1.7585], #&gt; [-0.1190, 2.0201], #&gt; [ 0.8763, -0.2098]]) \\[(A B)^T = B^T A^T\\] # tolerance torch$allclose(abt, btat, rtol=0.0001) #&gt; [1] TRUE "],
["linear-regression.html", "Chapter 6 Linear Regression 6.1 Case 1: simple linear regression 6.2 Case 2: Rainfall", " Chapter 6 Linear Regression 6.1 Case 1: simple linear regression Source: https://www.guru99.com/pytorch-tutorial.html 6.1.1 Creating the network model Our network model is a simple Linear layer with an input and an output shape of one. And the network output should be like this Net( (hidden): Linear(in_features=1, out_features=1, bias=True) ) library(rTorch) nn &lt;- torch$nn Variable &lt;- torch$autograd$Variable torch$manual_seed(123) #&gt; &lt;torch._C.Generator&gt; py_run_string(&quot;import torch&quot;) main = py_run_string( &quot; import torch.nn as nn class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.layer = torch.nn.Linear(1, 1) def forward(self, x): x = self.layer(x) return x &quot;) # build a Linear Rgression model net &lt;- main$Net() print(net) #&gt; Net( #&gt; (layer): Linear(in_features=1, out_features=1, bias=True) #&gt; ) 6.1.2 Datasets Before you start the training process, you need to know our data. You make a random function to test our model. \\(Y = x3 sin(x)+ 3x+0.8 rand(100)\\) np$random$seed(123L) x = np$random$rand(100L) y = np$sin(x) * np$power(x, 3L) + 3L * x + np$random$rand(100L) * 0.8 plot(x, y) Before you start the training process, you need to convert the numpy array to Variables that supported by Torch and autograd. 6.1.3 Converting from numpy to tensor Notice that before converting to a Torch tensor, we need first to convert the R numeric vector to a numpy array: # convert numpy array to tensor in shape of input size x &lt;- r_to_py(x) y &lt;- r_to_py(y) x = torch$from_numpy(x$reshape(-1L, 1L))$float() y = torch$from_numpy(y$reshape(-1L, 1L))$float() print(x, y) #&gt; tensor([[0.6965], #&gt; [0.2861], #&gt; [0.2269], #&gt; [0.5513], #&gt; [0.7195], #&gt; [0.4231], #&gt; [0.9808], #&gt; [0.6848], #&gt; [0.4809], #&gt; [0.3921], #&gt; [0.3432], #&gt; [0.7290], #&gt; [0.4386], #&gt; [0.0597], #&gt; [0.3980], #&gt; [0.7380], #&gt; [0.1825], #&gt; [0.1755], #&gt; [0.5316], #&gt; [0.5318], #&gt; [0.6344], #&gt; [0.8494], #&gt; [0.7245], #&gt; [0.6110], #&gt; [0.7224], #&gt; [0.3230], #&gt; [0.3618], #&gt; [0.2283], #&gt; [0.2937], #&gt; [0.6310], #&gt; [0.0921], #&gt; [0.4337], #&gt; [0.4309], #&gt; [0.4937], #&gt; [0.4258], #&gt; [0.3123], #&gt; [0.4264], #&gt; [0.8934], #&gt; [0.9442], #&gt; [0.5018], #&gt; [0.6240], #&gt; [0.1156], #&gt; [0.3173], #&gt; [0.4148], #&gt; [0.8663], #&gt; [0.2505], #&gt; [0.4830], #&gt; [0.9856], #&gt; [0.5195], #&gt; [0.6129], #&gt; [0.1206], #&gt; [0.8263], #&gt; [0.6031], #&gt; [0.5451], #&gt; [0.3428], #&gt; [0.3041], #&gt; [0.4170], #&gt; [0.6813], #&gt; [0.8755], #&gt; [0.5104], #&gt; [0.6693], #&gt; [0.5859], #&gt; [0.6249], #&gt; [0.6747], #&gt; [0.8423], #&gt; [0.0832], #&gt; [0.7637], #&gt; [0.2437], #&gt; [0.1942], #&gt; [0.5725], #&gt; [0.0957], #&gt; [0.8853], #&gt; [0.6272], #&gt; [0.7234], #&gt; [0.0161], #&gt; [0.5944], #&gt; [0.5568], #&gt; [0.1590], #&gt; [0.1531], #&gt; [0.6955], #&gt; [0.3188], #&gt; [0.6920], #&gt; [0.5544], #&gt; [0.3890], #&gt; [0.9251], #&gt; [0.8417], #&gt; [0.3574], #&gt; [0.0436], #&gt; [0.3048], #&gt; [0.3982], #&gt; [0.7050], #&gt; [0.9954], #&gt; [0.3559], #&gt; [0.7625], #&gt; [0.5932], #&gt; [0.6917], #&gt; [0.1511], #&gt; [0.3989], #&gt; [0.2409], #&gt; [0.3435]]) 6.1.4 Optimizer and Loss Next, you should define the Optimizer and the Loss Function for our training process. # Define Optimizer and Loss Function optimizer &lt;- torch$optim$SGD(net$parameters(), lr=0.2) loss_func &lt;- torch$nn$MSELoss() print(optimizer) #&gt; SGD ( #&gt; Parameter Group 0 #&gt; dampening: 0 #&gt; lr: 0.2 #&gt; momentum: 0 #&gt; nesterov: False #&gt; weight_decay: 0 #&gt; ) print(loss_func) #&gt; MSELoss() 6.1.5 Training Now let’s start our training process. With an epoch of 250, you will iterate our data to find the best value for our hyperparameters. # x = x$type(torch$float) # make it a a FloatTensor # y = y$type(torch$float) # x &lt;- torch$as_tensor(x, dtype = torch$float) # y &lt;- torch$as_tensor(y, dtype = torch$float) inputs = Variable(x) outputs = Variable(y) # base plot plot(x$data$numpy(), y$data$numpy(), col = &quot;blue&quot;) for (i in 1:250) { prediction = net(inputs) loss = loss_func(prediction, outputs) optimizer$zero_grad() loss$backward() optimizer$step() if (i &gt; 1) break if (i %% 10 == 0) { # plot and show learning process # points(x$data$numpy(), y$data$numpy()) points(x$data$numpy(), prediction$data$numpy(), col=&quot;red&quot;) # cat(i, loss$data$numpy(), &quot;\\n&quot;) } } 6.1.6 Result As you can see below, you successfully performed regression with a neural network. Actually, on every iteration, the red line in the plot will update and change its position to fit the data. But in this picture, you only show you the final result. 6.2 Case 2: Rainfall library(rTorch) 6.2.1 Select device torch$manual_seed(0) #&gt; &lt;torch._C.Generator&gt; device = torch$device(&#39;cpu&#39;) 6.2.2 Training data The training data can be represented using 2 matrices (inputs and targets), each with one row per observation, and one column per variable. # Input (temp, rainfall, humidity) inputs = np$array(list(list(73, 67, 43), list(91, 88, 64), list(87, 134, 58), list(102, 43, 37), list(69, 96, 70)), dtype=&#39;float32&#39;) # Targets (apples, oranges) targets = np$array(list(list(56, 70), list(81, 101), list(119, 133), list(22, 37), list(103, 119)), dtype=&#39;float32&#39;) 6.2.3 Convert to tensors Before we build a model, we need to convert inputs and targets to PyTorch tensors. # Convert inputs and targets to tensors inputs = torch$from_numpy(inputs) targets = torch$from_numpy(targets) print(inputs) #&gt; tensor([[ 73., 67., 43.], #&gt; [ 91., 88., 64.], #&gt; [ 87., 134., 58.], #&gt; [102., 43., 37.], #&gt; [ 69., 96., 70.]], dtype=torch.float64) print(targets) #&gt; tensor([[ 56., 70.], #&gt; [ 81., 101.], #&gt; [119., 133.], #&gt; [ 22., 37.], #&gt; [103., 119.]], dtype=torch.float64) The weights and biases can also be represented as matrices, initialized with random values. The first row of \\(w\\) and the first element of \\(b\\) are used to predict the first target variable, i.e. yield for apples, and, similarly, the second for oranges. # random numbers for weights and biases. Then convert to double() torch$set_default_dtype(torch$double) w = torch$randn(2L, 3L, requires_grad=TRUE) #$double() b = torch$randn(2L, requires_grad=TRUE) #$double() print(w) #&gt; tensor([[ 1.5410, -0.2934, -2.1788], #&gt; [ 0.5684, -1.0845, -1.3986]], requires_grad=True) print(b) #&gt; tensor([0.4033, 0.8380], requires_grad=True) 6.2.4 Build the model The model is simply a function that performs a matrix multiplication of the input \\(x\\) and the weights \\(w\\) (transposed), and adds the bias \\(b\\) (replicated for each observation). model &lt;- function(x) { wt &lt;- w$t() return(torch$add(torch$mm(x, wt), b)) } 6.2.5 Generate predictions The matrix obtained by passing the input data to the model is a set of predictions for the target variables. # Generate predictions preds = model(inputs) print(preds) #&gt; tensor([[ -0.4516, -90.4691], #&gt; [ -24.6303, -132.3828], #&gt; [ -31.2192, -176.1530], #&gt; [ 64.3523, -39.5645], #&gt; [ -73.9524, -161.9560]], grad_fn=&lt;AddBackward0&gt;) # Compare with targets print(targets) #&gt; tensor([[ 56., 70.], #&gt; [ 81., 101.], #&gt; [119., 133.], #&gt; [ 22., 37.], #&gt; [103., 119.]]) Because we’ve started with random weights and biases, the model does not a very good job of predicting the target variables. 6.2.6 Loss Function We can compare the predictions with the actual targets, using the following method: Calculate the difference between the two matrices (preds and targets). Square all elements of the difference matrix to remove negative values. Calculate the average of the elements in the resulting matrix. The result is a single number, known as the mean squared error (MSE). # MSE loss mse = function(t1, t2) { diff &lt;- torch$sub(t1, t2) mul &lt;- torch$sum(torch$mul(diff, diff)) return(torch$div(mul, diff$numel())) } # Compute loss loss = mse(preds, targets) print(loss) #&gt; tensor(33060.8053, grad_fn=&lt;DivBackward0&gt;) # 46194 # 33060.8070 The resulting number is called the loss, because it indicates how bad the model is at predicting the target variables. Lower the loss, better the model. 6.2.7 Compute Gradients With PyTorch, we can automatically compute the gradient or derivative of the loss w.r.t. to the weights and biases, because they have requires_grad set to True. # Compute gradients loss$backward() The gradients are stored in the .grad property of the respective tensors. # Gradients for weights print(w) #&gt; tensor([[ 1.5410, -0.2934, -2.1788], #&gt; [ 0.5684, -1.0845, -1.3986]], requires_grad=True) print(w$grad) #&gt; tensor([[ -6938.4351, -9674.6757, -5744.0206], #&gt; [-17408.7861, -20595.9333, -12453.4702]]) # Gradients for bias print(b) #&gt; tensor([0.4033, 0.8380], requires_grad=True) print(b$grad) #&gt; tensor([ -89.3802, -212.1051]) A key insight from calculus is that the gradient indicates the rate of change of the loss, or the slope of the loss function w.r.t. the weights and biases. If a gradient element is positive: increasing the element’s value slightly will increase the loss. decreasing the element’s value slightly will decrease the loss. If a gradient element is negative, increasing the element’s value slightly will decrease the loss. decreasing the element’s value slightly will increase the loss. The increase or decrease is proportional to the value of the gradient. Finally, we’ll reset the gradients to zero before moving forward, because PyTorch accumulates gradients. # Reset the gradients w$grad$zero_() #&gt; tensor([[0., 0., 0.], #&gt; [0., 0., 0.]]) b$grad$zero_() #&gt; tensor([0., 0.]) print(w$grad) #&gt; tensor([[0., 0., 0.], #&gt; [0., 0., 0.]]) print(b$grad) #&gt; tensor([0., 0.]) 6.2.8 Adjust weights and biases using gradient descent We’ll reduce the loss and improve our model using the gradient descent algorithm, which has the following steps: Generate predictions Calculate the loss Compute gradients w.r.t the weights and biases Adjust the weights by subtracting a small quantity proportional to the gradient Reset the gradients to zero # Generate predictions preds = model(inputs) print(preds) #&gt; tensor([[ -0.4516, -90.4691], #&gt; [ -24.6303, -132.3828], #&gt; [ -31.2192, -176.1530], #&gt; [ 64.3523, -39.5645], #&gt; [ -73.9524, -161.9560]], grad_fn=&lt;AddBackward0&gt;) # Calculate the loss loss = mse(preds, targets) print(loss) #&gt; tensor(33060.8053, grad_fn=&lt;DivBackward0&gt;) # Compute gradients loss$backward() print(w$grad) #&gt; tensor([[ -6938.4351, -9674.6757, -5744.0206], #&gt; [-17408.7861, -20595.9333, -12453.4702]]) print(b$grad) #&gt; tensor([ -89.3802, -212.1051]) # Adjust weights and reset gradients with(torch$no_grad(), { print(w); print(b) # requires_grad attribute remains w$data &lt;- torch$sub(w$data, torch$mul(w$grad$data, torch$scalar_tensor(1e-5))) b$data &lt;- torch$sub(b$data, torch$mul(b$grad$data, torch$scalar_tensor(1e-5))) print(w$grad$data$zero_()) print(b$grad$data$zero_()) }) #&gt; tensor([[ 1.5410, -0.2934, -2.1788], #&gt; [ 0.5684, -1.0845, -1.3986]], requires_grad=True) #&gt; tensor([0.4033, 0.8380], requires_grad=True) #&gt; tensor([[0., 0., 0.], #&gt; [0., 0., 0.]]) #&gt; tensor([0., 0.]) print(w) #&gt; tensor([[ 1.6104, -0.1967, -2.1213], #&gt; [ 0.7425, -0.8786, -1.2741]], requires_grad=True) print(b) #&gt; tensor([0.4042, 0.8401], requires_grad=True) With the new weights and biases, the model should have a lower loss. # Calculate loss preds = model(inputs) loss = mse(preds, targets) print(loss) #&gt; tensor(23432.4894, grad_fn=&lt;DivBackward0&gt;) 6.2.9 Train for multiple epochs To reduce the loss further, we repeat the process of adjusting the weights and biases using the gradients multiple times. Each iteration is called an epoch. # Running all together # Adjust weights and reset gradients for (i in 1:100) { preds = model(inputs) loss = mse(preds, targets) loss$backward() with(torch$no_grad(), { w$data &lt;- torch$sub(w$data, torch$mul(w$grad, torch$scalar_tensor(1e-5))) b$data &lt;- torch$sub(b$data, torch$mul(b$grad, torch$scalar_tensor(1e-5))) w$grad$zero_() b$grad$zero_() }) } # Calculate loss preds = model(inputs) loss = mse(preds, targets) print(loss) #&gt; tensor(1258.0216, grad_fn=&lt;DivBackward0&gt;) # predictions preds #&gt; tensor([[ 69.2462, 80.2082], #&gt; [ 73.7183, 97.2052], #&gt; [118.5780, 124.9272], #&gt; [ 89.2282, 92.7052], #&gt; [ 47.4648, 80.7782]], grad_fn=&lt;AddBackward0&gt;) # Targets targets #&gt; tensor([[ 56., 70.], #&gt; [ 81., 101.], #&gt; [119., 133.], #&gt; [ 22., 37.], #&gt; [103., 119.]]) "],
["logistic-regression.html", "Chapter 7 Logistic Regression 7.1 Example 1: MNIST handwritten digits", " Chapter 7 Logistic Regression library(rTorch) nn &lt;- torch$nn transforms &lt;- torchvision$transforms torch$set_default_dtype(torch$float) 7.1 Example 1: MNIST handwritten digits 7.1.1 Hyperparameters # Hyper-parameters input_size &lt;- 784L num_classes &lt;- 10L num_epochs &lt;- 5L batch_size &lt;- 100L learning_rate &lt;- 0.001 7.1.2 Read datasets # MNIST dataset (images and labels) # IDX format local_folder &lt;- &#39;../datasets/raw_data&#39; train_dataset = torchvision$datasets$MNIST(root=local_folder, train=TRUE, transform=transforms$ToTensor(), download=TRUE) test_dataset = torchvision$datasets$MNIST(root=local_folder, train=FALSE, transform=transforms$ToTensor()) # Data loader (input pipeline) train_loader = torch$utils$data$DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=TRUE) test_loader = torch$utils$data$DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=FALSE) class(train_loader) #&gt; [1] &quot;torch.utils.data.dataloader.DataLoader&quot; #&gt; [2] &quot;python.builtin.object&quot; length(train_loader) #&gt; [1] 2 7.1.3 Define the model # Logistic regression model model = nn$Linear(input_size, num_classes) # Loss and optimizer # nn.CrossEntropyLoss() computes softmax internally criterion = nn$CrossEntropyLoss() optimizer = torch$optim$SGD(model$parameters(), lr=learning_rate) print(model) #&gt; Linear(in_features=784, out_features=10, bias=True) 7.1.4 Training # Train the model iter_train_loader &lt;- iterate(train_loader) total_step &lt;-length(iter_train_loader) for (epoch in 1:num_epochs) { i &lt;- 0 for (obj in iter_train_loader) { images &lt;- obj[[1]] # tensor torch.Size([64, 3, 28, 28]) labels &lt;- obj[[2]] # tensor torch.Size([64]), labels from 0 to 9 # cat(i, &quot;\\t&quot;); print(images$shape) # Reshape images to (batch_size, input_size) images &lt;- images$reshape(-1L, 28L*28L) # images &lt;- torch$as_tensor(images$reshape(-1L, 28L*28L), dtype=torch$double) # Forward pass outputs &lt;- model(images) loss &lt;- criterion(outputs, labels) # Backward and optimize optimizer$zero_grad() loss$backward() optimizer$step() if ((i+1) %% 100 == 0) { cat(sprintf(&#39;Epoch [%d/%d], Step [%d/%d], Loss: %f \\n&#39;, epoch+1, num_epochs, i+1, total_step, loss$item())) } i &lt;- i + 1 } } #&gt; Epoch [2/5], Step [100/600], Loss: 2.174462 #&gt; Epoch [2/5], Step [200/600], Loss: 2.109377 #&gt; Epoch [2/5], Step [300/600], Loss: 2.025454 #&gt; Epoch [2/5], Step [400/600], Loss: 1.901923 #&gt; Epoch [2/5], Step [500/600], Loss: 1.889262 #&gt; Epoch [2/5], Step [600/600], Loss: 1.856338 #&gt; Epoch [3/5], Step [100/600], Loss: 1.659917 #&gt; Epoch [3/5], Step [200/600], Loss: 1.658874 #&gt; Epoch [3/5], Step [300/600], Loss: 1.649795 #&gt; Epoch [3/5], Step [400/600], Loss: 1.503465 #&gt; Epoch [3/5], Step [500/600], Loss: 1.522077 #&gt; Epoch [3/5], Step [600/600], Loss: 1.562645 #&gt; Epoch [4/5], Step [100/600], Loss: 1.346662 #&gt; Epoch [4/5], Step [200/600], Loss: 1.376837 #&gt; Epoch [4/5], Step [300/600], Loss: 1.413276 #&gt; Epoch [4/5], Step [400/600], Loss: 1.245952 #&gt; Epoch [4/5], Step [500/600], Loss: 1.282574 #&gt; Epoch [4/5], Step [600/600], Loss: 1.365682 #&gt; Epoch [5/5], Step [100/600], Loss: 1.142479 #&gt; Epoch [5/5], Step [200/600], Loss: 1.194964 #&gt; Epoch [5/5], Step [300/600], Loss: 1.257039 #&gt; Epoch [5/5], Step [400/600], Loss: 1.075126 #&gt; Epoch [5/5], Step [500/600], Loss: 1.121401 #&gt; Epoch [5/5], Step [600/600], Loss: 1.227914 #&gt; Epoch [6/5], Step [100/600], Loss: 1.002284 #&gt; Epoch [6/5], Step [200/600], Loss: 1.071919 #&gt; Epoch [6/5], Step [300/600], Loss: 1.148576 #&gt; Epoch [6/5], Step [400/600], Loss: 0.956691 #&gt; Epoch [6/5], Step [500/600], Loss: 1.007319 #&gt; Epoch [6/5], Step [600/600], Loss: 1.127370 7.1.5 Prediction # Adjust weights and reset gradients iter_test_loader &lt;- iterate(test_loader) with(torch$no_grad(), { correct &lt;- 0 total &lt;- 0 for (obj in iter_test_loader) { images &lt;- obj[[1]] # tensor torch.Size([64, 3, 28, 28]) labels &lt;- obj[[2]] # tensor torch.Size([64]), labels from 0 to 9 images = images$reshape(-1L, 28L*28L) # images &lt;- torch$as_tensor(images$reshape(-1L, 28L*28L), dtype=torch$double) outputs = model(images) .predicted = torch$max(outputs$data, 1L) predicted &lt;- .predicted[1L] total = total + labels$size(0L) correct = correct + sum((predicted$numpy() == labels$numpy())) } cat(sprintf(&#39;Accuracy of the model on the 10000 test images: %f %%&#39;, (100 * correct / total))) }) #&gt; Accuracy of the model on the 10000 test images: 82.690000 % 7.1.6 Save the model # Save the model checkpoint torch$save(model$state_dict(), &#39;model.ckpt&#39;) "],
["neural-networks.html", "Chapter 8 Neural Networks 8.1 Code in rTorch", " Chapter 8 Neural Networks Source: https://github.com/jcjohnson/pytorch-examples#pytorch-nn In this example we use the torch nn package to implement our two-layer network: 8.1 Code in rTorch 8.1.1 Select device library(rTorch) device = torch$device(&#39;cpu&#39;) # device = torch.device(&#39;cuda&#39;) # Uncomment this to run on GPU N is batch size; D_in is input dimension; H is hidden dimension; D_out is output dimension. 8.1.2 Create the datasets torch$manual_seed(0) #&gt; &lt;torch._C.Generator&gt; N &lt;- 64L; D_in &lt;- 1000L; H &lt;- 100L; D_out &lt;- 10L # Create random Tensors to hold inputs and outputs x = torch$randn(N, D_in, device=device) y = torch$randn(N, D_out, device=device) 8.1.3 Define the model Use the nn package to define our model as a sequence of layers. nn.Sequential is a Module which contains other Modules, and applies them in sequence to produce its output. Each Linear Module computes output from input using a linear function, and holds internal Tensors for its weight and bias. After constructing the model we use the .to() method to move it to the desired device. model &lt;- torch$nn$Sequential( torch$nn$Linear(D_in, H), # first layer torch$nn$ReLU(), torch$nn$Linear(H, D_out))$to(device) # output layer 8.1.4 Loss function The nn package also contains definitions of popular loss functions; in this case we will use Mean Squared Error (MSE) as our loss function. Setting reduction='sum' means that we are computing the sum of squared errors rather than the mean; this is for consistency with the examples above where we manually compute the loss, but in practice it is more common to use mean squared error as a loss by setting reduction='elementwise_mean'. loss_fn = torch$nn$MSELoss(reduction = &#39;sum&#39;) 8.1.5 Iterate through batches learning_rate = 1e-4 for (t in 1:500) { # Forward pass: compute predicted y by passing x to the model. Module objects # override the __call__ operator so you can call them like functions. When # doing so you pass a Tensor of input data to the Module and it produces # a Tensor of output data. y_pred = model(x) # Compute and print loss. We pass Tensors containing the predicted and true # values of y, and the loss function returns a Tensor containing the loss. loss = loss_fn(y_pred, y) cat(t, &quot;\\t&quot;) cat(loss$item(), &quot;\\n&quot;) # Zero the gradients before running the backward pass. model$zero_grad() # Backward pass: compute gradient of the loss with respect to all the learnable # parameters of the model. Internally, the parameters of each Module are stored # in Tensors with requires_grad=True, so this call will compute gradients for # all learnable parameters in the model. loss$backward() # Update the weights using gradient descent. Each parameter is a Tensor, so # we can access its data and gradients like we did before. with(torch$no_grad(), { for (param in iterate(model$parameters())) { # in Python this code is much simpler. In R we have to do some conversions # param$data &lt;- torch$sub(param$data, # torch$mul(param$grad$float(), # torch$scalar_tensor(learning_rate))) param$data &lt;- param$data - param$grad * learning_rate } }) } #&gt; 1 628 #&gt; 2 585 #&gt; 3 547 #&gt; 4 513 #&gt; 5 482 #&gt; 6 455 #&gt; 7 430 #&gt; 8 406 #&gt; 9 385 #&gt; 10 364 #&gt; 11 345 #&gt; 12 328 #&gt; 13 311 #&gt; 14 295 #&gt; 15 280 #&gt; 16 265 #&gt; 17 252 #&gt; 18 239 #&gt; 19 226 #&gt; 20 214 #&gt; 21 203 #&gt; 22 192 #&gt; 23 181 #&gt; 24 172 #&gt; 25 162 #&gt; 26 153 #&gt; 27 145 #&gt; 28 137 #&gt; 29 129 #&gt; 30 122 #&gt; 31 115 #&gt; 32 109 #&gt; 33 103 #&gt; 34 96.9 #&gt; 35 91.5 #&gt; 36 86.3 #&gt; 37 81.5 #&gt; 38 76.9 #&gt; 39 72.6 #&gt; 40 68.5 #&gt; 41 64.6 #&gt; 42 61 #&gt; 43 57.6 #&gt; 44 54.3 #&gt; 45 51.3 #&gt; 46 48.5 #&gt; 47 45.8 #&gt; 48 43.2 #&gt; 49 40.9 #&gt; 50 38.6 #&gt; 51 36.5 #&gt; 52 34.5 #&gt; 53 32.7 #&gt; 54 30.9 #&gt; 55 29.3 #&gt; 56 27.8 #&gt; 57 26.3 #&gt; 58 24.9 #&gt; 59 23.7 #&gt; 60 22.4 #&gt; 61 21.3 #&gt; 62 20.2 #&gt; 63 19.2 #&gt; 64 18.2 #&gt; 65 17.3 #&gt; 66 16.5 #&gt; 67 15.7 #&gt; 68 14.9 #&gt; 69 14.2 #&gt; 70 13.5 #&gt; 71 12.9 #&gt; 72 12.3 #&gt; 73 11.7 #&gt; 74 11.1 #&gt; 75 10.6 #&gt; 76 10.1 #&gt; 77 9.67 #&gt; 78 9.24 #&gt; 79 8.82 #&gt; 80 8.42 #&gt; 81 8.05 #&gt; 82 7.69 #&gt; 83 7.35 #&gt; 84 7.03 #&gt; 85 6.72 #&gt; 86 6.43 #&gt; 87 6.16 #&gt; 88 5.9 #&gt; 89 5.65 #&gt; 90 5.41 #&gt; 91 5.18 #&gt; 92 4.97 #&gt; 93 4.76 #&gt; 94 4.57 #&gt; 95 4.38 #&gt; 96 4.2 #&gt; 97 4.03 #&gt; 98 3.87 #&gt; 99 3.72 #&gt; 100 3.57 #&gt; 101 3.43 #&gt; 102 3.29 #&gt; 103 3.17 #&gt; 104 3.04 #&gt; 105 2.92 #&gt; 106 2.81 #&gt; 107 2.7 #&gt; 108 2.6 #&gt; 109 2.5 #&gt; 110 2.41 #&gt; 111 2.31 #&gt; 112 2.23 #&gt; 113 2.14 #&gt; 114 2.06 #&gt; 115 1.99 #&gt; 116 1.91 #&gt; 117 1.84 #&gt; 118 1.77 #&gt; 119 1.71 #&gt; 120 1.65 #&gt; 121 1.59 #&gt; 122 1.53 #&gt; 123 1.47 #&gt; 124 1.42 #&gt; 125 1.37 #&gt; 126 1.32 #&gt; 127 1.27 #&gt; 128 1.23 #&gt; 129 1.18 #&gt; 130 1.14 #&gt; 131 1.1 #&gt; 132 1.06 #&gt; 133 1.02 #&gt; 134 0.989 #&gt; 135 0.954 #&gt; 136 0.921 #&gt; 137 0.889 #&gt; 138 0.858 #&gt; 139 0.828 #&gt; 140 0.799 #&gt; 141 0.772 #&gt; 142 0.745 #&gt; 143 0.719 #&gt; 144 0.695 #&gt; 145 0.671 #&gt; 146 0.648 #&gt; 147 0.626 #&gt; 148 0.605 #&gt; 149 0.584 #&gt; 150 0.564 #&gt; 151 0.545 #&gt; 152 0.527 #&gt; 153 0.509 #&gt; 154 0.492 #&gt; 155 0.476 #&gt; 156 0.46 #&gt; 157 0.444 #&gt; 158 0.43 #&gt; 159 0.415 #&gt; 160 0.402 #&gt; 161 0.388 #&gt; 162 0.375 #&gt; 163 0.363 #&gt; 164 0.351 #&gt; 165 0.339 #&gt; 166 0.328 #&gt; 167 0.318 #&gt; 168 0.307 #&gt; 169 0.297 #&gt; 170 0.287 #&gt; 171 0.278 #&gt; 172 0.269 #&gt; 173 0.26 #&gt; 174 0.252 #&gt; 175 0.244 #&gt; 176 0.236 #&gt; 177 0.228 #&gt; 178 0.221 #&gt; 179 0.214 #&gt; 180 0.207 #&gt; 181 0.2 #&gt; 182 0.194 #&gt; 183 0.187 #&gt; 184 0.181 #&gt; 185 0.176 #&gt; 186 0.17 #&gt; 187 0.165 #&gt; 188 0.159 #&gt; 189 0.154 #&gt; 190 0.149 #&gt; 191 0.145 #&gt; 192 0.14 #&gt; 193 0.136 #&gt; 194 0.131 #&gt; 195 0.127 #&gt; 196 0.123 #&gt; 197 0.119 #&gt; 198 0.115 #&gt; 199 0.112 #&gt; 200 0.108 #&gt; 201 0.105 #&gt; 202 0.102 #&gt; 203 0.0983 #&gt; 204 0.0952 #&gt; 205 0.0923 #&gt; 206 0.0894 #&gt; 207 0.0866 #&gt; 208 0.0838 #&gt; 209 0.0812 #&gt; 210 0.0787 #&gt; 211 0.0762 #&gt; 212 0.0739 #&gt; 213 0.0716 #&gt; 214 0.0693 #&gt; 215 0.0672 #&gt; 216 0.0651 #&gt; 217 0.0631 #&gt; 218 0.0611 #&gt; 219 0.0592 #&gt; 220 0.0574 #&gt; 221 0.0556 #&gt; 222 0.0539 #&gt; 223 0.0522 #&gt; 224 0.0506 #&gt; 225 0.0491 #&gt; 226 0.0476 #&gt; 227 0.0461 #&gt; 228 0.0447 #&gt; 229 0.0433 #&gt; 230 0.042 #&gt; 231 0.0407 #&gt; 232 0.0394 #&gt; 233 0.0382 #&gt; 234 0.0371 #&gt; 235 0.0359 #&gt; 236 0.0348 #&gt; 237 0.0338 #&gt; 238 0.0327 #&gt; 239 0.0317 #&gt; 240 0.0308 #&gt; 241 0.0298 #&gt; 242 0.0289 #&gt; 243 0.028 #&gt; 244 0.0272 #&gt; 245 0.0263 #&gt; 246 0.0255 #&gt; 247 0.0248 #&gt; 248 0.024 #&gt; 249 0.0233 #&gt; 250 0.0226 #&gt; 251 0.0219 #&gt; 252 0.0212 #&gt; 253 0.0206 #&gt; 254 0.02 #&gt; 255 0.0194 #&gt; 256 0.0188 #&gt; 257 0.0182 #&gt; 258 0.0177 #&gt; 259 0.0171 #&gt; 260 0.0166 #&gt; 261 0.0161 #&gt; 262 0.0156 #&gt; 263 0.0151 #&gt; 264 0.0147 #&gt; 265 0.0142 #&gt; 266 0.0138 #&gt; 267 0.0134 #&gt; 268 0.013 #&gt; 269 0.0126 #&gt; 270 0.0122 #&gt; 271 0.0119 #&gt; 272 0.0115 #&gt; 273 0.0112 #&gt; 274 0.0108 #&gt; 275 0.0105 #&gt; 276 0.0102 #&gt; 277 0.00988 #&gt; 278 0.00959 #&gt; 279 0.0093 #&gt; 280 0.00902 #&gt; 281 0.00875 #&gt; 282 0.00849 #&gt; 283 0.00824 #&gt; 284 0.00799 #&gt; 285 0.00775 #&gt; 286 0.00752 #&gt; 287 0.0073 #&gt; 288 0.00708 #&gt; 289 0.00687 #&gt; 290 0.00666 #&gt; 291 0.00647 #&gt; 292 0.00627 #&gt; 293 0.00609 #&gt; 294 0.00591 #&gt; 295 0.00573 #&gt; 296 0.00556 #&gt; 297 0.0054 #&gt; 298 0.00524 #&gt; 299 0.00508 #&gt; 300 0.00493 #&gt; 301 0.00478 #&gt; 302 0.00464 #&gt; 303 0.0045 #&gt; 304 0.00437 #&gt; 305 0.00424 #&gt; 306 0.00412 #&gt; 307 0.00399 #&gt; 308 0.00388 #&gt; 309 0.00376 #&gt; 310 0.00365 #&gt; 311 0.00354 #&gt; 312 0.00344 #&gt; 313 0.00334 #&gt; 314 0.00324 #&gt; 315 0.00314 #&gt; 316 0.00305 #&gt; 317 0.00296 #&gt; 318 0.00287 #&gt; 319 0.00279 #&gt; 320 0.00271 #&gt; 321 0.00263 #&gt; 322 0.00255 #&gt; 323 0.00248 #&gt; 324 0.0024 #&gt; 325 0.00233 #&gt; 326 0.00226 #&gt; 327 0.0022 #&gt; 328 0.00213 #&gt; 329 0.00207 #&gt; 330 0.00201 #&gt; 331 0.00195 #&gt; 332 0.00189 #&gt; 333 0.00184 #&gt; 334 0.00178 #&gt; 335 0.00173 #&gt; 336 0.00168 #&gt; 337 0.00163 #&gt; 338 0.00158 #&gt; 339 0.00154 #&gt; 340 0.00149 #&gt; 341 0.00145 #&gt; 342 0.00141 #&gt; 343 0.00137 #&gt; 344 0.00133 #&gt; 345 0.00129 #&gt; 346 0.00125 #&gt; 347 0.00121 #&gt; 348 0.00118 #&gt; 349 0.00114 #&gt; 350 0.00111 #&gt; 351 0.00108 #&gt; 352 0.00105 #&gt; 353 0.00102 #&gt; 354 0.000987 #&gt; 355 0.000958 #&gt; 356 0.000931 #&gt; 357 0.000904 #&gt; 358 0.000877 #&gt; 359 0.000852 #&gt; 360 0.000827 #&gt; 361 0.000803 #&gt; 362 0.00078 #&gt; 363 0.000757 #&gt; 364 0.000735 #&gt; 365 0.000714 #&gt; 366 0.000693 #&gt; 367 0.000673 #&gt; 368 0.000654 #&gt; 369 0.000635 #&gt; 370 0.000617 #&gt; 371 0.000599 #&gt; 372 0.000581 #&gt; 373 0.000565 #&gt; 374 0.000548 #&gt; 375 0.000532 #&gt; 376 0.000517 #&gt; 377 0.000502 #&gt; 378 0.000488 #&gt; 379 0.000474 #&gt; 380 0.00046 #&gt; 381 0.000447 #&gt; 382 0.000434 #&gt; 383 0.000421 #&gt; 384 0.000409 #&gt; 385 0.000397 #&gt; 386 0.000386 #&gt; 387 0.000375 #&gt; 388 0.000364 #&gt; 389 0.000354 #&gt; 390 0.000343 #&gt; 391 0.000334 #&gt; 392 0.000324 #&gt; 393 0.000315 #&gt; 394 0.000306 #&gt; 395 0.000297 #&gt; 396 0.000288 #&gt; 397 0.00028 #&gt; 398 0.000272 #&gt; 399 0.000264 #&gt; 400 0.000257 #&gt; 401 0.000249 #&gt; 402 0.000242 #&gt; 403 0.000235 #&gt; 404 0.000228 #&gt; 405 0.000222 #&gt; 406 0.000216 #&gt; 407 0.000209 #&gt; 408 0.000203 #&gt; 409 0.000198 #&gt; 410 0.000192 #&gt; 411 0.000186 #&gt; 412 0.000181 #&gt; 413 0.000176 #&gt; 414 0.000171 #&gt; 415 0.000166 #&gt; 416 0.000161 #&gt; 417 0.000157 #&gt; 418 0.000152 #&gt; 419 0.000148 #&gt; 420 0.000144 #&gt; 421 0.00014 #&gt; 422 0.000136 #&gt; 423 0.000132 #&gt; 424 0.000128 #&gt; 425 0.000124 #&gt; 426 0.000121 #&gt; 427 0.000117 #&gt; 428 0.000114 #&gt; 429 0.000111 #&gt; 430 0.000108 #&gt; 431 0.000105 #&gt; 432 0.000102 #&gt; 433 9.87e-05 #&gt; 434 9.59e-05 #&gt; 435 9.32e-05 #&gt; 436 9.06e-05 #&gt; 437 8.8e-05 #&gt; 438 8.55e-05 #&gt; 439 8.31e-05 #&gt; 440 8.07e-05 #&gt; 441 7.84e-05 #&gt; 442 7.62e-05 #&gt; 443 7.41e-05 #&gt; 444 7.2e-05 #&gt; 445 6.99e-05 #&gt; 446 6.79e-05 #&gt; 447 6.6e-05 #&gt; 448 6.41e-05 #&gt; 449 6.23e-05 #&gt; 450 6.06e-05 #&gt; 451 5.89e-05 #&gt; 452 5.72e-05 #&gt; 453 5.56e-05 #&gt; 454 5.4e-05 #&gt; 455 5.25e-05 #&gt; 456 5.1e-05 #&gt; 457 4.96e-05 #&gt; 458 4.82e-05 #&gt; 459 4.68e-05 #&gt; 460 4.55e-05 #&gt; 461 4.42e-05 #&gt; 462 4.3e-05 #&gt; 463 4.18e-05 #&gt; 464 4.06e-05 #&gt; 465 3.94e-05 #&gt; 466 3.83e-05 #&gt; 467 3.72e-05 #&gt; 468 3.62e-05 #&gt; 469 3.52e-05 #&gt; 470 3.42e-05 #&gt; 471 3.32e-05 #&gt; 472 3.23e-05 #&gt; 473 3.14e-05 #&gt; 474 3.05e-05 #&gt; 475 2.96e-05 #&gt; 476 2.88e-05 #&gt; 477 2.8e-05 #&gt; 478 2.72e-05 #&gt; 479 2.65e-05 #&gt; 480 2.57e-05 #&gt; 481 2.5e-05 #&gt; 482 2.43e-05 #&gt; 483 2.36e-05 #&gt; 484 2.29e-05 #&gt; 485 2.23e-05 #&gt; 486 2.17e-05 #&gt; 487 2.11e-05 #&gt; 488 2.05e-05 #&gt; 489 1.99e-05 #&gt; 490 1.94e-05 #&gt; 491 1.88e-05 #&gt; 492 1.83e-05 #&gt; 493 1.78e-05 #&gt; 494 1.73e-05 #&gt; 495 1.68e-05 #&gt; 496 1.63e-05 #&gt; 497 1.59e-05 #&gt; 498 1.54e-05 #&gt; 499 1.5e-05 #&gt; 500 1.46e-05 These two expression are equivalent, with the first being the long version natural way of doing it in PyTorch. The second is using the generics in R for subtraction, multiplication and scalar conversion. param$data &lt;- torch$sub(param$data, torch$mul(param$grad$float(), torch$scalar_tensor(learning_rate))) } param$data &lt;- param$data - param$grad * learning_rate "],
["datasets-in-pytorch.html", "Chapter 9 Datasets in PyTorch", " Chapter 9 Datasets in PyTorch "],
["simple-regression-with-pytorch.html", "Chapter 10 Simple Regression with PyTorch 10.1 Creating the network model 10.2 Datasets 10.3 Optimizer and Loss 10.4 Training 10.5 Result", " Chapter 10 Simple Regression with PyTorch Source: https://www.guru99.com/pytorch-tutorial.html 10.1 Creating the network model Our network model is a simple Linear layer with an input and an output shape of 1. library(rTorch) from __future__ import print_function import torch import torch.nn as nn import torch.nn.functional as F from torch.autograd import Variable torch.manual_seed(123) #&gt; &lt;torch._C.Generator object at 0x7efd67342a70&gt; class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.layer = torch.nn.Linear(1, 1) def forward(self, x): x = self.layer(x) return x net = Net() print(net) #&gt; Net( #&gt; (layer): Linear(in_features=1, out_features=1, bias=True) #&gt; ) And the network output should be like this Net( (hidden): Linear(in_features=1, out_features=1, bias=True) ) 10.1.1 Code in R This would be the equivalent code in R: library(reticulate) #&gt; #&gt; Attaching package: &#39;reticulate&#39; #&gt; The following objects are masked from &#39;package:rTorch&#39;: #&gt; #&gt; conda_install, conda_python torch &lt;- import(&quot;torch&quot;) nn &lt;- import(&quot;torch.nn&quot;) Variable &lt;- import(&quot;torch.autograd&quot;)$Variable torch$manual_seed(123) #&gt; &lt;torch._C.Generator&gt; main = py_run_string( &quot; import torch.nn as nn class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.layer = torch.nn.Linear(1, 1) def forward(self, x): x = self.layer(x) return x &quot;) # build a Linear Rgression model net &lt;- main$Net() print(net) #&gt; Net( #&gt; (layer): Linear(in_features=1, out_features=1, bias=True) #&gt; ) 10.2 Datasets Before you start the training process, you need to know our data. You make a random function to test our model. \\(Y = x3 sin(x)+ 3x+0.8 rand(100)\\) # Visualize our data import matplotlib.pyplot as plt import numpy as np np.random.seed(123) x = np.random.rand(100) y = np.sin(x) * np.power(x,3) + 3*x + np.random.rand(100)*0.8 plt.scatter(x, y) plt.show() This is the code in R: np &lt;- import(&quot;numpy&quot;) np$random$seed(123L) x = np$random$rand(100L) y = np$sin(x) * np$power(x, 3L) + 3*x + np$random$rand(100L)*0.8 plot(x, y) Before you start the training process, you need to convert the numpy array to Variables that supported by Torch and autograd. # convert numpy array to tensor in shape of input size x = torch.from_numpy(x.reshape(-1,1)).float() y = torch.from_numpy(y.reshape(-1,1)).float() print(x, y) #&gt; tensor([[0.6965], #&gt; [0.2861], #&gt; [0.2269], #&gt; [0.5513], #&gt; [0.7195], #&gt; [0.4231], #&gt; [0.9808], #&gt; [0.6848], #&gt; [0.4809], #&gt; [0.3921], #&gt; [0.3432], #&gt; [0.7290], #&gt; [0.4386], #&gt; [0.0597], #&gt; [0.3980], #&gt; [0.7380], #&gt; [0.1825], #&gt; [0.1755], #&gt; [0.5316], #&gt; [0.5318], #&gt; [0.6344], #&gt; [0.8494], #&gt; [0.7245], #&gt; [0.6110], #&gt; [0.7224], #&gt; [0.3230], #&gt; [0.3618], #&gt; [0.2283], #&gt; [0.2937], #&gt; [0.6310], #&gt; [0.0921], #&gt; [0.4337], #&gt; [0.4309], #&gt; [0.4937], #&gt; [0.4258], #&gt; [0.3123], #&gt; [0.4264], #&gt; [0.8934], #&gt; [0.9442], #&gt; [0.5018], #&gt; [0.6240], #&gt; [0.1156], #&gt; [0.3173], #&gt; [0.4148], #&gt; [0.8663], #&gt; [0.2505], #&gt; [0.4830], #&gt; [0.9856], #&gt; [0.5195], #&gt; [0.6129], #&gt; [0.1206], #&gt; [0.8263], #&gt; [0.6031], #&gt; [0.5451], #&gt; [0.3428], #&gt; [0.3041], #&gt; [0.4170], #&gt; [0.6813], #&gt; [0.8755], #&gt; [0.5104], #&gt; [0.6693], #&gt; [0.5859], #&gt; [0.6249], #&gt; [0.6747], #&gt; [0.8423], #&gt; [0.0832], #&gt; [0.7637], #&gt; [0.2437], #&gt; [0.1942], #&gt; [0.5725], #&gt; [0.0957], #&gt; [0.8853], #&gt; [0.6272], #&gt; [0.7234], #&gt; [0.0161], #&gt; [0.5944], #&gt; [0.5568], #&gt; [0.1590], #&gt; [0.1531], #&gt; [0.6955], #&gt; [0.3188], #&gt; [0.6920], #&gt; [0.5544], #&gt; [0.3890], #&gt; [0.9251], #&gt; [0.8417], #&gt; [0.3574], #&gt; [0.0436], #&gt; [0.3048], #&gt; [0.3982], #&gt; [0.7050], #&gt; [0.9954], #&gt; [0.3559], #&gt; [0.7625], #&gt; [0.5932], #&gt; [0.6917], #&gt; [0.1511], #&gt; [0.3989], #&gt; [0.2409], #&gt; [0.3435]]) tensor([[2.7166], #&gt; [1.3983], #&gt; [0.7679], #&gt; [1.8464], #&gt; [2.6614], #&gt; [1.8297], #&gt; [4.4034], #&gt; [2.7003], #&gt; [2.1778], #&gt; [1.5073], #&gt; [1.2966], #&gt; [2.7287], #&gt; [1.4884], #&gt; [0.8423], #&gt; [1.4895], #&gt; [2.9263], #&gt; [1.0114], #&gt; [0.9445], #&gt; [1.6729], #&gt; [2.4624], #&gt; [2.7788], #&gt; [3.1746], #&gt; [2.6593], #&gt; [2.3800], #&gt; [3.1382], #&gt; [1.7665], #&gt; [1.3082], #&gt; [1.1390], #&gt; [1.5341], #&gt; [2.3566], #&gt; [0.8612], #&gt; [1.4642], #&gt; [1.8066], #&gt; [2.2308], #&gt; [2.0962], #&gt; [1.0096], #&gt; [1.6538], #&gt; [3.3994], #&gt; [3.8747], #&gt; [2.0045], #&gt; [2.0884], #&gt; [0.5845], #&gt; [1.7039], #&gt; [1.7285], #&gt; [3.4602], #&gt; [1.3581], #&gt; [2.0949], #&gt; [3.7935], #&gt; [2.1950], #&gt; [2.6425], #&gt; [0.4948], #&gt; [3.5188], #&gt; [2.1628], #&gt; [1.9643], #&gt; [1.5740], #&gt; [1.0099], #&gt; [1.8123], #&gt; [2.9534], #&gt; [3.6986], #&gt; [1.9485], #&gt; [2.5445], #&gt; [2.4811], #&gt; [2.4700], #&gt; [2.2838], #&gt; [3.4392], #&gt; [0.9015], #&gt; [2.8687], #&gt; [1.4766], #&gt; [1.1847], #&gt; [2.2782], #&gt; [0.8885], #&gt; [3.2565], #&gt; [2.7141], #&gt; [3.0781], #&gt; [0.7763], #&gt; [2.0038], #&gt; [1.8270], #&gt; [0.5882], #&gt; [0.7793], #&gt; [2.6416], #&gt; [1.4162], #&gt; [2.3851], #&gt; [1.9140], #&gt; [1.8385], #&gt; [3.7822], #&gt; [3.6160], #&gt; [1.0941], #&gt; [0.5721], #&gt; [1.6683], #&gt; [1.6848], #&gt; [2.5068], #&gt; [4.3876], #&gt; [1.3866], #&gt; [3.1286], #&gt; [1.9197], #&gt; [2.7949], #&gt; [0.4797], #&gt; [1.8171], #&gt; [1.1042], #&gt; [1.1414]]) 10.2.1 Code in R Notice that before converting to a Torch tensor, we need first to convert the R numeric vector to a numpy array: # convert numpy array to tensor in shape of input size x &lt;- r_to_py(x) y &lt;- r_to_py(y) x = torch$from_numpy(x$reshape(-1L, 1L)) #$float() y = torch$from_numpy(y$reshape(-1L, 1L)) #$float() print(x, y) #&gt; tensor([[0.6965], #&gt; [0.2861], #&gt; [0.2269], #&gt; [0.5513], #&gt; [0.7195], #&gt; [0.4231], #&gt; [0.9808], #&gt; [0.6848], #&gt; [0.4809], #&gt; [0.3921], #&gt; [0.3432], #&gt; [0.7290], #&gt; [0.4386], #&gt; [0.0597], #&gt; [0.3980], #&gt; [0.7380], #&gt; [0.1825], #&gt; [0.1755], #&gt; [0.5316], #&gt; [0.5318], #&gt; [0.6344], #&gt; [0.8494], #&gt; [0.7245], #&gt; [0.6110], #&gt; [0.7224], #&gt; [0.3230], #&gt; [0.3618], #&gt; [0.2283], #&gt; [0.2937], #&gt; [0.6310], #&gt; [0.0921], #&gt; [0.4337], #&gt; [0.4309], #&gt; [0.4937], #&gt; [0.4258], #&gt; [0.3123], #&gt; [0.4264], #&gt; [0.8934], #&gt; [0.9442], #&gt; [0.5018], #&gt; [0.6240], #&gt; [0.1156], #&gt; [0.3173], #&gt; [0.4148], #&gt; [0.8663], #&gt; [0.2505], #&gt; [0.4830], #&gt; [0.9856], #&gt; [0.5195], #&gt; [0.6129], #&gt; [0.1206], #&gt; [0.8263], #&gt; [0.6031], #&gt; [0.5451], #&gt; [0.3428], #&gt; [0.3041], #&gt; [0.4170], #&gt; [0.6813], #&gt; [0.8755], #&gt; [0.5104], #&gt; [0.6693], #&gt; [0.5859], #&gt; [0.6249], #&gt; [0.6747], #&gt; [0.8423], #&gt; [0.0832], #&gt; [0.7637], #&gt; [0.2437], #&gt; [0.1942], #&gt; [0.5725], #&gt; [0.0957], #&gt; [0.8853], #&gt; [0.6272], #&gt; [0.7234], #&gt; [0.0161], #&gt; [0.5944], #&gt; [0.5568], #&gt; [0.1590], #&gt; [0.1531], #&gt; [0.6955], #&gt; [0.3188], #&gt; [0.6920], #&gt; [0.5544], #&gt; [0.3890], #&gt; [0.9251], #&gt; [0.8417], #&gt; [0.3574], #&gt; [0.0436], #&gt; [0.3048], #&gt; [0.3982], #&gt; [0.7050], #&gt; [0.9954], #&gt; [0.3559], #&gt; [0.7625], #&gt; [0.5932], #&gt; [0.6917], #&gt; [0.1511], #&gt; [0.3989], #&gt; [0.2409], #&gt; [0.3435]], dtype=torch.float64) 10.3 Optimizer and Loss Next, you should define the Optimizer and the Loss Function for our training process. # Define Optimizer and Loss Function optimizer = torch.optim.SGD(net.parameters(), lr=0.2) loss_func = torch.nn.MSELoss() print(optimizer) #&gt; SGD ( #&gt; Parameter Group 0 #&gt; dampening: 0 #&gt; lr: 0.2 #&gt; momentum: 0 #&gt; nesterov: False #&gt; weight_decay: 0 #&gt; ) print(loss_func) #&gt; MSELoss() 10.3.1 Equivalent code in R # Define Optimizer and Loss Function optimizer &lt;- torch$optim$SGD(net$parameters(), lr=0.2) loss_func &lt;- torch$nn$MSELoss() print(optimizer) #&gt; SGD ( #&gt; Parameter Group 0 #&gt; dampening: 0 #&gt; lr: 0.2 #&gt; momentum: 0 #&gt; nesterov: False #&gt; weight_decay: 0 #&gt; ) print(loss_func) #&gt; MSELoss() 10.4 Training 10.4.1 Code in Python Now let’s start our training process. With an epoch of 250, you will iterate our data to find the best value for our hyperparameters. inputs = Variable(x) outputs = Variable(y) for i in range(250): prediction = net(inputs) loss = loss_func(prediction, outputs) optimizer.zero_grad() loss.backward() optimizer.step() if i % 10 == 0: # plot and show learning process plt.cla() plt.scatter(x.data.numpy(), y.data.numpy()) plt.plot(x.data.numpy(), prediction.data.numpy(), &#39;r-&#39;, lw=2) plt.text(0.5, 0, &#39;Loss=%.4f&#39; % loss.data.numpy(), fontdict={&#39;size&#39;: 10, &#39;color&#39;: &#39;red&#39;}) plt.pause(0.1) plt.show() 10.4.2 Code in R x = x$type(torch$FloatTensor) # make it a a FloatTensor y = y$type(torch$FloatTensor) inputs = Variable(x) outputs = Variable(y) plot(x$data$numpy(), y$data$numpy(), col = &quot;blue&quot;) for (i in 1:250) { prediction = net(inputs) loss = loss_func(prediction, outputs) optimizer$zero_grad() loss$backward() optimizer$step() if (i %% 10 == 0) { # plot and show learning process # points(x$data$numpy(), y$data$numpy()) points(x$data$numpy(), prediction$data$numpy(), col=&quot;red&quot;) # cat(i, loss$data$numpy(), &quot;\\n&quot;) } } 10.5 Result As you can see below, you successfully performed regression with a neural network. Actually, on every iteration, the red line in the plot will update and change its position to fit the data. But in this picture, you only show you the final result "],
["bookdown-tips.html", "Bookdown tips Label references Figures and Tables with references Long captions Citations and Bibiliography", " Bookdown tips Label references You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter 2. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter 5. Note. For the labels, do not use underscore _ or dash -; they will confuse bookdown referencing. Example: avoid linear_algebra or linear-algebra as labels. Preferrably, use one word. Figures and Tables with references Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 10.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 10.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 10.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 10.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa Long captions If you have a long caption with Latex included maybe is a good idea to write the caption as a separate paragraph, outside the Rmarkdown chunk. Just like this: (ref:ALongCaption) **A base plot of pressure vs. temperature**. This plot shows the pressure readings at different temperatures. The initial temperature, $t_0$, is nearer to the intersection of the axis. Then, in the caption reference copy the tag (ref:ALongCaption) enclosing it in quotes or single quotes. Figure 10.2: A base plot of pressure vs. temperature. This plot shows the pressure readings at different temperatures. The initial temperature, \\(t_0\\), is nearer to the intersection of the axis. With tables, do the same with long captions. (ref:TabLongCaption) The following table shows the numerical data for the sepal and petal measurements. And then insert the tag reference where the caption should go enclosed in quotes or single quotes. Table 10.2: The following table shows the numerical data for the sepal and petal measurements. Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa Citations and Bibiliography You can write citations, too. For example, we are using the bookdown package (Xie 2019) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). References "],
["references.html", "References", " References "]
]

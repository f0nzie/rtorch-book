<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>B Activation Functions | A Minimal rTorch Tutorial</title>
  <meta name="description" content="This is a minimal tutorial of using the rTorch package to have fun while doing machine learning. This book was produced with bookdown." />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="B Activation Functions | A Minimal rTorch Tutorial" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal tutorial of using the rTorch package to have fun while doing machine learning. This book was produced with bookdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="B Activation Functions | A Minimal rTorch Tutorial" />
  
  <meta name="twitter:description" content="This is a minimal tutorial of using the rTorch package to have fun while doing machine learning. This book was produced with bookdown." />
  

<meta name="author" content="Alfonso R. Reyes" />


<meta name="date" content="2019-09-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="appendixA.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal rTorch Tutorial</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#python-anaconda"><i class="fa fa-check"></i>Python Anaconda</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#example"><i class="fa fa-check"></i>Example</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#automatic-installation"><i class="fa fa-check"></i>Automatic installation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Getting Started</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#motivation"><i class="fa fa-check"></i><b>1.1</b> Motivation</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#how-do-we-start-using-rtorch"><i class="fa fa-check"></i><b>1.2</b> How do we start using <code>rTorch</code></a><ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#getting-the-pytorch-version"><i class="fa fa-check"></i><b>1.2.1</b> Getting the PyTorch version</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#pytorch-configuration"><i class="fa fa-check"></i><b>1.2.2</b> PyTorch configuration</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#what-can-you-do-with-rtorch"><i class="fa fa-check"></i><b>1.3</b> What can you do with <code>rTorch</code></a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#callable-pytorch-modules"><i class="fa fa-check"></i><b>1.4</b> Callable PyTorch modules</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#the-torchvision-module"><i class="fa fa-check"></i><b>1.4.1</b> The <code>torchvision</code> module</a></li>
<li class="chapter" data-level="1.4.2" data-path="intro.html"><a href="intro.html#np-the-numpy-module"><i class="fa fa-check"></i><b>1.4.2</b> <code>np</code>: the <code>numpy</code> module</a></li>
<li class="chapter" data-level="1.4.3" data-path="intro.html"><a href="intro.html#python-built-in-functions"><i class="fa fa-check"></i><b>1.4.3</b> Python built-in functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html"><i class="fa fa-check"></i><b>2</b> rTorch vs PyTorch: Whatâ€™s different</a><ul>
<li class="chapter" data-level="2.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#calling-objects-from-pytorch"><i class="fa fa-check"></i><b>2.1</b> Calling objects from PyTorch</a></li>
<li class="chapter" data-level="2.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#call-a-module-from-pytorch"><i class="fa fa-check"></i><b>2.2</b> Call a module from PyTorch</a></li>
<li class="chapter" data-level="2.3" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#show-the-attributes-methods-of-a-class-or-pytorch-object"><i class="fa fa-check"></i><b>2.3</b> Show the attributes (methods) of a class or PyTorch object</a></li>
<li class="chapter" data-level="2.4" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#enumeration"><i class="fa fa-check"></i><b>2.4</b> Enumeration</a></li>
<li class="chapter" data-level="2.5" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#how-to-iterate"><i class="fa fa-check"></i><b>2.5</b> How to iterate</a><ul>
<li class="chapter" data-level="2.5.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#using-enumerate-and-iterate"><i class="fa fa-check"></i><b>2.5.1</b> Using <code>enumerate</code> and <code>iterate</code></a></li>
<li class="chapter" data-level="2.5.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#using-a-for-loop-to-iterate"><i class="fa fa-check"></i><b>2.5.2</b> Using a <code>for-loop</code> to iterate</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#zero-gradient"><i class="fa fa-check"></i><b>2.6</b> Zero gradient</a><ul>
<li class="chapter" data-level="2.6.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#version-in-python"><i class="fa fa-check"></i><b>2.6.1</b> Version in Python</a></li>
<li class="chapter" data-level="2.6.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#version-in-r"><i class="fa fa-check"></i><b>2.6.2</b> Version in R</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#transform-a-tensor"><i class="fa fa-check"></i><b>2.7</b> Transform a tensor</a></li>
<li class="chapter" data-level="2.8" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#build-a-model-class"><i class="fa fa-check"></i><b>2.8</b> Build a model class</a><ul>
<li class="chapter" data-level="2.8.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#example-1"><i class="fa fa-check"></i><b>2.8.1</b> Example 1</a></li>
<li class="chapter" data-level="2.8.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#example-2-logistic-regression"><i class="fa fa-check"></i><b>2.8.2</b> Example 2: Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#convert-a-tensor-to-numpy-object"><i class="fa fa-check"></i><b>2.9</b> Convert a tensor to <code>numpy</code> object</a></li>
<li class="chapter" data-level="2.10" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#convert-a-numpy-object-to-an-r-object"><i class="fa fa-check"></i><b>2.10</b> Convert a <code>numpy</code> object to an <code>R</code> object</a></li>
</ul></li>
<li class="part"><span><b>II Basic Tensor Operations</b></span></li>
<li class="chapter" data-level="3" data-path="tensors.html"><a href="tensors.html"><i class="fa fa-check"></i><b>3</b> Tensors</a><ul>
<li class="chapter" data-level="3.1" data-path="tensors.html"><a href="tensors.html#tensor-data-types"><i class="fa fa-check"></i><b>3.1</b> Tensor data types</a></li>
<li class="chapter" data-level="3.2" data-path="tensors.html"><a href="tensors.html#arithmetic-of-tensors"><i class="fa fa-check"></i><b>3.2</b> Arithmetic of tensors</a><ul>
<li class="chapter" data-level="3.2.1" data-path="tensors.html"><a href="tensors.html#add-tensors"><i class="fa fa-check"></i><b>3.2.1</b> Add tensors</a></li>
<li class="chapter" data-level="3.2.2" data-path="tensors.html"><a href="tensors.html#multiply-a-tensor-by-a-scalar"><i class="fa fa-check"></i><b>3.2.2</b> Multiply a tensor by a scalar</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="tensors.html"><a href="tensors.html#numpy-and-pytorch"><i class="fa fa-check"></i><b>3.3</b> NumPy and PyTorch</a><ul>
<li class="chapter" data-level="3.3.1" data-path="tensors.html"><a href="tensors.html#tuples-python-and-vectors-r"><i class="fa fa-check"></i><b>3.3.1</b> Tuples (Python) and vectors (R)</a></li>
<li class="chapter" data-level="3.3.2" data-path="tensors.html"><a href="tensors.html#make-a-numpy-array-a-tensor-with-as_tensor"><i class="fa fa-check"></i><b>3.3.2</b> Make a numpy array a tensor with <code>as_tensor()</code></a></li>
<li class="chapter" data-level="3.3.3" data-path="tensors.html"><a href="tensors.html#tensor-to-array-and-viceversa"><i class="fa fa-check"></i><b>3.3.3</b> Tensor to array, and viceversa</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="tensors.html"><a href="tensors.html#create-tensors"><i class="fa fa-check"></i><b>3.4</b> Create tensors</a></li>
<li class="chapter" data-level="3.5" data-path="tensors.html"><a href="tensors.html#tensor-resizing"><i class="fa fa-check"></i><b>3.5</b> Tensor resizing</a><ul>
<li class="chapter" data-level="3.5.1" data-path="tensors.html"><a href="tensors.html#concatenate-tensors"><i class="fa fa-check"></i><b>3.5.1</b> Concatenate tensors</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="tensors.html"><a href="tensors.html#reshape-tensors"><i class="fa fa-check"></i><b>3.6</b> Reshape tensors</a><ul>
<li class="chapter" data-level="3.6.1" data-path="tensors.html"><a href="tensors.html#with-function-chunk"><i class="fa fa-check"></i><b>3.6.1</b> With function <code>chunk()</code>:</a></li>
<li class="chapter" data-level="3.6.2" data-path="tensors.html"><a href="tensors.html#with-index_select"><i class="fa fa-check"></i><b>3.6.2</b> With <code>index_select()</code>:</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="tensors.html"><a href="tensors.html#special-tensors"><i class="fa fa-check"></i><b>3.7</b> Special tensors</a><ul>
<li class="chapter" data-level="3.7.1" data-path="tensors.html"><a href="tensors.html#identity-matrix"><i class="fa fa-check"></i><b>3.7.1</b> Identity matrix</a></li>
<li class="chapter" data-level="3.7.2" data-path="tensors.html"><a href="tensors.html#ones"><i class="fa fa-check"></i><b>3.7.2</b> Ones</a></li>
<li class="chapter" data-level="3.7.3" data-path="tensors.html"><a href="tensors.html#zeros"><i class="fa fa-check"></i><b>3.7.3</b> Zeros</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="tensors.html"><a href="tensors.html#tensor-fill"><i class="fa fa-check"></i><b>3.8</b> Tensor fill</a><ul>
<li class="chapter" data-level="3.8.1" data-path="tensors.html"><a href="tensors.html#initialize-a-linear-or-log-scale-tensor"><i class="fa fa-check"></i><b>3.8.1</b> Initialize a linear or log scale Tensor</a></li>
<li class="chapter" data-level="3.8.2" data-path="tensors.html"><a href="tensors.html#inplace-out-of-place"><i class="fa fa-check"></i><b>3.8.2</b> Inplace / Out-of-place</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="tensors.html"><a href="tensors.html#access-to-tensor-elements"><i class="fa fa-check"></i><b>3.9</b> Access to tensor elements</a><ul>
<li class="chapter" data-level="3.9.1" data-path="tensors.html"><a href="tensors.html#using-indices-to-access-elements"><i class="fa fa-check"></i><b>3.9.1</b> Using indices to access elements</a></li>
<li class="chapter" data-level="3.9.2" data-path="tensors.html"><a href="tensors.html#using-the-take-function"><i class="fa fa-check"></i><b>3.9.2</b> Using the <code>take</code> function</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="tensors.html"><a href="tensors.html#other-tensor-operations"><i class="fa fa-check"></i><b>3.10</b> Other tensor operations</a><ul>
<li class="chapter" data-level="3.10.1" data-path="tensors.html"><a href="tensors.html#cross-product"><i class="fa fa-check"></i><b>3.10.1</b> Cross product</a></li>
<li class="chapter" data-level="3.10.2" data-path="tensors.html"><a href="tensors.html#dot-product"><i class="fa fa-check"></i><b>3.10.2</b> Dot product</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="tensors.html"><a href="tensors.html#logical-operations"><i class="fa fa-check"></i><b>3.11</b> Logical operations</a><ul>
<li class="chapter" data-level="3.11.1" data-path="tensors.html"><a href="tensors.html#logical-not"><i class="fa fa-check"></i><b>3.11.1</b> Logical NOT</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="tensors.html"><a href="tensors.html#distributions"><i class="fa fa-check"></i><b>3.12</b> Distributions</a><ul>
<li class="chapter" data-level="3.12.1" data-path="tensors.html"><a href="tensors.html#uniform-matrix"><i class="fa fa-check"></i><b>3.12.1</b> Uniform matrix</a></li>
<li class="chapter" data-level="3.12.2" data-path="tensors.html"><a href="tensors.html#binomial-distribution"><i class="fa fa-check"></i><b>3.12.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="3.12.3" data-path="tensors.html"><a href="tensors.html#exponential-distribution"><i class="fa fa-check"></i><b>3.12.3</b> Exponential distribution</a></li>
<li class="chapter" data-level="3.12.4" data-path="tensors.html"><a href="tensors.html#weibull-distribution"><i class="fa fa-check"></i><b>3.12.4</b> Weibull distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linearalgebra.html"><a href="linearalgebra.html"><i class="fa fa-check"></i><b>4</b> Linear Algebra with Torch</a><ul>
<li class="chapter" data-level="4.1" data-path="linearalgebra.html"><a href="linearalgebra.html#scalars"><i class="fa fa-check"></i><b>4.1</b> Scalars</a></li>
<li class="chapter" data-level="4.2" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors"><i class="fa fa-check"></i><b>4.2</b> Vectors</a></li>
<li class="chapter" data-level="4.3" data-path="linearalgebra.html"><a href="linearalgebra.html#matrices"><i class="fa fa-check"></i><b>4.3</b> Matrices</a></li>
<li class="chapter" data-level="4.4" data-path="linearalgebra.html"><a href="linearalgebra.html#d-tensors"><i class="fa fa-check"></i><b>4.4</b> 3D+ tensors</a></li>
<li class="chapter" data-level="4.5" data-path="linearalgebra.html"><a href="linearalgebra.html#transpose-of-a-matrix"><i class="fa fa-check"></i><b>4.5</b> Transpose of a matrix</a></li>
<li class="chapter" data-level="4.6" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors-special-case-of-a-matrix"><i class="fa fa-check"></i><b>4.6</b> Vectors, special case of a matrix</a></li>
<li class="chapter" data-level="4.7" data-path="linearalgebra.html"><a href="linearalgebra.html#tensor-arithmetic"><i class="fa fa-check"></i><b>4.7</b> Tensor arithmetic</a></li>
<li class="chapter" data-level="4.8" data-path="linearalgebra.html"><a href="linearalgebra.html#add-a-scalar-to-a-tensor"><i class="fa fa-check"></i><b>4.8</b> Add a scalar to a tensor</a></li>
<li class="chapter" data-level="4.9" data-path="linearalgebra.html"><a href="linearalgebra.html#multiplying-tensors"><i class="fa fa-check"></i><b>4.9</b> Multiplying tensors</a></li>
<li class="chapter" data-level="4.10" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-1"><i class="fa fa-check"></i><b>4.10</b> Dot product</a></li>
</ul></li>
<li class="part"><span><b>III Logistic Regression</b></span></li>
<li class="chapter" data-level="5" data-path="mnistdigits.html"><a href="mnistdigits.html"><i class="fa fa-check"></i><b>5</b> Example 1: MNIST handwritten digits</a><ul>
<li class="chapter" data-level="5.1" data-path="mnistdigits.html"><a href="mnistdigits.html#hyperparameters"><i class="fa fa-check"></i><b>5.1</b> Hyperparameters</a></li>
<li class="chapter" data-level="5.2" data-path="mnistdigits.html"><a href="mnistdigits.html#read-datasets"><i class="fa fa-check"></i><b>5.2</b> Read datasets</a></li>
<li class="chapter" data-level="5.3" data-path="mnistdigits.html"><a href="mnistdigits.html#define-the-model"><i class="fa fa-check"></i><b>5.3</b> Define the model</a></li>
<li class="chapter" data-level="5.4" data-path="mnistdigits.html"><a href="mnistdigits.html#training"><i class="fa fa-check"></i><b>5.4</b> Training</a></li>
<li class="chapter" data-level="5.5" data-path="mnistdigits.html"><a href="mnistdigits.html#prediction"><i class="fa fa-check"></i><b>5.5</b> Prediction</a></li>
<li class="chapter" data-level="5.6" data-path="mnistdigits.html"><a href="mnistdigits.html#save-the-model"><i class="fa fa-check"></i><b>5.6</b> Save the model</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="a-classic-classification-problem.html"><a href="a-classic-classification-problem.html"><i class="fa fa-check"></i><b>6</b> A classic classification problem</a></li>
<li class="part"><span><b>IV Linear Regression</b></span></li>
<li class="chapter" data-level="7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>7</b> Simple linear regression</a><ul>
<li class="chapter" data-level="7.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#introduction"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#generate-the-dataset"><i class="fa fa-check"></i><b>7.2</b> Generate the dataset</a></li>
<li class="chapter" data-level="7.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#convert-arrays-to-tensors"><i class="fa fa-check"></i><b>7.3</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="7.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#converting-from-numpy-to-tensor"><i class="fa fa-check"></i><b>7.4</b> Converting from numpy to tensor</a></li>
<li class="chapter" data-level="7.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#creating-the-network-model"><i class="fa fa-check"></i><b>7.5</b> Creating the network model</a></li>
<li class="chapter" data-level="7.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#optimizer-and-loss"><i class="fa fa-check"></i><b>7.6</b> Optimizer and Loss</a></li>
<li class="chapter" data-level="7.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#training-1"><i class="fa fa-check"></i><b>7.7</b> Training</a></li>
<li class="chapter" data-level="7.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#results"><i class="fa fa-check"></i><b>7.8</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html"><i class="fa fa-check"></i><b>8</b> Rainfall. Linear Regression</a><ul>
<li class="chapter" data-level="8.1" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#training-data"><i class="fa fa-check"></i><b>8.1</b> Training data</a></li>
<li class="chapter" data-level="8.2" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#convert-arrays-to-tensors-1"><i class="fa fa-check"></i><b>8.2</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="8.3" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#build-the-model"><i class="fa fa-check"></i><b>8.3</b> Build the model</a></li>
<li class="chapter" data-level="8.4" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#generate-predictions"><i class="fa fa-check"></i><b>8.4</b> Generate predictions</a></li>
<li class="chapter" data-level="8.5" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#loss-function"><i class="fa fa-check"></i><b>8.5</b> Loss Function</a></li>
<li class="chapter" data-level="8.6" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#step-by-step-process"><i class="fa fa-check"></i><b>8.6</b> Step by step process</a><ul>
<li class="chapter" data-level="8.6.1" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#compute-the-losses"><i class="fa fa-check"></i><b>8.6.1</b> Compute the losses</a></li>
<li class="chapter" data-level="8.6.2" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#compute-gradients"><i class="fa fa-check"></i><b>8.6.2</b> Compute Gradients</a></li>
<li class="chapter" data-level="8.6.3" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#reset-the-gradients"><i class="fa fa-check"></i><b>8.6.3</b> Reset the gradients</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#all-together-train-for-multiple-epochs"><i class="fa fa-check"></i><b>8.7</b> All together: train for multiple epochs</a></li>
</ul></li>
<li class="part"><span><b>V Neural Networks</b></span></li>
<li class="chapter" data-level="9" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html"><i class="fa fa-check"></i><b>9</b> A two-layer neural network</a><ul>
<li class="chapter" data-level="9.1" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#load-the-libraries"><i class="fa fa-check"></i><b>9.1</b> Load the libraries</a></li>
<li class="chapter" data-level="9.2" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#dataset"><i class="fa fa-check"></i><b>9.2</b> Dataset</a></li>
<li class="chapter" data-level="9.3" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#run-the-model-for-50-iterations"><i class="fa fa-check"></i><b>9.3</b> Run the model for 50 iterations</a></li>
<li class="chapter" data-level="9.4" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#run-it-at-100-iterations"><i class="fa fa-check"></i><b>9.4</b> Run it at 100 iterations</a></li>
<li class="chapter" data-level="9.5" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#original-pytorch-code"><i class="fa fa-check"></i><b>9.5</b> Original PyTorch code</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html"><i class="fa fa-check"></i><b>10</b> A very simple neural network</a><ul>
<li class="chapter" data-level="10.1" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#introduction-1"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#select-device"><i class="fa fa-check"></i><b>10.2</b> Select device</a></li>
<li class="chapter" data-level="10.3" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#create-the-dataset"><i class="fa fa-check"></i><b>10.3</b> Create the dataset</a></li>
<li class="chapter" data-level="10.4" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#define-the-model-1"><i class="fa fa-check"></i><b>10.4</b> Define the model</a></li>
<li class="chapter" data-level="10.5" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#loss-function-1"><i class="fa fa-check"></i><b>10.5</b> Loss function</a></li>
<li class="chapter" data-level="10.6" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#iterate-through-batches"><i class="fa fa-check"></i><b>10.6</b> Iterate through batches</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="neural-networks-2.html"><a href="neural-networks-2.html"><i class="fa fa-check"></i><b>11</b> Neural Networks 2</a><ul>
<li class="chapter" data-level="11.1" data-path="neural-networks-2.html"><a href="neural-networks-2.html#nn2-1"><i class="fa fa-check"></i><b>11.1</b> nn2 1</a></li>
<li class="chapter" data-level="11.2" data-path="neural-networks-2.html"><a href="neural-networks-2.html#nn2-2"><i class="fa fa-check"></i><b>11.2</b> nn2 2</a></li>
</ul></li>
<li class="part"><span><b>VI PyTorch and R data structures</b></span></li>
<li class="chapter" data-level="12" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html"><i class="fa fa-check"></i><b>12</b> Working with data.frame</a><ul>
<li class="chapter" data-level="12.1" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#load-pytorch-libraries"><i class="fa fa-check"></i><b>12.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="12.2" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#load-dataset"><i class="fa fa-check"></i><b>12.2</b> Load dataset</a></li>
<li class="chapter" data-level="12.3" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#summary-statistics-for-tensors"><i class="fa fa-check"></i><b>12.3</b> Summary statistics for tensors</a><ul>
<li class="chapter" data-level="12.3.1" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#using-data.frame"><i class="fa fa-check"></i><b>12.3.1</b> using <code>data.frame</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="working-with-data-table.html"><a href="working-with-data-table.html"><i class="fa fa-check"></i><b>13</b> Working with data.table</a><ul>
<li class="chapter" data-level="13.1" data-path="working-with-data-table.html"><a href="working-with-data-table.html#load-pytorch-libraries-1"><i class="fa fa-check"></i><b>13.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="13.2" data-path="working-with-data-table.html"><a href="working-with-data-table.html#load-dataset-1"><i class="fa fa-check"></i><b>13.2</b> Load dataset</a></li>
<li class="chapter" data-level="13.3" data-path="working-with-data-table.html"><a href="working-with-data-table.html#read-the-datasets-without-normalization"><i class="fa fa-check"></i><b>13.3</b> Read the datasets without normalization</a></li>
<li class="chapter" data-level="13.4" data-path="working-with-data-table.html"><a href="working-with-data-table.html#using-data.table"><i class="fa fa-check"></i><b>13.4</b> Using <code>data.table</code></a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendixA.html"><a href="appendixA.html"><i class="fa fa-check"></i><b>A</b> Statistical Background</a><ul>
<li class="chapter" data-level="A.1" data-path="appendixA.html"><a href="appendixA.html#basic-statistical-terms"><i class="fa fa-check"></i><b>A.1</b> Basic statistical terms</a><ul>
<li class="chapter" data-level="A.1.1" data-path="appendixA.html"><a href="appendixA.html#five-number-summary"><i class="fa fa-check"></i><b>A.1.1</b> Five-number summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendixB.html"><a href="appendixB.html"><i class="fa fa-check"></i><b>B</b> Activation Functions</a><ul>
<li class="chapter" data-level="B.1" data-path="appendixB.html"><a href="appendixB.html#the-sigmoid-function"><i class="fa fa-check"></i><b>B.1</b> The Sigmoid function</a></li>
<li class="chapter" data-level="B.2" data-path="appendixB.html"><a href="appendixB.html#the-relu-function"><i class="fa fa-check"></i><b>B.2</b> The ReLU function</a></li>
<li class="chapter" data-level="B.3" data-path="appendixB.html"><a href="appendixB.html#the-tanh-function"><i class="fa fa-check"></i><b>B.3</b> The tanh function</a></li>
<li class="chapter" data-level="B.4" data-path="appendixB.html"><a href="appendixB.html#the-softmax-activation-function"><i class="fa fa-check"></i><b>B.4</b> The Softmax Activation function</a></li>
<li class="chapter" data-level="B.5" data-path="appendixB.html"><a href="appendixB.html#coding-your-own-activation-functions-in-python"><i class="fa fa-check"></i><b>B.5</b> Coding your own activation functions in Python</a><ul>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#linear-activation"><i class="fa fa-check"></i>Linear activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#sigmoid-activation"><i class="fa fa-check"></i>Sigmoid activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#hyperbolic-tangent-activation"><i class="fa fa-check"></i>Hyperbolic Tangent activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#rectifier-linear-unit-relu"><i class="fa fa-check"></i>Rectifier linear unit (ReLU)</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#visualization"><i class="fa fa-check"></i>Visualization</a></li>
</ul></li>
<li class="chapter" data-level="B.6" data-path="appendixB.html"><a href="appendixB.html#softmax-in-python"><i class="fa fa-check"></i><b>B.6</b> Softmax in Python</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Minimal rTorch Tutorial</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="appendixB" class="section level1">
<h1><span class="header-section-number">B</span> Activation Functions</h1>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb236-1" data-line-number="1"><span class="kw">library</span>(rTorch)</a>
<a class="sourceLine" id="cb236-2" data-line-number="2"><span class="kw">library</span>(ggplot2)</a></code></pre></div>
<div id="the-sigmoid-function" class="section level2">
<h2><span class="header-section-number">B.1</span> The Sigmoid function</h2>
<p>Using the PyTorch <code>sigmoid()</code> function:</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb237-1" data-line-number="1">x &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">5.</span>, <span class="fl">5.</span>, <span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb237-2" data-line-number="2">y &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">sigmoid</span>(x)</a>
<a class="sourceLine" id="cb237-3" data-line-number="3"></a>
<a class="sourceLine" id="cb237-4" data-line-number="4">df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> x<span class="op">$</span><span class="kw">numpy</span>(), <span class="dt">sx =</span> y<span class="op">$</span><span class="kw">numpy</span>())</a>
<a class="sourceLine" id="cb237-5" data-line-number="5">df</a>
<a class="sourceLine" id="cb237-6" data-line-number="6"><span class="co">#&gt;        x      sx</span></a>
<a class="sourceLine" id="cb237-7" data-line-number="7"><span class="co">#&gt; 1   -5.0 0.00669</span></a>
<a class="sourceLine" id="cb237-8" data-line-number="8"><span class="co">#&gt; 2   -4.9 0.00739</span></a>
<a class="sourceLine" id="cb237-9" data-line-number="9"><span class="co">#&gt; 3   -4.8 0.00816</span></a>
<a class="sourceLine" id="cb237-10" data-line-number="10"><span class="co">#&gt; 4   -4.7 0.00901</span></a>
<a class="sourceLine" id="cb237-11" data-line-number="11"><span class="co">#&gt; 5   -4.6 0.00995</span></a>
<a class="sourceLine" id="cb237-12" data-line-number="12"><span class="co">#&gt; 6   -4.5 0.01099</span></a>
<a class="sourceLine" id="cb237-13" data-line-number="13"><span class="co">#&gt; 7   -4.4 0.01213</span></a>
<a class="sourceLine" id="cb237-14" data-line-number="14"><span class="co">#&gt; 8   -4.3 0.01339</span></a>
<a class="sourceLine" id="cb237-15" data-line-number="15"><span class="co">#&gt; 9   -4.2 0.01477</span></a>
<a class="sourceLine" id="cb237-16" data-line-number="16"><span class="co">#&gt; 10  -4.1 0.01630</span></a>
<a class="sourceLine" id="cb237-17" data-line-number="17"><span class="co">#&gt; 11  -4.0 0.01799</span></a>
<a class="sourceLine" id="cb237-18" data-line-number="18"><span class="co">#&gt; 12  -3.9 0.01984</span></a>
<a class="sourceLine" id="cb237-19" data-line-number="19"><span class="co">#&gt; 13  -3.8 0.02188</span></a>
<a class="sourceLine" id="cb237-20" data-line-number="20"><span class="co">#&gt; 14  -3.7 0.02413</span></a>
<a class="sourceLine" id="cb237-21" data-line-number="21"><span class="co">#&gt; 15  -3.6 0.02660</span></a>
<a class="sourceLine" id="cb237-22" data-line-number="22"><span class="co">#&gt; 16  -3.5 0.02931</span></a>
<a class="sourceLine" id="cb237-23" data-line-number="23"><span class="co">#&gt; 17  -3.4 0.03230</span></a>
<a class="sourceLine" id="cb237-24" data-line-number="24"><span class="co">#&gt; 18  -3.3 0.03557</span></a>
<a class="sourceLine" id="cb237-25" data-line-number="25"><span class="co">#&gt; 19  -3.2 0.03917</span></a>
<a class="sourceLine" id="cb237-26" data-line-number="26"><span class="co">#&gt; 20  -3.1 0.04311</span></a>
<a class="sourceLine" id="cb237-27" data-line-number="27"><span class="co">#&gt; 21  -3.0 0.04743</span></a>
<a class="sourceLine" id="cb237-28" data-line-number="28"><span class="co">#&gt; 22  -2.9 0.05215</span></a>
<a class="sourceLine" id="cb237-29" data-line-number="29"><span class="co">#&gt; 23  -2.8 0.05732</span></a>
<a class="sourceLine" id="cb237-30" data-line-number="30"><span class="co">#&gt; 24  -2.7 0.06297</span></a>
<a class="sourceLine" id="cb237-31" data-line-number="31"><span class="co">#&gt; 25  -2.6 0.06914</span></a>
<a class="sourceLine" id="cb237-32" data-line-number="32"><span class="co">#&gt; 26  -2.5 0.07586</span></a>
<a class="sourceLine" id="cb237-33" data-line-number="33"><span class="co">#&gt; 27  -2.4 0.08317</span></a>
<a class="sourceLine" id="cb237-34" data-line-number="34"><span class="co">#&gt; 28  -2.3 0.09112</span></a>
<a class="sourceLine" id="cb237-35" data-line-number="35"><span class="co">#&gt; 29  -2.2 0.09975</span></a>
<a class="sourceLine" id="cb237-36" data-line-number="36"><span class="co">#&gt; 30  -2.1 0.10910</span></a>
<a class="sourceLine" id="cb237-37" data-line-number="37"><span class="co">#&gt; 31  -2.0 0.11920</span></a>
<a class="sourceLine" id="cb237-38" data-line-number="38"><span class="co">#&gt; 32  -1.9 0.13011</span></a>
<a class="sourceLine" id="cb237-39" data-line-number="39"><span class="co">#&gt; 33  -1.8 0.14185</span></a>
<a class="sourceLine" id="cb237-40" data-line-number="40"><span class="co">#&gt; 34  -1.7 0.15447</span></a>
<a class="sourceLine" id="cb237-41" data-line-number="41"><span class="co">#&gt; 35  -1.6 0.16798</span></a>
<a class="sourceLine" id="cb237-42" data-line-number="42"><span class="co">#&gt; 36  -1.5 0.18243</span></a>
<a class="sourceLine" id="cb237-43" data-line-number="43"><span class="co">#&gt; 37  -1.4 0.19782</span></a>
<a class="sourceLine" id="cb237-44" data-line-number="44"><span class="co">#&gt; 38  -1.3 0.21417</span></a>
<a class="sourceLine" id="cb237-45" data-line-number="45"><span class="co">#&gt; 39  -1.2 0.23148</span></a>
<a class="sourceLine" id="cb237-46" data-line-number="46"><span class="co">#&gt; 40  -1.1 0.24974</span></a>
<a class="sourceLine" id="cb237-47" data-line-number="47"><span class="co">#&gt; 41  -1.0 0.26894</span></a>
<a class="sourceLine" id="cb237-48" data-line-number="48"><span class="co">#&gt; 42  -0.9 0.28905</span></a>
<a class="sourceLine" id="cb237-49" data-line-number="49"><span class="co">#&gt; 43  -0.8 0.31003</span></a>
<a class="sourceLine" id="cb237-50" data-line-number="50"><span class="co">#&gt; 44  -0.7 0.33181</span></a>
<a class="sourceLine" id="cb237-51" data-line-number="51"><span class="co">#&gt; 45  -0.6 0.35434</span></a>
<a class="sourceLine" id="cb237-52" data-line-number="52"><span class="co">#&gt; 46  -0.5 0.37754</span></a>
<a class="sourceLine" id="cb237-53" data-line-number="53"><span class="co">#&gt; 47  -0.4 0.40131</span></a>
<a class="sourceLine" id="cb237-54" data-line-number="54"><span class="co">#&gt; 48  -0.3 0.42556</span></a>
<a class="sourceLine" id="cb237-55" data-line-number="55"><span class="co">#&gt; 49  -0.2 0.45017</span></a>
<a class="sourceLine" id="cb237-56" data-line-number="56"><span class="co">#&gt; 50  -0.1 0.47502</span></a>
<a class="sourceLine" id="cb237-57" data-line-number="57"><span class="co">#&gt; 51   0.0 0.50000</span></a>
<a class="sourceLine" id="cb237-58" data-line-number="58"><span class="co">#&gt; 52   0.1 0.52498</span></a>
<a class="sourceLine" id="cb237-59" data-line-number="59"><span class="co">#&gt; 53   0.2 0.54983</span></a>
<a class="sourceLine" id="cb237-60" data-line-number="60"><span class="co">#&gt; 54   0.3 0.57444</span></a>
<a class="sourceLine" id="cb237-61" data-line-number="61"><span class="co">#&gt; 55   0.4 0.59869</span></a>
<a class="sourceLine" id="cb237-62" data-line-number="62"><span class="co">#&gt; 56   0.5 0.62246</span></a>
<a class="sourceLine" id="cb237-63" data-line-number="63"><span class="co">#&gt; 57   0.6 0.64566</span></a>
<a class="sourceLine" id="cb237-64" data-line-number="64"><span class="co">#&gt; 58   0.7 0.66819</span></a>
<a class="sourceLine" id="cb237-65" data-line-number="65"><span class="co">#&gt; 59   0.8 0.68997</span></a>
<a class="sourceLine" id="cb237-66" data-line-number="66"><span class="co">#&gt; 60   0.9 0.71095</span></a>
<a class="sourceLine" id="cb237-67" data-line-number="67"><span class="co">#&gt; 61   1.0 0.73106</span></a>
<a class="sourceLine" id="cb237-68" data-line-number="68"><span class="co">#&gt; 62   1.1 0.75026</span></a>
<a class="sourceLine" id="cb237-69" data-line-number="69"><span class="co">#&gt; 63   1.2 0.76852</span></a>
<a class="sourceLine" id="cb237-70" data-line-number="70"><span class="co">#&gt; 64   1.3 0.78584</span></a>
<a class="sourceLine" id="cb237-71" data-line-number="71"><span class="co">#&gt; 65   1.4 0.80218</span></a>
<a class="sourceLine" id="cb237-72" data-line-number="72"><span class="co">#&gt; 66   1.5 0.81757</span></a>
<a class="sourceLine" id="cb237-73" data-line-number="73"><span class="co">#&gt; 67   1.6 0.83202</span></a>
<a class="sourceLine" id="cb237-74" data-line-number="74"><span class="co">#&gt; 68   1.7 0.84553</span></a>
<a class="sourceLine" id="cb237-75" data-line-number="75"><span class="co">#&gt; 69   1.8 0.85815</span></a>
<a class="sourceLine" id="cb237-76" data-line-number="76"><span class="co">#&gt; 70   1.9 0.86989</span></a>
<a class="sourceLine" id="cb237-77" data-line-number="77"><span class="co">#&gt; 71   2.0 0.88080</span></a>
<a class="sourceLine" id="cb237-78" data-line-number="78"><span class="co">#&gt; 72   2.1 0.89090</span></a>
<a class="sourceLine" id="cb237-79" data-line-number="79"><span class="co">#&gt; 73   2.2 0.90025</span></a>
<a class="sourceLine" id="cb237-80" data-line-number="80"><span class="co">#&gt; 74   2.3 0.90888</span></a>
<a class="sourceLine" id="cb237-81" data-line-number="81"><span class="co">#&gt; 75   2.4 0.91683</span></a>
<a class="sourceLine" id="cb237-82" data-line-number="82"><span class="co">#&gt; 76   2.5 0.92414</span></a>
<a class="sourceLine" id="cb237-83" data-line-number="83"><span class="co">#&gt; 77   2.6 0.93086</span></a>
<a class="sourceLine" id="cb237-84" data-line-number="84"><span class="co">#&gt; 78   2.7 0.93703</span></a>
<a class="sourceLine" id="cb237-85" data-line-number="85"><span class="co">#&gt; 79   2.8 0.94268</span></a>
<a class="sourceLine" id="cb237-86" data-line-number="86"><span class="co">#&gt; 80   2.9 0.94785</span></a>
<a class="sourceLine" id="cb237-87" data-line-number="87"><span class="co">#&gt; 81   3.0 0.95257</span></a>
<a class="sourceLine" id="cb237-88" data-line-number="88"><span class="co">#&gt; 82   3.1 0.95689</span></a>
<a class="sourceLine" id="cb237-89" data-line-number="89"><span class="co">#&gt; 83   3.2 0.96083</span></a>
<a class="sourceLine" id="cb237-90" data-line-number="90"><span class="co">#&gt; 84   3.3 0.96443</span></a>
<a class="sourceLine" id="cb237-91" data-line-number="91"><span class="co">#&gt; 85   3.4 0.96770</span></a>
<a class="sourceLine" id="cb237-92" data-line-number="92"><span class="co">#&gt; 86   3.5 0.97069</span></a>
<a class="sourceLine" id="cb237-93" data-line-number="93"><span class="co">#&gt; 87   3.6 0.97340</span></a>
<a class="sourceLine" id="cb237-94" data-line-number="94"><span class="co">#&gt; 88   3.7 0.97587</span></a>
<a class="sourceLine" id="cb237-95" data-line-number="95"><span class="co">#&gt; 89   3.8 0.97812</span></a>
<a class="sourceLine" id="cb237-96" data-line-number="96"><span class="co">#&gt; 90   3.9 0.98016</span></a>
<a class="sourceLine" id="cb237-97" data-line-number="97"><span class="co">#&gt; 91   4.0 0.98201</span></a>
<a class="sourceLine" id="cb237-98" data-line-number="98"><span class="co">#&gt; 92   4.1 0.98370</span></a>
<a class="sourceLine" id="cb237-99" data-line-number="99"><span class="co">#&gt; 93   4.2 0.98523</span></a>
<a class="sourceLine" id="cb237-100" data-line-number="100"><span class="co">#&gt; 94   4.3 0.98661</span></a>
<a class="sourceLine" id="cb237-101" data-line-number="101"><span class="co">#&gt; 95   4.4 0.98787</span></a>
<a class="sourceLine" id="cb237-102" data-line-number="102"><span class="co">#&gt; 96   4.5 0.98901</span></a>
<a class="sourceLine" id="cb237-103" data-line-number="103"><span class="co">#&gt; 97   4.6 0.99005</span></a>
<a class="sourceLine" id="cb237-104" data-line-number="104"><span class="co">#&gt; 98   4.7 0.99099</span></a>
<a class="sourceLine" id="cb237-105" data-line-number="105"><span class="co">#&gt; 99   4.8 0.99184</span></a>
<a class="sourceLine" id="cb237-106" data-line-number="106"><span class="co">#&gt; 100  4.9 0.99261</span></a>
<a class="sourceLine" id="cb237-107" data-line-number="107"><span class="co">#&gt; 101  5.0 0.99331</span></a>
<a class="sourceLine" id="cb237-108" data-line-number="108"></a>
<a class="sourceLine" id="cb237-109" data-line-number="109"><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> sx)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb237-110" data-line-number="110"><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb237-111" data-line-number="111"><span class="st">    </span><span class="kw">ggtitle</span>(<span class="st">&quot;Sigmoid&quot;</span>)</a></code></pre></div>
<p><img src="9992-appendixB_files/figure-html/sigmoid-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Plot the sigmoid function using an R custom-made function:</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb238-1" data-line-number="1">sigmoid =<span class="st"> </span><span class="cf">function</span>(x) {</a>
<a class="sourceLine" id="cb238-2" data-line-number="2">   <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>x))</a>
<a class="sourceLine" id="cb238-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb238-4" data-line-number="4"></a>
<a class="sourceLine" id="cb238-5" data-line-number="5">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="fl">0.01</span>)</a>
<a class="sourceLine" id="cb238-6" data-line-number="6"><span class="kw">plot</span>(x, <span class="kw">sigmoid</span>(x), <span class="dt">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="dt">cex =</span> <span class="fl">0.5</span>, <span class="dt">main =</span> <span class="st">&quot;Sigmoid&quot;</span>)</a></code></pre></div>
<p><img src="9992-appendixB_files/figure-html/unnamed-chunk-5-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="the-relu-function" class="section level2">
<h2><span class="header-section-number">B.2</span> The ReLU function</h2>
<p>Using the PyTorch <code>relu()</code> function:</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb239-1" data-line-number="1">x &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">5.</span>, <span class="fl">5.</span>, <span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb239-2" data-line-number="2">y &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">relu</span>(x)</a>
<a class="sourceLine" id="cb239-3" data-line-number="3"></a>
<a class="sourceLine" id="cb239-4" data-line-number="4">df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> x<span class="op">$</span><span class="kw">numpy</span>(), <span class="dt">sx =</span> y<span class="op">$</span><span class="kw">numpy</span>())</a>
<a class="sourceLine" id="cb239-5" data-line-number="5">df</a>
<a class="sourceLine" id="cb239-6" data-line-number="6"></a>
<a class="sourceLine" id="cb239-7" data-line-number="7"><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> sx)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb239-8" data-line-number="8"><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb239-9" data-line-number="9"><span class="st">    </span><span class="kw">ggtitle</span>(<span class="st">&quot;ReLU&quot;</span>)</a></code></pre></div>
<p><img src="9992-appendixB_files/figure-html/relu-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="the-tanh-function" class="section level2">
<h2><span class="header-section-number">B.3</span> The tanh function</h2>
<p>Using the PyTorch <code>tanh()</code> function:</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb240-1" data-line-number="1">x &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">5.</span>, <span class="fl">5.</span>, <span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb240-2" data-line-number="2">y &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">tanh</span>(x)</a>
<a class="sourceLine" id="cb240-3" data-line-number="3"></a>
<a class="sourceLine" id="cb240-4" data-line-number="4">df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> x<span class="op">$</span><span class="kw">numpy</span>(), <span class="dt">sx =</span> y<span class="op">$</span><span class="kw">numpy</span>())</a>
<a class="sourceLine" id="cb240-5" data-line-number="5">df</a>
<a class="sourceLine" id="cb240-6" data-line-number="6"></a>
<a class="sourceLine" id="cb240-7" data-line-number="7"><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> sx)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb240-8" data-line-number="8"><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb240-9" data-line-number="9"><span class="st">    </span><span class="kw">ggtitle</span>(<span class="st">&quot;tanh&quot;</span>)</a></code></pre></div>
<p><img src="9992-appendixB_files/figure-html/tanh-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="the-softmax-activation-function" class="section level2">
<h2><span class="header-section-number">B.4</span> The Softmax Activation function</h2>
<p>Using the PyTorch <code>tanh()</code> function:</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb241-1" data-line-number="1">x &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">range</span>(<span class="op">-</span><span class="fl">5.0</span>, <span class="fl">5.0</span>, <span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb241-2" data-line-number="2">y &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">softmax</span>(x, <span class="dt">dim=</span>0L)</a>
<a class="sourceLine" id="cb241-3" data-line-number="3"></a>
<a class="sourceLine" id="cb241-4" data-line-number="4">df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> x<span class="op">$</span><span class="kw">numpy</span>(), <span class="dt">sx =</span> y<span class="op">$</span><span class="kw">numpy</span>())</a>
<a class="sourceLine" id="cb241-5" data-line-number="5"></a>
<a class="sourceLine" id="cb241-6" data-line-number="6"><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> sx)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb241-7" data-line-number="7"><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb241-8" data-line-number="8"><span class="st">    </span><span class="kw">ggtitle</span>(<span class="st">&quot;Softmax&quot;</span>)</a></code></pre></div>
<p><img src="9992-appendixB_files/figure-html/softmax-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="coding-your-own-activation-functions-in-python" class="section level2">
<h2><span class="header-section-number">B.5</span> Coding your own activation functions in Python</h2>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb242-1" data-line-number="1"><span class="kw">library</span>(rTorch)</a></code></pre></div>
<div class="sourceCode" id="cb243"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb243-1" data-line-number="1"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb243-2" data-line-number="2"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</a>
<a class="sourceLine" id="cb243-3" data-line-number="3">np.random.seed(<span class="dv">42</span>)</a></code></pre></div>
<div id="linear-activation" class="section level3 unnumbered">
<h3>Linear activation</h3>
<div class="sourceCode" id="cb244"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb244-1" data-line-number="1"><span class="kw">def</span> Linear(x, derivative<span class="op">=</span><span class="va">False</span>):</a>
<a class="sourceLine" id="cb244-2" data-line-number="2">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb244-3" data-line-number="3"><span class="co">    Computes the Linear activation function for array x</span></a>
<a class="sourceLine" id="cb244-4" data-line-number="4"><span class="co">    inputs:</span></a>
<a class="sourceLine" id="cb244-5" data-line-number="5"><span class="co">    x: array</span></a>
<a class="sourceLine" id="cb244-6" data-line-number="6"><span class="co">    derivative: if True, return the derivative else the forward pass</span></a>
<a class="sourceLine" id="cb244-7" data-line-number="7"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb244-8" data-line-number="8">    </a>
<a class="sourceLine" id="cb244-9" data-line-number="9">    <span class="cf">if</span> derivative:              <span class="co"># Return derivative of the function at x</span></a>
<a class="sourceLine" id="cb244-10" data-line-number="10">        <span class="cf">return</span> np.ones_like(x)</a>
<a class="sourceLine" id="cb244-11" data-line-number="11">    <span class="cf">else</span>:                       <span class="co"># Return forward pass of the function at x</span></a>
<a class="sourceLine" id="cb244-12" data-line-number="12">        <span class="cf">return</span> x</a></code></pre></div>
</div>
<div id="sigmoid-activation" class="section level3 unnumbered">
<h3>Sigmoid activation</h3>
<div class="sourceCode" id="cb245"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb245-1" data-line-number="1"><span class="kw">def</span> Sigmoid(x, derivative<span class="op">=</span><span class="va">False</span>):</a>
<a class="sourceLine" id="cb245-2" data-line-number="2">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb245-3" data-line-number="3"><span class="co">    Computes the Sigmoid activation function for array x</span></a>
<a class="sourceLine" id="cb245-4" data-line-number="4"><span class="co">    inputs:</span></a>
<a class="sourceLine" id="cb245-5" data-line-number="5"><span class="co">    x: array </span></a>
<a class="sourceLine" id="cb245-6" data-line-number="6"><span class="co">    derivative: if True, return the derivative else the forward pass</span></a>
<a class="sourceLine" id="cb245-7" data-line-number="7"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb245-8" data-line-number="8">    f <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>np.exp(<span class="op">-</span>x))</a>
<a class="sourceLine" id="cb245-9" data-line-number="9">    </a>
<a class="sourceLine" id="cb245-10" data-line-number="10">    <span class="cf">if</span> derivative:              <span class="co"># Return derivative of the function at x</span></a>
<a class="sourceLine" id="cb245-11" data-line-number="11">        <span class="cf">return</span> f<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>f)</a>
<a class="sourceLine" id="cb245-12" data-line-number="12">    <span class="cf">else</span>:                       <span class="co"># Return forward pass of the function at x</span></a>
<a class="sourceLine" id="cb245-13" data-line-number="13">        <span class="cf">return</span> f</a></code></pre></div>
</div>
<div id="hyperbolic-tangent-activation" class="section level3 unnumbered">
<h3>Hyperbolic Tangent activation</h3>
<div class="sourceCode" id="cb246"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb246-1" data-line-number="1"><span class="kw">def</span> Tanh(x, derivative<span class="op">=</span><span class="va">False</span>):</a>
<a class="sourceLine" id="cb246-2" data-line-number="2">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb246-3" data-line-number="3"><span class="co">    Computes the Hyperbolic Tangent activation function for array x</span></a>
<a class="sourceLine" id="cb246-4" data-line-number="4"><span class="co">    inputs:</span></a>
<a class="sourceLine" id="cb246-5" data-line-number="5"><span class="co">    x: array </span></a>
<a class="sourceLine" id="cb246-6" data-line-number="6"><span class="co">    derivative: if True, return the derivative else the forward pass</span></a>
<a class="sourceLine" id="cb246-7" data-line-number="7"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb246-8" data-line-number="8">    f <span class="op">=</span> (np.exp(x)<span class="op">-</span>np.exp(<span class="op">-</span>x))<span class="op">/</span>(np.exp(x)<span class="op">+</span>np.exp(<span class="op">-</span>x))</a>
<a class="sourceLine" id="cb246-9" data-line-number="9">    </a>
<a class="sourceLine" id="cb246-10" data-line-number="10">    <span class="cf">if</span> derivative:              <span class="co"># Return  derivative of the function at x</span></a>
<a class="sourceLine" id="cb246-11" data-line-number="11">        <span class="cf">return</span> <span class="dv">1</span><span class="op">-</span>f<span class="op">**</span><span class="dv">2</span></a>
<a class="sourceLine" id="cb246-12" data-line-number="12">    <span class="cf">else</span>:                       <span class="co"># Return the forward pass of the function at x</span></a>
<a class="sourceLine" id="cb246-13" data-line-number="13">        <span class="cf">return</span> f</a></code></pre></div>
</div>
<div id="rectifier-linear-unit-relu" class="section level3 unnumbered">
<h3>Rectifier linear unit (ReLU)</h3>
<div class="sourceCode" id="cb247"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb247-1" data-line-number="1"><span class="kw">def</span> ReLU(x, derivative<span class="op">=</span><span class="va">False</span>):</a>
<a class="sourceLine" id="cb247-2" data-line-number="2">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb247-3" data-line-number="3"><span class="co">    Computes the Rectifier Linear Unit activation function for array x</span></a>
<a class="sourceLine" id="cb247-4" data-line-number="4"><span class="co">    inputs:</span></a>
<a class="sourceLine" id="cb247-5" data-line-number="5"><span class="co">    x: array</span></a>
<a class="sourceLine" id="cb247-6" data-line-number="6"><span class="co">    derivative: if True, return the derivative else the forward pass</span></a>
<a class="sourceLine" id="cb247-7" data-line-number="7"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb247-8" data-line-number="8">    </a>
<a class="sourceLine" id="cb247-9" data-line-number="9">    <span class="cf">if</span> derivative:              <span class="co"># Return derivative of the function at x</span></a>
<a class="sourceLine" id="cb247-10" data-line-number="10">        <span class="cf">return</span> (x<span class="op">&gt;</span><span class="dv">0</span>).astype(<span class="bu">int</span>)</a>
<a class="sourceLine" id="cb247-11" data-line-number="11">    <span class="cf">else</span>:                       <span class="co"># Return forward pass of the function at x</span></a>
<a class="sourceLine" id="cb247-12" data-line-number="12">        <span class="cf">return</span> np.maximum(x, <span class="dv">0</span>)</a></code></pre></div>
</div>
<div id="visualization" class="section level3 unnumbered">
<h3>Visualization</h3>
<p>Plotting using <code>matplotlib</code>:</p>
<div class="sourceCode" id="cb248"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb248-1" data-line-number="1">x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb248-2" data-line-number="2">units <span class="op">=</span> {</a>
<a class="sourceLine" id="cb248-3" data-line-number="3">    <span class="st">&quot;Linear&quot;</span>: <span class="kw">lambda</span> x: Linear(x),</a>
<a class="sourceLine" id="cb248-4" data-line-number="4">    <span class="st">&quot;Sigmoid&quot;</span>: <span class="kw">lambda</span> x: Sigmoid(x),</a>
<a class="sourceLine" id="cb248-5" data-line-number="5">    <span class="st">&quot;ReLU&quot;</span>: <span class="kw">lambda</span> x: ReLU(x),</a>
<a class="sourceLine" id="cb248-6" data-line-number="6">    <span class="st">&quot;tanh&quot;</span>: <span class="kw">lambda</span> x: Tanh(x)</a>
<a class="sourceLine" id="cb248-7" data-line-number="7">}</a>
<a class="sourceLine" id="cb248-8" data-line-number="8"></a>
<a class="sourceLine" id="cb248-9" data-line-number="9">plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</a>
<a class="sourceLine" id="cb248-10" data-line-number="10">[plt.plot(x, unit(x), label<span class="op">=</span>unit_name, lw<span class="op">=</span><span class="dv">2</span>) </a>
<a class="sourceLine" id="cb248-11" data-line-number="11">    <span class="cf">for</span> unit_name, unit <span class="kw">in</span> units.items()]</a>
<a class="sourceLine" id="cb248-12" data-line-number="12">plt.legend(loc<span class="op">=</span><span class="dv">2</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</a>
<a class="sourceLine" id="cb248-13" data-line-number="13">plt.title(<span class="st">&#39;Activation functions&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb248-14" data-line-number="14">plt.ylim([<span class="op">-</span><span class="dv">2</span>, <span class="dv">5</span>])</a>
<a class="sourceLine" id="cb248-15" data-line-number="15">plt.xlim([<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>])</a>
<a class="sourceLine" id="cb248-16" data-line-number="16">plt.show()</a></code></pre></div>
<p><img src="9992-appendixB_files/figure-html/unnamed-chunk-12-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="softmax-in-python" class="section level2">
<h2><span class="header-section-number">B.6</span> Softmax in Python</h2>
<div class="sourceCode" id="cb249"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb249-1" data-line-number="1"><span class="co"># Source: https://dataaspirant.com/2017/03/07/difference-between-softmax-function-and-sigmoid-function/</span></a>
<a class="sourceLine" id="cb249-2" data-line-number="2"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb249-3" data-line-number="3"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</a>
<a class="sourceLine" id="cb249-4" data-line-number="4"> </a>
<a class="sourceLine" id="cb249-5" data-line-number="5"> </a>
<a class="sourceLine" id="cb249-6" data-line-number="6"><span class="kw">def</span> softmax(inputs):</a>
<a class="sourceLine" id="cb249-7" data-line-number="7">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb249-8" data-line-number="8"><span class="co">    Calculate the softmax for the give inputs (array)</span></a>
<a class="sourceLine" id="cb249-9" data-line-number="9"><span class="co">    :param inputs:</span></a>
<a class="sourceLine" id="cb249-10" data-line-number="10"><span class="co">    :return:</span></a>
<a class="sourceLine" id="cb249-11" data-line-number="11"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb249-12" data-line-number="12">    <span class="cf">return</span> np.exp(inputs) <span class="op">/</span> <span class="bu">float</span>(<span class="bu">sum</span>(np.exp(inputs)))</a>
<a class="sourceLine" id="cb249-13" data-line-number="13"> </a>
<a class="sourceLine" id="cb249-14" data-line-number="14"> </a>
<a class="sourceLine" id="cb249-15" data-line-number="15"><span class="kw">def</span> line_graph(x, y, x_title, y_title):</a>
<a class="sourceLine" id="cb249-16" data-line-number="16">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb249-17" data-line-number="17"><span class="co">    Draw line graph with x and y values</span></a>
<a class="sourceLine" id="cb249-18" data-line-number="18"><span class="co">    :param x:</span></a>
<a class="sourceLine" id="cb249-19" data-line-number="19"><span class="co">    :param y:</span></a>
<a class="sourceLine" id="cb249-20" data-line-number="20"><span class="co">    :param x_title:</span></a>
<a class="sourceLine" id="cb249-21" data-line-number="21"><span class="co">    :param y_title:</span></a>
<a class="sourceLine" id="cb249-22" data-line-number="22"><span class="co">    :return:</span></a>
<a class="sourceLine" id="cb249-23" data-line-number="23"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb249-24" data-line-number="24">    plt.plot(x, y)</a>
<a class="sourceLine" id="cb249-25" data-line-number="25">    plt.xlabel(x_title)</a>
<a class="sourceLine" id="cb249-26" data-line-number="26">    plt.ylabel(y_title)</a>
<a class="sourceLine" id="cb249-27" data-line-number="27">    plt.show()</a>
<a class="sourceLine" id="cb249-28" data-line-number="28"> </a>
<a class="sourceLine" id="cb249-29" data-line-number="29"> </a>
<a class="sourceLine" id="cb249-30" data-line-number="30">graph_x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb249-31" data-line-number="31">graph_y <span class="op">=</span> softmax(graph_x)</a>
<a class="sourceLine" id="cb249-32" data-line-number="32"> </a>
<a class="sourceLine" id="cb249-33" data-line-number="33"><span class="bu">print</span>(<span class="st">&quot;Graph X readings: </span><span class="sc">{}</span><span class="st">&quot;</span>.<span class="bu">format</span>(graph_x))</a>
<a class="sourceLine" id="cb249-34" data-line-number="34"><span class="bu">print</span>(<span class="st">&quot;Graph Y readings: </span><span class="sc">{}</span><span class="st">&quot;</span>.<span class="bu">format</span>(graph_y))</a>
<a class="sourceLine" id="cb249-35" data-line-number="35"> </a>
<a class="sourceLine" id="cb249-36" data-line-number="36">line_graph(graph_x, graph_y, <span class="st">&quot;Inputs&quot;</span>, <span class="st">&quot;Softmax Scores&quot;</span>)</a></code></pre></div>
<p><img src="9992-appendixB_files/figure-html/unnamed-chunk-13-1.png" width="70%" style="display: block; margin: auto;" /></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="appendixA.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["rtorch-book.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

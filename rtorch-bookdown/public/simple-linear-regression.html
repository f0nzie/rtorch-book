<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Simple linear regression | A Minimal rTorch Tutorial</title>
  <meta name="description" content="This is a minimal tutorial of using the rTorch package to have fun while doing machine learning. This book was produced with bookdown." />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Simple linear regression | A Minimal rTorch Tutorial" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal tutorial of using the rTorch package to have fun while doing machine learning. This book was produced with bookdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Simple linear regression | A Minimal rTorch Tutorial" />
  
  <meta name="twitter:description" content="This is a minimal tutorial of using the rTorch package to have fun while doing machine learning. This book was produced with bookdown." />
  

<meta name="author" content="Alfonso R. Reyes" />


<meta name="date" content="2019-09-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="a-classic-classification-problem.html"/>
<link rel="next" href="rainfall-linear-regression.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal rTorch Tutorial</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#python-anaconda"><i class="fa fa-check"></i>Python Anaconda</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#example"><i class="fa fa-check"></i>Example</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#automatic-installation"><i class="fa fa-check"></i>Automatic installation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Getting Started</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#motivation"><i class="fa fa-check"></i><b>1.1</b> Motivation</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#how-do-we-start-using-rtorch"><i class="fa fa-check"></i><b>1.2</b> How do we start using <code>rTorch</code></a><ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#getting-the-pytorch-version"><i class="fa fa-check"></i><b>1.2.1</b> Getting the PyTorch version</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#pytorch-configuration"><i class="fa fa-check"></i><b>1.2.2</b> PyTorch configuration</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#what-can-you-do-with-rtorch"><i class="fa fa-check"></i><b>1.3</b> What can you do with <code>rTorch</code></a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#callable-pytorch-modules"><i class="fa fa-check"></i><b>1.4</b> Callable PyTorch modules</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#the-torchvision-module"><i class="fa fa-check"></i><b>1.4.1</b> The <code>torchvision</code> module</a></li>
<li class="chapter" data-level="1.4.2" data-path="intro.html"><a href="intro.html#np-the-numpy-module"><i class="fa fa-check"></i><b>1.4.2</b> <code>np</code>: the <code>numpy</code> module</a></li>
<li class="chapter" data-level="1.4.3" data-path="intro.html"><a href="intro.html#python-built-in-functions"><i class="fa fa-check"></i><b>1.4.3</b> Python built-in functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html"><i class="fa fa-check"></i><b>2</b> rTorch vs PyTorch: Whatâ€™s different</a><ul>
<li class="chapter" data-level="2.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#calling-objects-from-pytorch"><i class="fa fa-check"></i><b>2.1</b> Calling objects from PyTorch</a></li>
<li class="chapter" data-level="2.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#call-a-module-from-pytorch"><i class="fa fa-check"></i><b>2.2</b> Call a module from PyTorch</a></li>
<li class="chapter" data-level="2.3" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#show-the-attributes-methods-of-a-class-or-pytorch-object"><i class="fa fa-check"></i><b>2.3</b> Show the attributes (methods) of a class or PyTorch object</a></li>
<li class="chapter" data-level="2.4" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#enumeration"><i class="fa fa-check"></i><b>2.4</b> Enumeration</a></li>
<li class="chapter" data-level="2.5" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#how-to-iterate"><i class="fa fa-check"></i><b>2.5</b> How to iterate</a><ul>
<li class="chapter" data-level="2.5.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#using-enumerate-and-iterate"><i class="fa fa-check"></i><b>2.5.1</b> Using <code>enumerate</code> and <code>iterate</code></a></li>
<li class="chapter" data-level="2.5.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#using-a-for-loop-to-iterate"><i class="fa fa-check"></i><b>2.5.2</b> Using a <code>for-loop</code> to iterate</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#zero-gradient"><i class="fa fa-check"></i><b>2.6</b> Zero gradient</a><ul>
<li class="chapter" data-level="2.6.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#version-in-python"><i class="fa fa-check"></i><b>2.6.1</b> Version in Python</a></li>
<li class="chapter" data-level="2.6.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#version-in-r"><i class="fa fa-check"></i><b>2.6.2</b> Version in R</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#transform-a-tensor"><i class="fa fa-check"></i><b>2.7</b> Transform a tensor</a></li>
<li class="chapter" data-level="2.8" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#build-a-model-class"><i class="fa fa-check"></i><b>2.8</b> Build a model class</a><ul>
<li class="chapter" data-level="2.8.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#example-1"><i class="fa fa-check"></i><b>2.8.1</b> Example 1</a></li>
<li class="chapter" data-level="2.8.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#example-2-logistic-regression"><i class="fa fa-check"></i><b>2.8.2</b> Example 2: Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#convert-a-tensor-to-numpy-object"><i class="fa fa-check"></i><b>2.9</b> Convert a tensor to <code>numpy</code> object</a></li>
<li class="chapter" data-level="2.10" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#convert-a-numpy-object-to-an-r-object"><i class="fa fa-check"></i><b>2.10</b> Convert a <code>numpy</code> object to an <code>R</code> object</a></li>
</ul></li>
<li class="part"><span><b>II Basic Tensor Operations</b></span></li>
<li class="chapter" data-level="3" data-path="tensors.html"><a href="tensors.html"><i class="fa fa-check"></i><b>3</b> Tensors</a><ul>
<li class="chapter" data-level="3.1" data-path="tensors.html"><a href="tensors.html#tensor-data-types"><i class="fa fa-check"></i><b>3.1</b> Tensor data types</a></li>
<li class="chapter" data-level="3.2" data-path="tensors.html"><a href="tensors.html#arithmetic-of-tensors"><i class="fa fa-check"></i><b>3.2</b> Arithmetic of tensors</a><ul>
<li class="chapter" data-level="3.2.1" data-path="tensors.html"><a href="tensors.html#add-tensors"><i class="fa fa-check"></i><b>3.2.1</b> Add tensors</a></li>
<li class="chapter" data-level="3.2.2" data-path="tensors.html"><a href="tensors.html#multiply-a-tensor-by-a-scalar"><i class="fa fa-check"></i><b>3.2.2</b> Multiply a tensor by a scalar</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="tensors.html"><a href="tensors.html#numpy-and-pytorch"><i class="fa fa-check"></i><b>3.3</b> NumPy and PyTorch</a><ul>
<li class="chapter" data-level="3.3.1" data-path="tensors.html"><a href="tensors.html#tuples-python-and-vectors-r"><i class="fa fa-check"></i><b>3.3.1</b> Tuples (Python) and vectors (R)</a></li>
<li class="chapter" data-level="3.3.2" data-path="tensors.html"><a href="tensors.html#make-a-numpy-array-a-tensor-with-as_tensor"><i class="fa fa-check"></i><b>3.3.2</b> Make a numpy array a tensor with <code>as_tensor()</code></a></li>
<li class="chapter" data-level="3.3.3" data-path="tensors.html"><a href="tensors.html#tensor-to-array-and-viceversa"><i class="fa fa-check"></i><b>3.3.3</b> Tensor to array, and viceversa</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="tensors.html"><a href="tensors.html#create-tensors"><i class="fa fa-check"></i><b>3.4</b> Create tensors</a></li>
<li class="chapter" data-level="3.5" data-path="tensors.html"><a href="tensors.html#tensor-resizing"><i class="fa fa-check"></i><b>3.5</b> Tensor resizing</a><ul>
<li class="chapter" data-level="3.5.1" data-path="tensors.html"><a href="tensors.html#concatenate-tensors"><i class="fa fa-check"></i><b>3.5.1</b> Concatenate tensors</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="tensors.html"><a href="tensors.html#reshape-tensors"><i class="fa fa-check"></i><b>3.6</b> Reshape tensors</a><ul>
<li class="chapter" data-level="3.6.1" data-path="tensors.html"><a href="tensors.html#with-function-chunk"><i class="fa fa-check"></i><b>3.6.1</b> With function <code>chunk()</code>:</a></li>
<li class="chapter" data-level="3.6.2" data-path="tensors.html"><a href="tensors.html#with-index_select"><i class="fa fa-check"></i><b>3.6.2</b> With <code>index_select()</code>:</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="tensors.html"><a href="tensors.html#special-tensors"><i class="fa fa-check"></i><b>3.7</b> Special tensors</a><ul>
<li class="chapter" data-level="3.7.1" data-path="tensors.html"><a href="tensors.html#identity-matrix"><i class="fa fa-check"></i><b>3.7.1</b> Identity matrix</a></li>
<li class="chapter" data-level="3.7.2" data-path="tensors.html"><a href="tensors.html#ones"><i class="fa fa-check"></i><b>3.7.2</b> Ones</a></li>
<li class="chapter" data-level="3.7.3" data-path="tensors.html"><a href="tensors.html#zeros"><i class="fa fa-check"></i><b>3.7.3</b> Zeros</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="tensors.html"><a href="tensors.html#tensor-fill"><i class="fa fa-check"></i><b>3.8</b> Tensor fill</a><ul>
<li class="chapter" data-level="3.8.1" data-path="tensors.html"><a href="tensors.html#initialize-a-linear-or-log-scale-tensor"><i class="fa fa-check"></i><b>3.8.1</b> Initialize a linear or log scale Tensor</a></li>
<li class="chapter" data-level="3.8.2" data-path="tensors.html"><a href="tensors.html#inplace-out-of-place"><i class="fa fa-check"></i><b>3.8.2</b> Inplace / Out-of-place</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="tensors.html"><a href="tensors.html#access-to-tensor-elements"><i class="fa fa-check"></i><b>3.9</b> Access to tensor elements</a><ul>
<li class="chapter" data-level="3.9.1" data-path="tensors.html"><a href="tensors.html#using-indices-to-access-elements"><i class="fa fa-check"></i><b>3.9.1</b> Using indices to access elements</a></li>
<li class="chapter" data-level="3.9.2" data-path="tensors.html"><a href="tensors.html#using-the-take-function"><i class="fa fa-check"></i><b>3.9.2</b> Using the <code>take</code> function</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="tensors.html"><a href="tensors.html#other-tensor-operations"><i class="fa fa-check"></i><b>3.10</b> Other tensor operations</a><ul>
<li class="chapter" data-level="3.10.1" data-path="tensors.html"><a href="tensors.html#cross-product"><i class="fa fa-check"></i><b>3.10.1</b> Cross product</a></li>
<li class="chapter" data-level="3.10.2" data-path="tensors.html"><a href="tensors.html#dot-product"><i class="fa fa-check"></i><b>3.10.2</b> Dot product</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="tensors.html"><a href="tensors.html#logical-operations"><i class="fa fa-check"></i><b>3.11</b> Logical operations</a><ul>
<li class="chapter" data-level="3.11.1" data-path="tensors.html"><a href="tensors.html#logical-not"><i class="fa fa-check"></i><b>3.11.1</b> Logical NOT</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="tensors.html"><a href="tensors.html#distributions"><i class="fa fa-check"></i><b>3.12</b> Distributions</a><ul>
<li class="chapter" data-level="3.12.1" data-path="tensors.html"><a href="tensors.html#uniform-matrix"><i class="fa fa-check"></i><b>3.12.1</b> Uniform matrix</a></li>
<li class="chapter" data-level="3.12.2" data-path="tensors.html"><a href="tensors.html#binomial-distribution"><i class="fa fa-check"></i><b>3.12.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="3.12.3" data-path="tensors.html"><a href="tensors.html#exponential-distribution"><i class="fa fa-check"></i><b>3.12.3</b> Exponential distribution</a></li>
<li class="chapter" data-level="3.12.4" data-path="tensors.html"><a href="tensors.html#weibull-distribution"><i class="fa fa-check"></i><b>3.12.4</b> Weibull distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linearalgebra.html"><a href="linearalgebra.html"><i class="fa fa-check"></i><b>4</b> Linear Algebra with Torch</a><ul>
<li class="chapter" data-level="4.1" data-path="linearalgebra.html"><a href="linearalgebra.html#scalars"><i class="fa fa-check"></i><b>4.1</b> Scalars</a></li>
<li class="chapter" data-level="4.2" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors"><i class="fa fa-check"></i><b>4.2</b> Vectors</a></li>
<li class="chapter" data-level="4.3" data-path="linearalgebra.html"><a href="linearalgebra.html#matrices"><i class="fa fa-check"></i><b>4.3</b> Matrices</a></li>
<li class="chapter" data-level="4.4" data-path="linearalgebra.html"><a href="linearalgebra.html#d-tensors"><i class="fa fa-check"></i><b>4.4</b> 3D+ tensors</a></li>
<li class="chapter" data-level="4.5" data-path="linearalgebra.html"><a href="linearalgebra.html#transpose-of-a-matrix"><i class="fa fa-check"></i><b>4.5</b> Transpose of a matrix</a></li>
<li class="chapter" data-level="4.6" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors-special-case-of-a-matrix"><i class="fa fa-check"></i><b>4.6</b> Vectors, special case of a matrix</a></li>
<li class="chapter" data-level="4.7" data-path="linearalgebra.html"><a href="linearalgebra.html#tensor-arithmetic"><i class="fa fa-check"></i><b>4.7</b> Tensor arithmetic</a></li>
<li class="chapter" data-level="4.8" data-path="linearalgebra.html"><a href="linearalgebra.html#add-a-scalar-to-a-tensor"><i class="fa fa-check"></i><b>4.8</b> Add a scalar to a tensor</a></li>
<li class="chapter" data-level="4.9" data-path="linearalgebra.html"><a href="linearalgebra.html#multiplying-tensors"><i class="fa fa-check"></i><b>4.9</b> Multiplying tensors</a></li>
<li class="chapter" data-level="4.10" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-1"><i class="fa fa-check"></i><b>4.10</b> Dot product</a></li>
</ul></li>
<li class="part"><span><b>III Logistic Regression</b></span></li>
<li class="chapter" data-level="5" data-path="mnistdigits.html"><a href="mnistdigits.html"><i class="fa fa-check"></i><b>5</b> Example 1: MNIST handwritten digits</a><ul>
<li class="chapter" data-level="5.1" data-path="mnistdigits.html"><a href="mnistdigits.html#hyperparameters"><i class="fa fa-check"></i><b>5.1</b> Hyperparameters</a></li>
<li class="chapter" data-level="5.2" data-path="mnistdigits.html"><a href="mnistdigits.html#read-datasets"><i class="fa fa-check"></i><b>5.2</b> Read datasets</a></li>
<li class="chapter" data-level="5.3" data-path="mnistdigits.html"><a href="mnistdigits.html#define-the-model"><i class="fa fa-check"></i><b>5.3</b> Define the model</a></li>
<li class="chapter" data-level="5.4" data-path="mnistdigits.html"><a href="mnistdigits.html#training"><i class="fa fa-check"></i><b>5.4</b> Training</a></li>
<li class="chapter" data-level="5.5" data-path="mnistdigits.html"><a href="mnistdigits.html#prediction"><i class="fa fa-check"></i><b>5.5</b> Prediction</a></li>
<li class="chapter" data-level="5.6" data-path="mnistdigits.html"><a href="mnistdigits.html#save-the-model"><i class="fa fa-check"></i><b>5.6</b> Save the model</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="the-sigmoid-function.html"><a href="the-sigmoid-function.html"><i class="fa fa-check"></i><b>6</b> The Sigmoid function</a></li>
<li class="chapter" data-level="7" data-path="a-classic-classification-problem.html"><a href="a-classic-classification-problem.html"><i class="fa fa-check"></i><b>7</b> A classic classification problem</a></li>
<li class="part"><span><b>IV Linear Regression</b></span></li>
<li class="chapter" data-level="8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>8</b> Simple linear regression</a><ul>
<li class="chapter" data-level="8.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#introduction"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#generate-the-dataset"><i class="fa fa-check"></i><b>8.2</b> Generate the dataset</a></li>
<li class="chapter" data-level="8.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#convert-arrays-to-tensors"><i class="fa fa-check"></i><b>8.3</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="8.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#converting-from-numpy-to-tensor"><i class="fa fa-check"></i><b>8.4</b> Converting from numpy to tensor</a></li>
<li class="chapter" data-level="8.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#creating-the-network-model"><i class="fa fa-check"></i><b>8.5</b> Creating the network model</a></li>
<li class="chapter" data-level="8.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#optimizer-and-loss"><i class="fa fa-check"></i><b>8.6</b> Optimizer and Loss</a></li>
<li class="chapter" data-level="8.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#training-1"><i class="fa fa-check"></i><b>8.7</b> Training</a></li>
<li class="chapter" data-level="8.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#results"><i class="fa fa-check"></i><b>8.8</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html"><i class="fa fa-check"></i><b>9</b> Rainfall. Linear Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#training-data"><i class="fa fa-check"></i><b>9.1</b> Training data</a></li>
<li class="chapter" data-level="9.2" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#convert-arrays-to-tensors-1"><i class="fa fa-check"></i><b>9.2</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="9.3" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#build-the-model"><i class="fa fa-check"></i><b>9.3</b> Build the model</a></li>
<li class="chapter" data-level="9.4" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#generate-predictions"><i class="fa fa-check"></i><b>9.4</b> Generate predictions</a></li>
<li class="chapter" data-level="9.5" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#loss-function"><i class="fa fa-check"></i><b>9.5</b> Loss Function</a></li>
<li class="chapter" data-level="9.6" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#step-by-step-process"><i class="fa fa-check"></i><b>9.6</b> Step by step process</a><ul>
<li class="chapter" data-level="9.6.1" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#compute-the-losses"><i class="fa fa-check"></i><b>9.6.1</b> Compute the losses</a></li>
<li class="chapter" data-level="9.6.2" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#compute-gradients"><i class="fa fa-check"></i><b>9.6.2</b> Compute Gradients</a></li>
<li class="chapter" data-level="9.6.3" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#reset-the-gradients"><i class="fa fa-check"></i><b>9.6.3</b> Reset the gradients</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#all-together-train-for-multiple-epochs"><i class="fa fa-check"></i><b>9.7</b> All together: train for multiple epochs</a></li>
</ul></li>
<li class="part"><span><b>V Neural Networks</b></span></li>
<li class="chapter" data-level="10" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html"><i class="fa fa-check"></i><b>10</b> A two-layer neural network</a><ul>
<li class="chapter" data-level="10.1" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#load-the-libraries"><i class="fa fa-check"></i><b>10.1</b> Load the libraries</a></li>
<li class="chapter" data-level="10.2" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#dataset"><i class="fa fa-check"></i><b>10.2</b> Dataset</a></li>
<li class="chapter" data-level="10.3" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#run-the-model-for-50-iterations"><i class="fa fa-check"></i><b>10.3</b> Run the model for 50 iterations</a></li>
<li class="chapter" data-level="10.4" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#run-it-at-100-iterations"><i class="fa fa-check"></i><b>10.4</b> Run it at 100 iterations</a></li>
<li class="chapter" data-level="10.5" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#original-pytorch-code"><i class="fa fa-check"></i><b>10.5</b> Original PyTorch code</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html"><i class="fa fa-check"></i><b>11</b> A very simple neural network</a><ul>
<li class="chapter" data-level="11.1" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#introduction-1"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#select-device"><i class="fa fa-check"></i><b>11.2</b> Select device</a></li>
<li class="chapter" data-level="11.3" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#create-the-dataset"><i class="fa fa-check"></i><b>11.3</b> Create the dataset</a></li>
<li class="chapter" data-level="11.4" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#define-the-model-1"><i class="fa fa-check"></i><b>11.4</b> Define the model</a></li>
<li class="chapter" data-level="11.5" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#loss-function-1"><i class="fa fa-check"></i><b>11.5</b> Loss function</a></li>
<li class="chapter" data-level="11.6" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#iterate-through-batches"><i class="fa fa-check"></i><b>11.6</b> Iterate through batches</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="neural-networks-2.html"><a href="neural-networks-2.html"><i class="fa fa-check"></i><b>12</b> Neural Networks 2</a><ul>
<li class="chapter" data-level="12.1" data-path="neural-networks-2.html"><a href="neural-networks-2.html#nn2-1"><i class="fa fa-check"></i><b>12.1</b> nn2 1</a></li>
<li class="chapter" data-level="12.2" data-path="neural-networks-2.html"><a href="neural-networks-2.html#nn2-2"><i class="fa fa-check"></i><b>12.2</b> nn2 2</a></li>
</ul></li>
<li class="part"><span><b>VI PyTorch and R data structures</b></span></li>
<li class="chapter" data-level="13" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html"><i class="fa fa-check"></i><b>13</b> Working with data.frame</a><ul>
<li class="chapter" data-level="13.1" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#load-pytorch-libraries"><i class="fa fa-check"></i><b>13.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="13.2" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#load-dataset"><i class="fa fa-check"></i><b>13.2</b> Load dataset</a></li>
<li class="chapter" data-level="13.3" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#summary-statistics-for-tensors"><i class="fa fa-check"></i><b>13.3</b> Summary statistics for tensors</a><ul>
<li class="chapter" data-level="13.3.1" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#using-data.frame"><i class="fa fa-check"></i><b>13.3.1</b> using <code>data.frame</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="working-with-data-table.html"><a href="working-with-data-table.html"><i class="fa fa-check"></i><b>14</b> Working with data.table</a><ul>
<li class="chapter" data-level="14.1" data-path="working-with-data-table.html"><a href="working-with-data-table.html#load-pytorch-libraries-1"><i class="fa fa-check"></i><b>14.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="14.2" data-path="working-with-data-table.html"><a href="working-with-data-table.html#load-dataset-1"><i class="fa fa-check"></i><b>14.2</b> Load dataset</a></li>
<li class="chapter" data-level="14.3" data-path="working-with-data-table.html"><a href="working-with-data-table.html#read-the-datasets-without-normalization"><i class="fa fa-check"></i><b>14.3</b> Read the datasets without normalization</a></li>
<li class="chapter" data-level="14.4" data-path="working-with-data-table.html"><a href="working-with-data-table.html#using-data.table"><i class="fa fa-check"></i><b>14.4</b> Using <code>data.table</code></a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendixA.html"><a href="appendixA.html"><i class="fa fa-check"></i><b>A</b> Statistical Background</a><ul>
<li class="chapter" data-level="A.1" data-path="appendixA.html"><a href="appendixA.html#basic-statistical-terms"><i class="fa fa-check"></i><b>A.1</b> Basic statistical terms</a><ul>
<li class="chapter" data-level="A.1.1" data-path="appendixA.html"><a href="appendixA.html#five-number-summary"><i class="fa fa-check"></i><b>A.1.1</b> Five-number summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Minimal rTorch Tutorial</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simple-linear-regression" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Simple linear regression</h1>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">8.1</span> Introduction</h2>
<p>Source: <a href="https://www.guru99.com/pytorch-tutorial.html" class="uri">https://www.guru99.com/pytorch-tutorial.html</a></p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb185-1" data-line-number="1"><span class="kw">library</span>(rTorch)</a>
<a class="sourceLine" id="cb185-2" data-line-number="2"></a>
<a class="sourceLine" id="cb185-3" data-line-number="3">nn       &lt;-<span class="st"> </span>torch<span class="op">$</span>nn</a>
<a class="sourceLine" id="cb185-4" data-line-number="4">Variable &lt;-<span class="st"> </span>torch<span class="op">$</span>autograd<span class="op">$</span>Variable</a>
<a class="sourceLine" id="cb185-5" data-line-number="5"></a>
<a class="sourceLine" id="cb185-6" data-line-number="6">torch<span class="op">$</span><span class="kw">manual_seed</span>(<span class="dv">123</span>)</a>
<a class="sourceLine" id="cb185-7" data-line-number="7"><span class="co">#&gt; &lt;torch._C.Generator&gt;</span></a></code></pre></div>
</div>
<div id="generate-the-dataset" class="section level2">
<h2><span class="header-section-number">8.2</span> Generate the dataset</h2>
<p>Before you start the training process, you need to know our data. You make a random function to test our model. <span class="math inline">\(Y = x3 sin(x)+ 3x+0.8 rand(100)\)</span></p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb186-1" data-line-number="1"></a>
<a class="sourceLine" id="cb186-2" data-line-number="2">np<span class="op">$</span>random<span class="op">$</span><span class="kw">seed</span>(123L)</a>
<a class="sourceLine" id="cb186-3" data-line-number="3"></a>
<a class="sourceLine" id="cb186-4" data-line-number="4">x =<span class="st"> </span>np<span class="op">$</span>random<span class="op">$</span><span class="kw">rand</span>(100L)</a>
<a class="sourceLine" id="cb186-5" data-line-number="5">y =<span class="st"> </span>np<span class="op">$</span><span class="kw">sin</span>(x) <span class="op">*</span><span class="st"> </span>np<span class="op">$</span><span class="kw">power</span>(x, 3L) <span class="op">+</span><span class="st"> </span>3L <span class="op">*</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>np<span class="op">$</span>random<span class="op">$</span><span class="kw">rand</span>(100L) <span class="op">*</span><span class="st"> </span><span class="fl">0.8</span></a>
<a class="sourceLine" id="cb186-6" data-line-number="6"></a>
<a class="sourceLine" id="cb186-7" data-line-number="7"><span class="kw">plot</span>(x, y)</a></code></pre></div>
<p><img src="0401-linear_regression-simple_files/figure-html/datasets-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="convert-arrays-to-tensors" class="section level2">
<h2><span class="header-section-number">8.3</span> Convert arrays to tensors</h2>
<p>Before you start the training process, you need to convert the numpy array to Variables that supported by Torch and autograd.</p>
</div>
<div id="converting-from-numpy-to-tensor" class="section level2">
<h2><span class="header-section-number">8.4</span> Converting from numpy to tensor</h2>
<p>Notice that before converting to a Torch tensor, we need first to convert the R numeric vector to a <code>numpy</code> array:</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb187-1" data-line-number="1"><span class="co"># convert numpy array to tensor in shape of input size</span></a>
<a class="sourceLine" id="cb187-2" data-line-number="2">x &lt;-<span class="st"> </span><span class="kw">r_to_py</span>(x)</a>
<a class="sourceLine" id="cb187-3" data-line-number="3">y &lt;-<span class="st"> </span><span class="kw">r_to_py</span>(y)</a>
<a class="sourceLine" id="cb187-4" data-line-number="4">x =<span class="st"> </span>torch<span class="op">$</span><span class="kw">from_numpy</span>(x<span class="op">$</span><span class="kw">reshape</span>(<span class="op">-</span>1L, 1L))<span class="op">$</span><span class="kw">float</span>()</a>
<a class="sourceLine" id="cb187-5" data-line-number="5">y =<span class="st"> </span>torch<span class="op">$</span><span class="kw">from_numpy</span>(y<span class="op">$</span><span class="kw">reshape</span>(<span class="op">-</span>1L, 1L))<span class="op">$</span><span class="kw">float</span>()</a>
<a class="sourceLine" id="cb187-6" data-line-number="6"><span class="kw">print</span>(x, y)</a>
<a class="sourceLine" id="cb187-7" data-line-number="7"><span class="co">#&gt; tensor([[0.6965],</span></a>
<a class="sourceLine" id="cb187-8" data-line-number="8"><span class="co">#&gt;         [0.2861],</span></a>
<a class="sourceLine" id="cb187-9" data-line-number="9"><span class="co">#&gt;         [0.2269],</span></a>
<a class="sourceLine" id="cb187-10" data-line-number="10"><span class="co">#&gt;         [0.5513],</span></a>
<a class="sourceLine" id="cb187-11" data-line-number="11"><span class="co">#&gt;         [0.7195],</span></a>
<a class="sourceLine" id="cb187-12" data-line-number="12"><span class="co">#&gt;         [0.4231],</span></a>
<a class="sourceLine" id="cb187-13" data-line-number="13"><span class="co">#&gt;         [0.9808],</span></a>
<a class="sourceLine" id="cb187-14" data-line-number="14"><span class="co">#&gt;         [0.6848],</span></a>
<a class="sourceLine" id="cb187-15" data-line-number="15"><span class="co">#&gt;         [0.4809],</span></a>
<a class="sourceLine" id="cb187-16" data-line-number="16"><span class="co">#&gt;         [0.3921],</span></a>
<a class="sourceLine" id="cb187-17" data-line-number="17"><span class="co">#&gt;         [0.3432],</span></a>
<a class="sourceLine" id="cb187-18" data-line-number="18"><span class="co">#&gt;         [0.7290],</span></a>
<a class="sourceLine" id="cb187-19" data-line-number="19"><span class="co">#&gt;         [0.4386],</span></a>
<a class="sourceLine" id="cb187-20" data-line-number="20"><span class="co">#&gt;         [0.0597],</span></a>
<a class="sourceLine" id="cb187-21" data-line-number="21"><span class="co">#&gt;         [0.3980],</span></a>
<a class="sourceLine" id="cb187-22" data-line-number="22"><span class="co">#&gt;         [0.7380],</span></a>
<a class="sourceLine" id="cb187-23" data-line-number="23"><span class="co">#&gt;         [0.1825],</span></a>
<a class="sourceLine" id="cb187-24" data-line-number="24"><span class="co">#&gt;         [0.1755],</span></a>
<a class="sourceLine" id="cb187-25" data-line-number="25"><span class="co">#&gt;         [0.5316],</span></a>
<a class="sourceLine" id="cb187-26" data-line-number="26"><span class="co">#&gt;         [0.5318],</span></a>
<a class="sourceLine" id="cb187-27" data-line-number="27"><span class="co">#&gt;         [0.6344],</span></a>
<a class="sourceLine" id="cb187-28" data-line-number="28"><span class="co">#&gt;         [0.8494],</span></a>
<a class="sourceLine" id="cb187-29" data-line-number="29"><span class="co">#&gt;         [0.7245],</span></a>
<a class="sourceLine" id="cb187-30" data-line-number="30"><span class="co">#&gt;         [0.6110],</span></a>
<a class="sourceLine" id="cb187-31" data-line-number="31"><span class="co">#&gt;         [0.7224],</span></a>
<a class="sourceLine" id="cb187-32" data-line-number="32"><span class="co">#&gt;         [0.3230],</span></a>
<a class="sourceLine" id="cb187-33" data-line-number="33"><span class="co">#&gt;         [0.3618],</span></a>
<a class="sourceLine" id="cb187-34" data-line-number="34"><span class="co">#&gt;         [0.2283],</span></a>
<a class="sourceLine" id="cb187-35" data-line-number="35"><span class="co">#&gt;         [0.2937],</span></a>
<a class="sourceLine" id="cb187-36" data-line-number="36"><span class="co">#&gt;         [0.6310],</span></a>
<a class="sourceLine" id="cb187-37" data-line-number="37"><span class="co">#&gt;         [0.0921],</span></a>
<a class="sourceLine" id="cb187-38" data-line-number="38"><span class="co">#&gt;         [0.4337],</span></a>
<a class="sourceLine" id="cb187-39" data-line-number="39"><span class="co">#&gt;         [0.4309],</span></a>
<a class="sourceLine" id="cb187-40" data-line-number="40"><span class="co">#&gt;         [0.4937],</span></a>
<a class="sourceLine" id="cb187-41" data-line-number="41"><span class="co">#&gt;         [0.4258],</span></a>
<a class="sourceLine" id="cb187-42" data-line-number="42"><span class="co">#&gt;         [0.3123],</span></a>
<a class="sourceLine" id="cb187-43" data-line-number="43"><span class="co">#&gt;         [0.4264],</span></a>
<a class="sourceLine" id="cb187-44" data-line-number="44"><span class="co">#&gt;         [0.8934],</span></a>
<a class="sourceLine" id="cb187-45" data-line-number="45"><span class="co">#&gt;         [0.9442],</span></a>
<a class="sourceLine" id="cb187-46" data-line-number="46"><span class="co">#&gt;         [0.5018],</span></a>
<a class="sourceLine" id="cb187-47" data-line-number="47"><span class="co">#&gt;         [0.6240],</span></a>
<a class="sourceLine" id="cb187-48" data-line-number="48"><span class="co">#&gt;         [0.1156],</span></a>
<a class="sourceLine" id="cb187-49" data-line-number="49"><span class="co">#&gt;         [0.3173],</span></a>
<a class="sourceLine" id="cb187-50" data-line-number="50"><span class="co">#&gt;         [0.4148],</span></a>
<a class="sourceLine" id="cb187-51" data-line-number="51"><span class="co">#&gt;         [0.8663],</span></a>
<a class="sourceLine" id="cb187-52" data-line-number="52"><span class="co">#&gt;         [0.2505],</span></a>
<a class="sourceLine" id="cb187-53" data-line-number="53"><span class="co">#&gt;         [0.4830],</span></a>
<a class="sourceLine" id="cb187-54" data-line-number="54"><span class="co">#&gt;         [0.9856],</span></a>
<a class="sourceLine" id="cb187-55" data-line-number="55"><span class="co">#&gt;         [0.5195],</span></a>
<a class="sourceLine" id="cb187-56" data-line-number="56"><span class="co">#&gt;         [0.6129],</span></a>
<a class="sourceLine" id="cb187-57" data-line-number="57"><span class="co">#&gt;         [0.1206],</span></a>
<a class="sourceLine" id="cb187-58" data-line-number="58"><span class="co">#&gt;         [0.8263],</span></a>
<a class="sourceLine" id="cb187-59" data-line-number="59"><span class="co">#&gt;         [0.6031],</span></a>
<a class="sourceLine" id="cb187-60" data-line-number="60"><span class="co">#&gt;         [0.5451],</span></a>
<a class="sourceLine" id="cb187-61" data-line-number="61"><span class="co">#&gt;         [0.3428],</span></a>
<a class="sourceLine" id="cb187-62" data-line-number="62"><span class="co">#&gt;         [0.3041],</span></a>
<a class="sourceLine" id="cb187-63" data-line-number="63"><span class="co">#&gt;         [0.4170],</span></a>
<a class="sourceLine" id="cb187-64" data-line-number="64"><span class="co">#&gt;         [0.6813],</span></a>
<a class="sourceLine" id="cb187-65" data-line-number="65"><span class="co">#&gt;         [0.8755],</span></a>
<a class="sourceLine" id="cb187-66" data-line-number="66"><span class="co">#&gt;         [0.5104],</span></a>
<a class="sourceLine" id="cb187-67" data-line-number="67"><span class="co">#&gt;         [0.6693],</span></a>
<a class="sourceLine" id="cb187-68" data-line-number="68"><span class="co">#&gt;         [0.5859],</span></a>
<a class="sourceLine" id="cb187-69" data-line-number="69"><span class="co">#&gt;         [0.6249],</span></a>
<a class="sourceLine" id="cb187-70" data-line-number="70"><span class="co">#&gt;         [0.6747],</span></a>
<a class="sourceLine" id="cb187-71" data-line-number="71"><span class="co">#&gt;         [0.8423],</span></a>
<a class="sourceLine" id="cb187-72" data-line-number="72"><span class="co">#&gt;         [0.0832],</span></a>
<a class="sourceLine" id="cb187-73" data-line-number="73"><span class="co">#&gt;         [0.7637],</span></a>
<a class="sourceLine" id="cb187-74" data-line-number="74"><span class="co">#&gt;         [0.2437],</span></a>
<a class="sourceLine" id="cb187-75" data-line-number="75"><span class="co">#&gt;         [0.1942],</span></a>
<a class="sourceLine" id="cb187-76" data-line-number="76"><span class="co">#&gt;         [0.5725],</span></a>
<a class="sourceLine" id="cb187-77" data-line-number="77"><span class="co">#&gt;         [0.0957],</span></a>
<a class="sourceLine" id="cb187-78" data-line-number="78"><span class="co">#&gt;         [0.8853],</span></a>
<a class="sourceLine" id="cb187-79" data-line-number="79"><span class="co">#&gt;         [0.6272],</span></a>
<a class="sourceLine" id="cb187-80" data-line-number="80"><span class="co">#&gt;         [0.7234],</span></a>
<a class="sourceLine" id="cb187-81" data-line-number="81"><span class="co">#&gt;         [0.0161],</span></a>
<a class="sourceLine" id="cb187-82" data-line-number="82"><span class="co">#&gt;         [0.5944],</span></a>
<a class="sourceLine" id="cb187-83" data-line-number="83"><span class="co">#&gt;         [0.5568],</span></a>
<a class="sourceLine" id="cb187-84" data-line-number="84"><span class="co">#&gt;         [0.1590],</span></a>
<a class="sourceLine" id="cb187-85" data-line-number="85"><span class="co">#&gt;         [0.1531],</span></a>
<a class="sourceLine" id="cb187-86" data-line-number="86"><span class="co">#&gt;         [0.6955],</span></a>
<a class="sourceLine" id="cb187-87" data-line-number="87"><span class="co">#&gt;         [0.3188],</span></a>
<a class="sourceLine" id="cb187-88" data-line-number="88"><span class="co">#&gt;         [0.6920],</span></a>
<a class="sourceLine" id="cb187-89" data-line-number="89"><span class="co">#&gt;         [0.5544],</span></a>
<a class="sourceLine" id="cb187-90" data-line-number="90"><span class="co">#&gt;         [0.3890],</span></a>
<a class="sourceLine" id="cb187-91" data-line-number="91"><span class="co">#&gt;         [0.9251],</span></a>
<a class="sourceLine" id="cb187-92" data-line-number="92"><span class="co">#&gt;         [0.8417],</span></a>
<a class="sourceLine" id="cb187-93" data-line-number="93"><span class="co">#&gt;         [0.3574],</span></a>
<a class="sourceLine" id="cb187-94" data-line-number="94"><span class="co">#&gt;         [0.0436],</span></a>
<a class="sourceLine" id="cb187-95" data-line-number="95"><span class="co">#&gt;         [0.3048],</span></a>
<a class="sourceLine" id="cb187-96" data-line-number="96"><span class="co">#&gt;         [0.3982],</span></a>
<a class="sourceLine" id="cb187-97" data-line-number="97"><span class="co">#&gt;         [0.7050],</span></a>
<a class="sourceLine" id="cb187-98" data-line-number="98"><span class="co">#&gt;         [0.9954],</span></a>
<a class="sourceLine" id="cb187-99" data-line-number="99"><span class="co">#&gt;         [0.3559],</span></a>
<a class="sourceLine" id="cb187-100" data-line-number="100"><span class="co">#&gt;         [0.7625],</span></a>
<a class="sourceLine" id="cb187-101" data-line-number="101"><span class="co">#&gt;         [0.5932],</span></a>
<a class="sourceLine" id="cb187-102" data-line-number="102"><span class="co">#&gt;         [0.6917],</span></a>
<a class="sourceLine" id="cb187-103" data-line-number="103"><span class="co">#&gt;         [0.1511],</span></a>
<a class="sourceLine" id="cb187-104" data-line-number="104"><span class="co">#&gt;         [0.3989],</span></a>
<a class="sourceLine" id="cb187-105" data-line-number="105"><span class="co">#&gt;         [0.2409],</span></a>
<a class="sourceLine" id="cb187-106" data-line-number="106"><span class="co">#&gt;         [0.3435]])</span></a></code></pre></div>
</div>
<div id="creating-the-network-model" class="section level2">
<h2><span class="header-section-number">8.5</span> Creating the network model</h2>
<p>Our network model is a simple Linear layer with an input and an output shape of one.</p>
<p>And the network output should be like this</p>
<pre><code>Net(
  (hidden): Linear(in_features=1, out_features=1, bias=True)
)</code></pre>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb189-1" data-line-number="1"><span class="kw">py_run_string</span>(<span class="st">&quot;import torch&quot;</span>)</a>
<a class="sourceLine" id="cb189-2" data-line-number="2">main =<span class="st"> </span><span class="kw">py_run_string</span>(</a>
<a class="sourceLine" id="cb189-3" data-line-number="3"><span class="st">&quot;</span></a>
<a class="sourceLine" id="cb189-4" data-line-number="4"><span class="st">import torch.nn as nn</span></a>
<a class="sourceLine" id="cb189-5" data-line-number="5"></a>
<a class="sourceLine" id="cb189-6" data-line-number="6"><span class="st">class Net(nn.Module):</span></a>
<a class="sourceLine" id="cb189-7" data-line-number="7"><span class="st">   def __init__(self):</span></a>
<a class="sourceLine" id="cb189-8" data-line-number="8"><span class="st">       super(Net, self).__init__()</span></a>
<a class="sourceLine" id="cb189-9" data-line-number="9"><span class="st">       self.layer = torch.nn.Linear(1, 1)</span></a>
<a class="sourceLine" id="cb189-10" data-line-number="10"></a>
<a class="sourceLine" id="cb189-11" data-line-number="11"><span class="st">   def forward(self, x):</span></a>
<a class="sourceLine" id="cb189-12" data-line-number="12"><span class="st">       x = self.layer(x)      </span></a>
<a class="sourceLine" id="cb189-13" data-line-number="13"><span class="st">       return x</span></a>
<a class="sourceLine" id="cb189-14" data-line-number="14"><span class="st">&quot;</span>)</a>
<a class="sourceLine" id="cb189-15" data-line-number="15"></a>
<a class="sourceLine" id="cb189-16" data-line-number="16"></a>
<a class="sourceLine" id="cb189-17" data-line-number="17"><span class="co"># build a Linear Rgression model</span></a>
<a class="sourceLine" id="cb189-18" data-line-number="18">net &lt;-<span class="st"> </span>main<span class="op">$</span><span class="kw">Net</span>()</a>
<a class="sourceLine" id="cb189-19" data-line-number="19"></a>
<a class="sourceLine" id="cb189-20" data-line-number="20"><span class="kw">print</span>(net)</a>
<a class="sourceLine" id="cb189-21" data-line-number="21"><span class="co">#&gt; Net(</span></a>
<a class="sourceLine" id="cb189-22" data-line-number="22"><span class="co">#&gt;   (layer): Linear(in_features=1, out_features=1, bias=True)</span></a>
<a class="sourceLine" id="cb189-23" data-line-number="23"><span class="co">#&gt; )</span></a></code></pre></div>
</div>
<div id="optimizer-and-loss" class="section level2">
<h2><span class="header-section-number">8.6</span> Optimizer and Loss</h2>
<p>Next, you should define the Optimizer and the Loss Function for our training process.</p>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb190-1" data-line-number="1"><span class="co"># Define Optimizer and Loss Function</span></a>
<a class="sourceLine" id="cb190-2" data-line-number="2">optimizer &lt;-<span class="st"> </span>torch<span class="op">$</span>optim<span class="op">$</span><span class="kw">SGD</span>(net<span class="op">$</span><span class="kw">parameters</span>(), <span class="dt">lr=</span><span class="fl">0.2</span>)</a>
<a class="sourceLine" id="cb190-3" data-line-number="3">loss_func &lt;-<span class="st"> </span>torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">MSELoss</span>()</a>
<a class="sourceLine" id="cb190-4" data-line-number="4"><span class="kw">print</span>(optimizer)</a>
<a class="sourceLine" id="cb190-5" data-line-number="5"><span class="co">#&gt; SGD (</span></a>
<a class="sourceLine" id="cb190-6" data-line-number="6"><span class="co">#&gt; Parameter Group 0</span></a>
<a class="sourceLine" id="cb190-7" data-line-number="7"><span class="co">#&gt;     dampening: 0</span></a>
<a class="sourceLine" id="cb190-8" data-line-number="8"><span class="co">#&gt;     lr: 0.2</span></a>
<a class="sourceLine" id="cb190-9" data-line-number="9"><span class="co">#&gt;     momentum: 0</span></a>
<a class="sourceLine" id="cb190-10" data-line-number="10"><span class="co">#&gt;     nesterov: False</span></a>
<a class="sourceLine" id="cb190-11" data-line-number="11"><span class="co">#&gt;     weight_decay: 0</span></a>
<a class="sourceLine" id="cb190-12" data-line-number="12"><span class="co">#&gt; )</span></a>
<a class="sourceLine" id="cb190-13" data-line-number="13"><span class="kw">print</span>(loss_func)</a>
<a class="sourceLine" id="cb190-14" data-line-number="14"><span class="co">#&gt; MSELoss()</span></a></code></pre></div>
</div>
<div id="training-1" class="section level2">
<h2><span class="header-section-number">8.7</span> Training</h2>
<p>Now letâ€™s start our training process. With an epoch of 250, you will iterate our data to find the best value for our hyperparameters.</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb191-1" data-line-number="1"><span class="co"># x = x$type(torch$float)   # make it a a FloatTensor</span></a>
<a class="sourceLine" id="cb191-2" data-line-number="2"><span class="co"># y = y$type(torch$float)</span></a>
<a class="sourceLine" id="cb191-3" data-line-number="3"></a>
<a class="sourceLine" id="cb191-4" data-line-number="4"><span class="co"># x &lt;- torch$as_tensor(x, dtype = torch$float)</span></a>
<a class="sourceLine" id="cb191-5" data-line-number="5"><span class="co"># y &lt;- torch$as_tensor(y, dtype = torch$float)</span></a>
<a class="sourceLine" id="cb191-6" data-line-number="6"></a>
<a class="sourceLine" id="cb191-7" data-line-number="7">inputs  =<span class="st"> </span><span class="kw">Variable</span>(x)</a>
<a class="sourceLine" id="cb191-8" data-line-number="8">outputs =<span class="st"> </span><span class="kw">Variable</span>(y)</a>
<a class="sourceLine" id="cb191-9" data-line-number="9"></a>
<a class="sourceLine" id="cb191-10" data-line-number="10"><span class="co"># base plot</span></a>
<a class="sourceLine" id="cb191-11" data-line-number="11"><span class="kw">plot</span>(x<span class="op">$</span>data<span class="op">$</span><span class="kw">numpy</span>(), y<span class="op">$</span>data<span class="op">$</span><span class="kw">numpy</span>(), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)</a>
<a class="sourceLine" id="cb191-12" data-line-number="12"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">250</span>) {</a>
<a class="sourceLine" id="cb191-13" data-line-number="13">   prediction =<span class="st"> </span><span class="kw">net</span>(inputs)</a>
<a class="sourceLine" id="cb191-14" data-line-number="14">   loss =<span class="st"> </span><span class="kw">loss_func</span>(prediction, outputs)</a>
<a class="sourceLine" id="cb191-15" data-line-number="15">   optimizer<span class="op">$</span><span class="kw">zero_grad</span>()</a>
<a class="sourceLine" id="cb191-16" data-line-number="16">   loss<span class="op">$</span><span class="kw">backward</span>()</a>
<a class="sourceLine" id="cb191-17" data-line-number="17">   optimizer<span class="op">$</span><span class="kw">step</span>()</a>
<a class="sourceLine" id="cb191-18" data-line-number="18">   </a>
<a class="sourceLine" id="cb191-19" data-line-number="19">   <span class="cf">if</span> (i <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) <span class="cf">break</span></a>
<a class="sourceLine" id="cb191-20" data-line-number="20"></a>
<a class="sourceLine" id="cb191-21" data-line-number="21">   <span class="cf">if</span> (i <span class="op">%%</span><span class="st"> </span><span class="dv">10</span> <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) {</a>
<a class="sourceLine" id="cb191-22" data-line-number="22">       <span class="co"># plot and show learning process</span></a>
<a class="sourceLine" id="cb191-23" data-line-number="23">      <span class="co"># points(x$data$numpy(), y$data$numpy())</span></a>
<a class="sourceLine" id="cb191-24" data-line-number="24">      <span class="kw">points</span>(x<span class="op">$</span>data<span class="op">$</span><span class="kw">numpy</span>(), prediction<span class="op">$</span>data<span class="op">$</span><span class="kw">numpy</span>(), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb191-25" data-line-number="25">       <span class="co"># cat(i, loss$data$numpy(), &quot;\n&quot;)</span></a>
<a class="sourceLine" id="cb191-26" data-line-number="26">   }</a>
<a class="sourceLine" id="cb191-27" data-line-number="27">}</a></code></pre></div>
<p><img src="0401-linear_regression-simple_files/figure-html/plot-xy-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="results" class="section level2">
<h2><span class="header-section-number">8.8</span> Results</h2>
<p>As you can see below, you successfully performed regression with a neural network. Actually, on every iteration, the red line in the plot will update and change its position to fit the data. But in this picture, you only show you the final result.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="a-classic-classification-problem.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="rainfall-linear-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["rtorch-book.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

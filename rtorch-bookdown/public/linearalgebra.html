<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Linear Algebra with Torch | A Minimal rTorch Tutorial</title>
  <meta name="description" content="This is a minimal tutorial of using the rTorch package to have fun while doing machine learning. This book was produced with bookdown." />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Linear Algebra with Torch | A Minimal rTorch Tutorial" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal tutorial of using the rTorch package to have fun while doing machine learning. This book was produced with bookdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Linear Algebra with Torch | A Minimal rTorch Tutorial" />
  
  <meta name="twitter:description" content="This is a minimal tutorial of using the rTorch package to have fun while doing machine learning. This book was produced with bookdown." />
  

<meta name="author" content="Alfonso R. Reyes" />


<meta name="date" content="2019-09-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="tensors.html"/>
<link rel="next" href="mnistdigits.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal rTorch Tutorial</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#python-anaconda"><i class="fa fa-check"></i>Python Anaconda</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#example"><i class="fa fa-check"></i>Example</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#automatic-installation"><i class="fa fa-check"></i>Automatic installation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Getting Started</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#motivation"><i class="fa fa-check"></i><b>1.1</b> Motivation</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#how-do-we-start-using-rtorch"><i class="fa fa-check"></i><b>1.2</b> How do we start using <code>rTorch</code></a><ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#getting-the-pytorch-version"><i class="fa fa-check"></i><b>1.2.1</b> Getting the PyTorch version</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#pytorch-configuration"><i class="fa fa-check"></i><b>1.2.2</b> PyTorch configuration</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#what-can-you-do-with-rtorch"><i class="fa fa-check"></i><b>1.3</b> What can you do with <code>rTorch</code></a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#callable-pytorch-modules"><i class="fa fa-check"></i><b>1.4</b> Callable PyTorch modules</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#the-torchvision-module"><i class="fa fa-check"></i><b>1.4.1</b> The <code>torchvision</code> module</a></li>
<li class="chapter" data-level="1.4.2" data-path="intro.html"><a href="intro.html#np-the-numpy-module"><i class="fa fa-check"></i><b>1.4.2</b> <code>np</code>: the <code>numpy</code> module</a></li>
<li class="chapter" data-level="1.4.3" data-path="intro.html"><a href="intro.html#python-built-in-functions"><i class="fa fa-check"></i><b>1.4.3</b> Python built-in functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html"><i class="fa fa-check"></i><b>2</b> rTorch vs PyTorch: Whatâ€™s different</a><ul>
<li class="chapter" data-level="2.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#calling-objects-from-pytorch"><i class="fa fa-check"></i><b>2.1</b> Calling objects from PyTorch</a></li>
<li class="chapter" data-level="2.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#call-a-module-from-pytorch"><i class="fa fa-check"></i><b>2.2</b> Call a module from PyTorch</a></li>
<li class="chapter" data-level="2.3" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#show-the-attributes-methods-of-a-class-or-pytorch-object"><i class="fa fa-check"></i><b>2.3</b> Show the attributes (methods) of a class or PyTorch object</a></li>
<li class="chapter" data-level="2.4" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#enumeration"><i class="fa fa-check"></i><b>2.4</b> Enumeration</a></li>
<li class="chapter" data-level="2.5" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#how-to-iterate"><i class="fa fa-check"></i><b>2.5</b> How to iterate</a><ul>
<li class="chapter" data-level="2.5.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#using-enumerate-and-iterate"><i class="fa fa-check"></i><b>2.5.1</b> Using <code>enumerate</code> and <code>iterate</code></a></li>
<li class="chapter" data-level="2.5.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#using-a-for-loop-to-iterate"><i class="fa fa-check"></i><b>2.5.2</b> Using a <code>for-loop</code> to iterate</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#zero-gradient"><i class="fa fa-check"></i><b>2.6</b> Zero gradient</a><ul>
<li class="chapter" data-level="2.6.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#version-in-python"><i class="fa fa-check"></i><b>2.6.1</b> Version in Python</a></li>
<li class="chapter" data-level="2.6.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#version-in-r"><i class="fa fa-check"></i><b>2.6.2</b> Version in R</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#transform-a-tensor"><i class="fa fa-check"></i><b>2.7</b> Transform a tensor</a></li>
<li class="chapter" data-level="2.8" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#build-a-model-class"><i class="fa fa-check"></i><b>2.8</b> Build a model class</a><ul>
<li class="chapter" data-level="2.8.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#example-1"><i class="fa fa-check"></i><b>2.8.1</b> Example 1</a></li>
<li class="chapter" data-level="2.8.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#example-2-logistic-regression"><i class="fa fa-check"></i><b>2.8.2</b> Example 2: Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#convert-a-tensor-to-numpy-object"><i class="fa fa-check"></i><b>2.9</b> Convert a tensor to <code>numpy</code> object</a></li>
<li class="chapter" data-level="2.10" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#convert-a-numpy-object-to-an-r-object"><i class="fa fa-check"></i><b>2.10</b> Convert a <code>numpy</code> object to an <code>R</code> object</a></li>
</ul></li>
<li class="part"><span><b>II Basic Tensor Operations</b></span></li>
<li class="chapter" data-level="3" data-path="tensors.html"><a href="tensors.html"><i class="fa fa-check"></i><b>3</b> Tensors</a><ul>
<li class="chapter" data-level="3.1" data-path="tensors.html"><a href="tensors.html#tensor-data-types"><i class="fa fa-check"></i><b>3.1</b> Tensor data types</a></li>
<li class="chapter" data-level="3.2" data-path="tensors.html"><a href="tensors.html#arithmetic-of-tensors"><i class="fa fa-check"></i><b>3.2</b> Arithmetic of tensors</a><ul>
<li class="chapter" data-level="3.2.1" data-path="tensors.html"><a href="tensors.html#add-tensors"><i class="fa fa-check"></i><b>3.2.1</b> Add tensors</a></li>
<li class="chapter" data-level="3.2.2" data-path="tensors.html"><a href="tensors.html#multiply-a-tensor-by-a-scalar"><i class="fa fa-check"></i><b>3.2.2</b> Multiply a tensor by a scalar</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="tensors.html"><a href="tensors.html#numpy-and-pytorch"><i class="fa fa-check"></i><b>3.3</b> NumPy and PyTorch</a><ul>
<li class="chapter" data-level="3.3.1" data-path="tensors.html"><a href="tensors.html#tuples-python-and-vectors-r"><i class="fa fa-check"></i><b>3.3.1</b> Tuples (Python) and vectors (R)</a></li>
<li class="chapter" data-level="3.3.2" data-path="tensors.html"><a href="tensors.html#make-a-numpy-array-a-tensor-with-as_tensor"><i class="fa fa-check"></i><b>3.3.2</b> Make a numpy array a tensor with <code>as_tensor()</code></a></li>
<li class="chapter" data-level="3.3.3" data-path="tensors.html"><a href="tensors.html#tensor-to-array-and-viceversa"><i class="fa fa-check"></i><b>3.3.3</b> Tensor to array, and viceversa</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="tensors.html"><a href="tensors.html#create-tensors"><i class="fa fa-check"></i><b>3.4</b> Create tensors</a></li>
<li class="chapter" data-level="3.5" data-path="tensors.html"><a href="tensors.html#tensor-resizing"><i class="fa fa-check"></i><b>3.5</b> Tensor resizing</a><ul>
<li class="chapter" data-level="3.5.1" data-path="tensors.html"><a href="tensors.html#concatenate-tensors"><i class="fa fa-check"></i><b>3.5.1</b> Concatenate tensors</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="tensors.html"><a href="tensors.html#reshape-tensors"><i class="fa fa-check"></i><b>3.6</b> Reshape tensors</a><ul>
<li class="chapter" data-level="3.6.1" data-path="tensors.html"><a href="tensors.html#with-function-chunk"><i class="fa fa-check"></i><b>3.6.1</b> With function <code>chunk()</code>:</a></li>
<li class="chapter" data-level="3.6.2" data-path="tensors.html"><a href="tensors.html#with-index_select"><i class="fa fa-check"></i><b>3.6.2</b> With <code>index_select()</code>:</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="tensors.html"><a href="tensors.html#special-tensors"><i class="fa fa-check"></i><b>3.7</b> Special tensors</a><ul>
<li class="chapter" data-level="3.7.1" data-path="tensors.html"><a href="tensors.html#identity-matrix"><i class="fa fa-check"></i><b>3.7.1</b> Identity matrix</a></li>
<li class="chapter" data-level="3.7.2" data-path="tensors.html"><a href="tensors.html#ones"><i class="fa fa-check"></i><b>3.7.2</b> Ones</a></li>
<li class="chapter" data-level="3.7.3" data-path="tensors.html"><a href="tensors.html#zeros"><i class="fa fa-check"></i><b>3.7.3</b> Zeros</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="tensors.html"><a href="tensors.html#tensor-fill"><i class="fa fa-check"></i><b>3.8</b> Tensor fill</a><ul>
<li class="chapter" data-level="3.8.1" data-path="tensors.html"><a href="tensors.html#initialize-a-linear-or-log-scale-tensor"><i class="fa fa-check"></i><b>3.8.1</b> Initialize a linear or log scale Tensor</a></li>
<li class="chapter" data-level="3.8.2" data-path="tensors.html"><a href="tensors.html#inplace-out-of-place"><i class="fa fa-check"></i><b>3.8.2</b> Inplace / Out-of-place</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="tensors.html"><a href="tensors.html#access-to-tensor-elements"><i class="fa fa-check"></i><b>3.9</b> Access to tensor elements</a><ul>
<li class="chapter" data-level="3.9.1" data-path="tensors.html"><a href="tensors.html#using-indices-to-access-elements"><i class="fa fa-check"></i><b>3.9.1</b> Using indices to access elements</a></li>
<li class="chapter" data-level="3.9.2" data-path="tensors.html"><a href="tensors.html#using-the-take-function"><i class="fa fa-check"></i><b>3.9.2</b> Using the <code>take</code> function</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="tensors.html"><a href="tensors.html#other-tensor-operations"><i class="fa fa-check"></i><b>3.10</b> Other tensor operations</a><ul>
<li class="chapter" data-level="3.10.1" data-path="tensors.html"><a href="tensors.html#cross-product"><i class="fa fa-check"></i><b>3.10.1</b> Cross product</a></li>
<li class="chapter" data-level="3.10.2" data-path="tensors.html"><a href="tensors.html#dot-product"><i class="fa fa-check"></i><b>3.10.2</b> Dot product</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="tensors.html"><a href="tensors.html#logical-operations"><i class="fa fa-check"></i><b>3.11</b> Logical operations</a><ul>
<li class="chapter" data-level="3.11.1" data-path="tensors.html"><a href="tensors.html#logical-not"><i class="fa fa-check"></i><b>3.11.1</b> Logical NOT</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="tensors.html"><a href="tensors.html#distributions"><i class="fa fa-check"></i><b>3.12</b> Distributions</a><ul>
<li class="chapter" data-level="3.12.1" data-path="tensors.html"><a href="tensors.html#uniform-matrix"><i class="fa fa-check"></i><b>3.12.1</b> Uniform matrix</a></li>
<li class="chapter" data-level="3.12.2" data-path="tensors.html"><a href="tensors.html#binomial-distribution"><i class="fa fa-check"></i><b>3.12.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="3.12.3" data-path="tensors.html"><a href="tensors.html#exponential-distribution"><i class="fa fa-check"></i><b>3.12.3</b> Exponential distribution</a></li>
<li class="chapter" data-level="3.12.4" data-path="tensors.html"><a href="tensors.html#weibull-distribution"><i class="fa fa-check"></i><b>3.12.4</b> Weibull distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linearalgebra.html"><a href="linearalgebra.html"><i class="fa fa-check"></i><b>4</b> Linear Algebra with Torch</a><ul>
<li class="chapter" data-level="4.1" data-path="linearalgebra.html"><a href="linearalgebra.html#scalars"><i class="fa fa-check"></i><b>4.1</b> Scalars</a></li>
<li class="chapter" data-level="4.2" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors"><i class="fa fa-check"></i><b>4.2</b> Vectors</a></li>
<li class="chapter" data-level="4.3" data-path="linearalgebra.html"><a href="linearalgebra.html#matrices"><i class="fa fa-check"></i><b>4.3</b> Matrices</a></li>
<li class="chapter" data-level="4.4" data-path="linearalgebra.html"><a href="linearalgebra.html#d-tensors"><i class="fa fa-check"></i><b>4.4</b> 3D+ tensors</a></li>
<li class="chapter" data-level="4.5" data-path="linearalgebra.html"><a href="linearalgebra.html#transpose-of-a-matrix"><i class="fa fa-check"></i><b>4.5</b> Transpose of a matrix</a></li>
<li class="chapter" data-level="4.6" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors-special-case-of-a-matrix"><i class="fa fa-check"></i><b>4.6</b> Vectors, special case of a matrix</a></li>
<li class="chapter" data-level="4.7" data-path="linearalgebra.html"><a href="linearalgebra.html#tensor-arithmetic"><i class="fa fa-check"></i><b>4.7</b> Tensor arithmetic</a></li>
<li class="chapter" data-level="4.8" data-path="linearalgebra.html"><a href="linearalgebra.html#add-a-scalar-to-a-tensor"><i class="fa fa-check"></i><b>4.8</b> Add a scalar to a tensor</a></li>
<li class="chapter" data-level="4.9" data-path="linearalgebra.html"><a href="linearalgebra.html#multiplying-tensors"><i class="fa fa-check"></i><b>4.9</b> Multiplying tensors</a></li>
<li class="chapter" data-level="4.10" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-1"><i class="fa fa-check"></i><b>4.10</b> Dot product</a></li>
</ul></li>
<li class="part"><span><b>III Logistic Regression</b></span></li>
<li class="chapter" data-level="5" data-path="mnistdigits.html"><a href="mnistdigits.html"><i class="fa fa-check"></i><b>5</b> Example 1: MNIST handwritten digits</a><ul>
<li class="chapter" data-level="5.1" data-path="mnistdigits.html"><a href="mnistdigits.html#hyperparameters"><i class="fa fa-check"></i><b>5.1</b> Hyperparameters</a></li>
<li class="chapter" data-level="5.2" data-path="mnistdigits.html"><a href="mnistdigits.html#read-datasets"><i class="fa fa-check"></i><b>5.2</b> Read datasets</a></li>
<li class="chapter" data-level="5.3" data-path="mnistdigits.html"><a href="mnistdigits.html#define-the-model"><i class="fa fa-check"></i><b>5.3</b> Define the model</a></li>
<li class="chapter" data-level="5.4" data-path="mnistdigits.html"><a href="mnistdigits.html#training"><i class="fa fa-check"></i><b>5.4</b> Training</a></li>
<li class="chapter" data-level="5.5" data-path="mnistdigits.html"><a href="mnistdigits.html#prediction"><i class="fa fa-check"></i><b>5.5</b> Prediction</a></li>
<li class="chapter" data-level="5.6" data-path="mnistdigits.html"><a href="mnistdigits.html#save-the-model"><i class="fa fa-check"></i><b>5.6</b> Save the model</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="a-classic-classification-problem.html"><a href="a-classic-classification-problem.html"><i class="fa fa-check"></i><b>6</b> A classic classification problem</a></li>
<li class="part"><span><b>IV Linear Regression</b></span></li>
<li class="chapter" data-level="7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>7</b> Simple linear regression</a><ul>
<li class="chapter" data-level="7.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#introduction"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#generate-the-dataset"><i class="fa fa-check"></i><b>7.2</b> Generate the dataset</a></li>
<li class="chapter" data-level="7.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#convert-arrays-to-tensors"><i class="fa fa-check"></i><b>7.3</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="7.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#converting-from-numpy-to-tensor"><i class="fa fa-check"></i><b>7.4</b> Converting from numpy to tensor</a></li>
<li class="chapter" data-level="7.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#creating-the-network-model"><i class="fa fa-check"></i><b>7.5</b> Creating the network model</a></li>
<li class="chapter" data-level="7.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#optimizer-and-loss"><i class="fa fa-check"></i><b>7.6</b> Optimizer and Loss</a></li>
<li class="chapter" data-level="7.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#training-1"><i class="fa fa-check"></i><b>7.7</b> Training</a></li>
<li class="chapter" data-level="7.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#results"><i class="fa fa-check"></i><b>7.8</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html"><i class="fa fa-check"></i><b>8</b> Rainfall. Linear Regression</a><ul>
<li class="chapter" data-level="8.1" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#training-data"><i class="fa fa-check"></i><b>8.1</b> Training data</a></li>
<li class="chapter" data-level="8.2" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#convert-arrays-to-tensors-1"><i class="fa fa-check"></i><b>8.2</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="8.3" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#build-the-model"><i class="fa fa-check"></i><b>8.3</b> Build the model</a></li>
<li class="chapter" data-level="8.4" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#generate-predictions"><i class="fa fa-check"></i><b>8.4</b> Generate predictions</a></li>
<li class="chapter" data-level="8.5" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#loss-function"><i class="fa fa-check"></i><b>8.5</b> Loss Function</a></li>
<li class="chapter" data-level="8.6" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#step-by-step-process"><i class="fa fa-check"></i><b>8.6</b> Step by step process</a><ul>
<li class="chapter" data-level="8.6.1" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#compute-the-losses"><i class="fa fa-check"></i><b>8.6.1</b> Compute the losses</a></li>
<li class="chapter" data-level="8.6.2" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#compute-gradients"><i class="fa fa-check"></i><b>8.6.2</b> Compute Gradients</a></li>
<li class="chapter" data-level="8.6.3" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#reset-the-gradients"><i class="fa fa-check"></i><b>8.6.3</b> Reset the gradients</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#all-together-train-for-multiple-epochs"><i class="fa fa-check"></i><b>8.7</b> All together: train for multiple epochs</a></li>
</ul></li>
<li class="part"><span><b>V Neural Networks</b></span></li>
<li class="chapter" data-level="9" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html"><i class="fa fa-check"></i><b>9</b> A two-layer neural network</a><ul>
<li class="chapter" data-level="9.1" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#load-the-libraries"><i class="fa fa-check"></i><b>9.1</b> Load the libraries</a></li>
<li class="chapter" data-level="9.2" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#dataset"><i class="fa fa-check"></i><b>9.2</b> Dataset</a></li>
<li class="chapter" data-level="9.3" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#run-the-model-for-50-iterations"><i class="fa fa-check"></i><b>9.3</b> Run the model for 50 iterations</a></li>
<li class="chapter" data-level="9.4" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#run-it-at-100-iterations"><i class="fa fa-check"></i><b>9.4</b> Run it at 100 iterations</a></li>
<li class="chapter" data-level="9.5" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#original-pytorch-code"><i class="fa fa-check"></i><b>9.5</b> Original PyTorch code</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html"><i class="fa fa-check"></i><b>10</b> A very simple neural network</a><ul>
<li class="chapter" data-level="10.1" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#introduction-1"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#select-device"><i class="fa fa-check"></i><b>10.2</b> Select device</a></li>
<li class="chapter" data-level="10.3" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#create-the-dataset"><i class="fa fa-check"></i><b>10.3</b> Create the dataset</a></li>
<li class="chapter" data-level="10.4" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#define-the-model-1"><i class="fa fa-check"></i><b>10.4</b> Define the model</a></li>
<li class="chapter" data-level="10.5" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#loss-function-1"><i class="fa fa-check"></i><b>10.5</b> Loss function</a></li>
<li class="chapter" data-level="10.6" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#iterate-through-batches"><i class="fa fa-check"></i><b>10.6</b> Iterate through batches</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="neural-networks-2.html"><a href="neural-networks-2.html"><i class="fa fa-check"></i><b>11</b> Neural Networks 2</a><ul>
<li class="chapter" data-level="11.1" data-path="neural-networks-2.html"><a href="neural-networks-2.html#nn2-1"><i class="fa fa-check"></i><b>11.1</b> nn2 1</a></li>
<li class="chapter" data-level="11.2" data-path="neural-networks-2.html"><a href="neural-networks-2.html#nn2-2"><i class="fa fa-check"></i><b>11.2</b> nn2 2</a></li>
</ul></li>
<li class="part"><span><b>VI PyTorch and R data structures</b></span></li>
<li class="chapter" data-level="12" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html"><i class="fa fa-check"></i><b>12</b> Working with data.frame</a><ul>
<li class="chapter" data-level="12.1" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#load-pytorch-libraries"><i class="fa fa-check"></i><b>12.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="12.2" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#load-dataset"><i class="fa fa-check"></i><b>12.2</b> Load dataset</a></li>
<li class="chapter" data-level="12.3" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#summary-statistics-for-tensors"><i class="fa fa-check"></i><b>12.3</b> Summary statistics for tensors</a><ul>
<li class="chapter" data-level="12.3.1" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#using-data.frame"><i class="fa fa-check"></i><b>12.3.1</b> using <code>data.frame</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="working-with-data-table.html"><a href="working-with-data-table.html"><i class="fa fa-check"></i><b>13</b> Working with data.table</a><ul>
<li class="chapter" data-level="13.1" data-path="working-with-data-table.html"><a href="working-with-data-table.html#load-pytorch-libraries-1"><i class="fa fa-check"></i><b>13.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="13.2" data-path="working-with-data-table.html"><a href="working-with-data-table.html#load-dataset-1"><i class="fa fa-check"></i><b>13.2</b> Load dataset</a></li>
<li class="chapter" data-level="13.3" data-path="working-with-data-table.html"><a href="working-with-data-table.html#read-the-datasets-without-normalization"><i class="fa fa-check"></i><b>13.3</b> Read the datasets without normalization</a></li>
<li class="chapter" data-level="13.4" data-path="working-with-data-table.html"><a href="working-with-data-table.html#using-data.table"><i class="fa fa-check"></i><b>13.4</b> Using <code>data.table</code></a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendixA.html"><a href="appendixA.html"><i class="fa fa-check"></i><b>A</b> Statistical Background</a><ul>
<li class="chapter" data-level="A.1" data-path="appendixA.html"><a href="appendixA.html#basic-statistical-terms"><i class="fa fa-check"></i><b>A.1</b> Basic statistical terms</a><ul>
<li class="chapter" data-level="A.1.1" data-path="appendixA.html"><a href="appendixA.html#five-number-summary"><i class="fa fa-check"></i><b>A.1.1</b> Five-number summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendixB.html"><a href="appendixB.html"><i class="fa fa-check"></i><b>B</b> Activation Functions</a><ul>
<li class="chapter" data-level="B.1" data-path="appendixB.html"><a href="appendixB.html#the-sigmoid-function"><i class="fa fa-check"></i><b>B.1</b> The Sigmoid function</a></li>
<li class="chapter" data-level="B.2" data-path="appendixB.html"><a href="appendixB.html#the-relu-function"><i class="fa fa-check"></i><b>B.2</b> The ReLU function</a></li>
<li class="chapter" data-level="B.3" data-path="appendixB.html"><a href="appendixB.html#the-tanh-function"><i class="fa fa-check"></i><b>B.3</b> The tanh function</a></li>
<li class="chapter" data-level="B.4" data-path="appendixB.html"><a href="appendixB.html#the-softmax-activation-function"><i class="fa fa-check"></i><b>B.4</b> The Softmax Activation function</a></li>
<li class="chapter" data-level="B.5" data-path="appendixB.html"><a href="appendixB.html#coding-your-own-activation-functions-in-python"><i class="fa fa-check"></i><b>B.5</b> Coding your own activation functions in Python</a><ul>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#linear-activation"><i class="fa fa-check"></i>Linear activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#sigmoid-activation"><i class="fa fa-check"></i>Sigmoid activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#hyperbolic-tangent-activation"><i class="fa fa-check"></i>Hyperbolic Tangent activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#rectifier-linear-unit-relu"><i class="fa fa-check"></i>Rectifier linear unit (ReLU)</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#visualization"><i class="fa fa-check"></i>Visualization</a></li>
</ul></li>
<li class="chapter" data-level="B.6" data-path="appendixB.html"><a href="appendixB.html#softmax-in-python"><i class="fa fa-check"></i><b>B.6</b> Softmax in Python</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Minimal rTorch Tutorial</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linearalgebra" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Linear Algebra with Torch</h1>
<p>The following are basic operations of Linear Algebra using PyTorch.</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb130-1" data-line-number="1"><span class="kw">library</span>(rTorch)</a></code></pre></div>
<div id="scalars" class="section level2">
<h2><span class="header-section-number">4.1</span> Scalars</h2>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb131-1" data-line-number="1">torch<span class="op">$</span><span class="kw">scalar_tensor</span>(<span class="fl">2.78654</span>)</a>
<a class="sourceLine" id="cb131-2" data-line-number="2"><span class="co">#&gt; tensor(2.7865)</span></a>
<a class="sourceLine" id="cb131-3" data-line-number="3"></a>
<a class="sourceLine" id="cb131-4" data-line-number="4">torch<span class="op">$</span><span class="kw">scalar_tensor</span>(0L)</a>
<a class="sourceLine" id="cb131-5" data-line-number="5"><span class="co">#&gt; tensor(0.)</span></a>
<a class="sourceLine" id="cb131-6" data-line-number="6"></a>
<a class="sourceLine" id="cb131-7" data-line-number="7">torch<span class="op">$</span><span class="kw">scalar_tensor</span>(1L)</a>
<a class="sourceLine" id="cb131-8" data-line-number="8"><span class="co">#&gt; tensor(1.)</span></a>
<a class="sourceLine" id="cb131-9" data-line-number="9"></a>
<a class="sourceLine" id="cb131-10" data-line-number="10">torch<span class="op">$</span><span class="kw">scalar_tensor</span>(<span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb131-11" data-line-number="11"><span class="co">#&gt; tensor(1.)</span></a>
<a class="sourceLine" id="cb131-12" data-line-number="12"></a>
<a class="sourceLine" id="cb131-13" data-line-number="13">torch<span class="op">$</span><span class="kw">scalar_tensor</span>(<span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb131-14" data-line-number="14"><span class="co">#&gt; tensor(0.)</span></a></code></pre></div>
</div>
<div id="vectors" class="section level2">
<h2><span class="header-section-number">4.2</span> Vectors</h2>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb132-1" data-line-number="1">v &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb132-2" data-line-number="2">torch<span class="op">$</span><span class="kw">as_tensor</span>(v)</a>
<a class="sourceLine" id="cb132-3" data-line-number="3"><span class="co">#&gt; tensor([0., 1., 2., 3., 4., 5.])</span></a></code></pre></div>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb133-1" data-line-number="1"><span class="co"># row-vector</span></a>
<a class="sourceLine" id="cb133-2" data-line-number="2"><span class="kw">message</span>(<span class="st">&quot;R matrix&quot;</span>)</a>
<a class="sourceLine" id="cb133-3" data-line-number="3"><span class="co">#&gt; R matrix</span></a>
<a class="sourceLine" id="cb133-4" data-line-number="4">(mr &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">nrow=</span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb133-5" data-line-number="5"><span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]</span></a>
<a class="sourceLine" id="cb133-6" data-line-number="6"><span class="co">#&gt; [1,]    1    2    3    4    5    6    7    8    9    10</span></a>
<a class="sourceLine" id="cb133-7" data-line-number="7"><span class="kw">message</span>(<span class="st">&quot;as_tensor&quot;</span>)</a>
<a class="sourceLine" id="cb133-8" data-line-number="8"><span class="co">#&gt; as_tensor</span></a>
<a class="sourceLine" id="cb133-9" data-line-number="9">torch<span class="op">$</span><span class="kw">as_tensor</span>(mr)</a>
<a class="sourceLine" id="cb133-10" data-line-number="10"><span class="co">#&gt; tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]], dtype=torch.int32)</span></a>
<a class="sourceLine" id="cb133-11" data-line-number="11"><span class="kw">message</span>(<span class="st">&quot;shape_of_tensor&quot;</span>)</a>
<a class="sourceLine" id="cb133-12" data-line-number="12"><span class="co">#&gt; shape_of_tensor</span></a>
<a class="sourceLine" id="cb133-13" data-line-number="13">torch<span class="op">$</span><span class="kw">as_tensor</span>(mr)<span class="op">$</span>shape</a>
<a class="sourceLine" id="cb133-14" data-line-number="14"><span class="co">#&gt; torch.Size([1, 10])</span></a></code></pre></div>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb134-1" data-line-number="1"><span class="co"># column-vector</span></a>
<a class="sourceLine" id="cb134-2" data-line-number="2"><span class="kw">message</span>(<span class="st">&quot;R matrix, one column&quot;</span>)</a>
<a class="sourceLine" id="cb134-3" data-line-number="3"><span class="co">#&gt; R matrix, one column</span></a>
<a class="sourceLine" id="cb134-4" data-line-number="4">(mc &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">ncol=</span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb134-5" data-line-number="5"><span class="co">#&gt;       [,1]</span></a>
<a class="sourceLine" id="cb134-6" data-line-number="6"><span class="co">#&gt;  [1,]    1</span></a>
<a class="sourceLine" id="cb134-7" data-line-number="7"><span class="co">#&gt;  [2,]    2</span></a>
<a class="sourceLine" id="cb134-8" data-line-number="8"><span class="co">#&gt;  [3,]    3</span></a>
<a class="sourceLine" id="cb134-9" data-line-number="9"><span class="co">#&gt;  [4,]    4</span></a>
<a class="sourceLine" id="cb134-10" data-line-number="10"><span class="co">#&gt;  [5,]    5</span></a>
<a class="sourceLine" id="cb134-11" data-line-number="11"><span class="co">#&gt;  [6,]    6</span></a>
<a class="sourceLine" id="cb134-12" data-line-number="12"><span class="co">#&gt;  [7,]    7</span></a>
<a class="sourceLine" id="cb134-13" data-line-number="13"><span class="co">#&gt;  [8,]    8</span></a>
<a class="sourceLine" id="cb134-14" data-line-number="14"><span class="co">#&gt;  [9,]    9</span></a>
<a class="sourceLine" id="cb134-15" data-line-number="15"><span class="co">#&gt; [10,]   10</span></a>
<a class="sourceLine" id="cb134-16" data-line-number="16"><span class="kw">message</span>(<span class="st">&quot;as_tensor&quot;</span>)</a>
<a class="sourceLine" id="cb134-17" data-line-number="17"><span class="co">#&gt; as_tensor</span></a>
<a class="sourceLine" id="cb134-18" data-line-number="18">torch<span class="op">$</span><span class="kw">as_tensor</span>(mc)</a>
<a class="sourceLine" id="cb134-19" data-line-number="19"><span class="co">#&gt; tensor([[ 1],</span></a>
<a class="sourceLine" id="cb134-20" data-line-number="20"><span class="co">#&gt;         [ 2],</span></a>
<a class="sourceLine" id="cb134-21" data-line-number="21"><span class="co">#&gt;         [ 3],</span></a>
<a class="sourceLine" id="cb134-22" data-line-number="22"><span class="co">#&gt;         [ 4],</span></a>
<a class="sourceLine" id="cb134-23" data-line-number="23"><span class="co">#&gt;         [ 5],</span></a>
<a class="sourceLine" id="cb134-24" data-line-number="24"><span class="co">#&gt;         [ 6],</span></a>
<a class="sourceLine" id="cb134-25" data-line-number="25"><span class="co">#&gt;         [ 7],</span></a>
<a class="sourceLine" id="cb134-26" data-line-number="26"><span class="co">#&gt;         [ 8],</span></a>
<a class="sourceLine" id="cb134-27" data-line-number="27"><span class="co">#&gt;         [ 9],</span></a>
<a class="sourceLine" id="cb134-28" data-line-number="28"><span class="co">#&gt;         [10]], dtype=torch.int32)</span></a>
<a class="sourceLine" id="cb134-29" data-line-number="29"><span class="kw">message</span>(<span class="st">&quot;size of tensor&quot;</span>)</a>
<a class="sourceLine" id="cb134-30" data-line-number="30"><span class="co">#&gt; size of tensor</span></a>
<a class="sourceLine" id="cb134-31" data-line-number="31">torch<span class="op">$</span><span class="kw">as_tensor</span>(mc)<span class="op">$</span>shape</a>
<a class="sourceLine" id="cb134-32" data-line-number="32"><span class="co">#&gt; torch.Size([10, 1])</span></a></code></pre></div>
</div>
<div id="matrices" class="section level2">
<h2><span class="header-section-number">4.3</span> Matrices</h2>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb135-1" data-line-number="1"><span class="kw">message</span>(<span class="st">&quot;R matrix&quot;</span>)</a>
<a class="sourceLine" id="cb135-2" data-line-number="2"><span class="co">#&gt; R matrix</span></a>
<a class="sourceLine" id="cb135-3" data-line-number="3">(m1 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">24</span>, <span class="dt">nrow =</span> <span class="dv">3</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>))</a>
<a class="sourceLine" id="cb135-4" data-line-number="4"><span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]</span></a>
<a class="sourceLine" id="cb135-5" data-line-number="5"><span class="co">#&gt; [1,]    1    2    3    4    5    6    7    8</span></a>
<a class="sourceLine" id="cb135-6" data-line-number="6"><span class="co">#&gt; [2,]    9   10   11   12   13   14   15   16</span></a>
<a class="sourceLine" id="cb135-7" data-line-number="7"><span class="co">#&gt; [3,]   17   18   19   20   21   22   23   24</span></a>
<a class="sourceLine" id="cb135-8" data-line-number="8"><span class="kw">message</span>(<span class="st">&quot;as_tensor&quot;</span>)</a>
<a class="sourceLine" id="cb135-9" data-line-number="9"><span class="co">#&gt; as_tensor</span></a>
<a class="sourceLine" id="cb135-10" data-line-number="10">(t1 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(m1))</a>
<a class="sourceLine" id="cb135-11" data-line-number="11"><span class="co">#&gt; tensor([[ 1,  2,  3,  4,  5,  6,  7,  8],</span></a>
<a class="sourceLine" id="cb135-12" data-line-number="12"><span class="co">#&gt;         [ 9, 10, 11, 12, 13, 14, 15, 16],</span></a>
<a class="sourceLine" id="cb135-13" data-line-number="13"><span class="co">#&gt;         [17, 18, 19, 20, 21, 22, 23, 24]], dtype=torch.int32)</span></a>
<a class="sourceLine" id="cb135-14" data-line-number="14"><span class="kw">message</span>(<span class="st">&quot;shape&quot;</span>)</a>
<a class="sourceLine" id="cb135-15" data-line-number="15"><span class="co">#&gt; shape</span></a>
<a class="sourceLine" id="cb135-16" data-line-number="16">torch<span class="op">$</span><span class="kw">as_tensor</span>(m1)<span class="op">$</span>shape</a>
<a class="sourceLine" id="cb135-17" data-line-number="17"><span class="co">#&gt; torch.Size([3, 8])</span></a>
<a class="sourceLine" id="cb135-18" data-line-number="18"><span class="kw">message</span>(<span class="st">&quot;size&quot;</span>)</a>
<a class="sourceLine" id="cb135-19" data-line-number="19"><span class="co">#&gt; size</span></a>
<a class="sourceLine" id="cb135-20" data-line-number="20">torch<span class="op">$</span><span class="kw">as_tensor</span>(m1)<span class="op">$</span><span class="kw">size</span>()</a>
<a class="sourceLine" id="cb135-21" data-line-number="21"><span class="co">#&gt; torch.Size([3, 8])</span></a>
<a class="sourceLine" id="cb135-22" data-line-number="22"><span class="kw">message</span>(<span class="st">&quot;dim&quot;</span>)</a>
<a class="sourceLine" id="cb135-23" data-line-number="23"><span class="co">#&gt; dim</span></a>
<a class="sourceLine" id="cb135-24" data-line-number="24"><span class="kw">dim</span>(torch<span class="op">$</span><span class="kw">as_tensor</span>(m1))</a>
<a class="sourceLine" id="cb135-25" data-line-number="25"><span class="co">#&gt; [1] 3 8</span></a>
<a class="sourceLine" id="cb135-26" data-line-number="26"><span class="kw">message</span>(<span class="st">&quot;length&quot;</span>)</a>
<a class="sourceLine" id="cb135-27" data-line-number="27"><span class="co">#&gt; length</span></a>
<a class="sourceLine" id="cb135-28" data-line-number="28"><span class="kw">length</span>(torch<span class="op">$</span><span class="kw">as_tensor</span>(m1))</a>
<a class="sourceLine" id="cb135-29" data-line-number="29"><span class="co">#&gt; [1] 24</span></a></code></pre></div>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb136-1" data-line-number="1"><span class="kw">message</span>(<span class="st">&quot;R matrix&quot;</span>)</a>
<a class="sourceLine" id="cb136-2" data-line-number="2"><span class="co">#&gt; R matrix</span></a>
<a class="sourceLine" id="cb136-3" data-line-number="3">(m2 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">99</span>, <span class="dt">ncol =</span> <span class="dv">10</span>))</a>
<a class="sourceLine" id="cb136-4" data-line-number="4"><span class="co">#&gt;       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]</span></a>
<a class="sourceLine" id="cb136-5" data-line-number="5"><span class="co">#&gt;  [1,]    0   10   20   30   40   50   60   70   80    90</span></a>
<a class="sourceLine" id="cb136-6" data-line-number="6"><span class="co">#&gt;  [2,]    1   11   21   31   41   51   61   71   81    91</span></a>
<a class="sourceLine" id="cb136-7" data-line-number="7"><span class="co">#&gt;  [3,]    2   12   22   32   42   52   62   72   82    92</span></a>
<a class="sourceLine" id="cb136-8" data-line-number="8"><span class="co">#&gt;  [4,]    3   13   23   33   43   53   63   73   83    93</span></a>
<a class="sourceLine" id="cb136-9" data-line-number="9"><span class="co">#&gt;  [5,]    4   14   24   34   44   54   64   74   84    94</span></a>
<a class="sourceLine" id="cb136-10" data-line-number="10"><span class="co">#&gt;  [6,]    5   15   25   35   45   55   65   75   85    95</span></a>
<a class="sourceLine" id="cb136-11" data-line-number="11"><span class="co">#&gt;  [7,]    6   16   26   36   46   56   66   76   86    96</span></a>
<a class="sourceLine" id="cb136-12" data-line-number="12"><span class="co">#&gt;  [8,]    7   17   27   37   47   57   67   77   87    97</span></a>
<a class="sourceLine" id="cb136-13" data-line-number="13"><span class="co">#&gt;  [9,]    8   18   28   38   48   58   68   78   88    98</span></a>
<a class="sourceLine" id="cb136-14" data-line-number="14"><span class="co">#&gt; [10,]    9   19   29   39   49   59   69   79   89    99</span></a>
<a class="sourceLine" id="cb136-15" data-line-number="15"><span class="kw">message</span>(<span class="st">&quot;as_tensor&quot;</span>)</a>
<a class="sourceLine" id="cb136-16" data-line-number="16"><span class="co">#&gt; as_tensor</span></a>
<a class="sourceLine" id="cb136-17" data-line-number="17">(t2 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(m2))</a>
<a class="sourceLine" id="cb136-18" data-line-number="18"><span class="co">#&gt; tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90],</span></a>
<a class="sourceLine" id="cb136-19" data-line-number="19"><span class="co">#&gt;         [ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91],</span></a>
<a class="sourceLine" id="cb136-20" data-line-number="20"><span class="co">#&gt;         [ 2, 12, 22, 32, 42, 52, 62, 72, 82, 92],</span></a>
<a class="sourceLine" id="cb136-21" data-line-number="21"><span class="co">#&gt;         [ 3, 13, 23, 33, 43, 53, 63, 73, 83, 93],</span></a>
<a class="sourceLine" id="cb136-22" data-line-number="22"><span class="co">#&gt;         [ 4, 14, 24, 34, 44, 54, 64, 74, 84, 94],</span></a>
<a class="sourceLine" id="cb136-23" data-line-number="23"><span class="co">#&gt;         [ 5, 15, 25, 35, 45, 55, 65, 75, 85, 95],</span></a>
<a class="sourceLine" id="cb136-24" data-line-number="24"><span class="co">#&gt;         [ 6, 16, 26, 36, 46, 56, 66, 76, 86, 96],</span></a>
<a class="sourceLine" id="cb136-25" data-line-number="25"><span class="co">#&gt;         [ 7, 17, 27, 37, 47, 57, 67, 77, 87, 97],</span></a>
<a class="sourceLine" id="cb136-26" data-line-number="26"><span class="co">#&gt;         [ 8, 18, 28, 38, 48, 58, 68, 78, 88, 98],</span></a>
<a class="sourceLine" id="cb136-27" data-line-number="27"><span class="co">#&gt;         [ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]], dtype=torch.int32)</span></a>
<a class="sourceLine" id="cb136-28" data-line-number="28"><span class="kw">message</span>(<span class="st">&quot;shape&quot;</span>)</a>
<a class="sourceLine" id="cb136-29" data-line-number="29"><span class="co">#&gt; shape</span></a>
<a class="sourceLine" id="cb136-30" data-line-number="30">t2<span class="op">$</span>shape</a>
<a class="sourceLine" id="cb136-31" data-line-number="31"><span class="co">#&gt; torch.Size([10, 10])</span></a>
<a class="sourceLine" id="cb136-32" data-line-number="32"><span class="kw">message</span>(<span class="st">&quot;dim&quot;</span>)</a>
<a class="sourceLine" id="cb136-33" data-line-number="33"><span class="co">#&gt; dim</span></a>
<a class="sourceLine" id="cb136-34" data-line-number="34"><span class="kw">dim</span>(torch<span class="op">$</span><span class="kw">as_tensor</span>(m2))</a>
<a class="sourceLine" id="cb136-35" data-line-number="35"><span class="co">#&gt; [1] 10 10</span></a></code></pre></div>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb137-1" data-line-number="1">m1[<span class="dv">1</span>, <span class="dv">1</span>]</a>
<a class="sourceLine" id="cb137-2" data-line-number="2"><span class="co">#&gt; [1] 1</span></a>
<a class="sourceLine" id="cb137-3" data-line-number="3">m2[<span class="dv">1</span>, <span class="dv">1</span>]</a>
<a class="sourceLine" id="cb137-4" data-line-number="4"><span class="co">#&gt; [1] 0</span></a></code></pre></div>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb138-1" data-line-number="1">t1[<span class="dv">1</span>, <span class="dv">1</span>]</a>
<a class="sourceLine" id="cb138-2" data-line-number="2"><span class="co">#&gt; tensor(1, dtype=torch.int32)</span></a>
<a class="sourceLine" id="cb138-3" data-line-number="3">t2[<span class="dv">1</span>, <span class="dv">1</span>]</a>
<a class="sourceLine" id="cb138-4" data-line-number="4"><span class="co">#&gt; tensor(0, dtype=torch.int32)</span></a></code></pre></div>
</div>
<div id="d-tensors" class="section level2">
<h2><span class="header-section-number">4.4</span> 3D+ tensors</h2>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb139-1" data-line-number="1"><span class="co"># RGB color image has three axes </span></a>
<a class="sourceLine" id="cb139-2" data-line-number="2">(img &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">rand</span>(3L, 28L, 28L))</a>
<a class="sourceLine" id="cb139-3" data-line-number="3"><span class="co">#&gt; tensor([[[2.3195e-01, 2.7901e-01, 6.2459e-01,  ..., 8.4426e-01,</span></a>
<a class="sourceLine" id="cb139-4" data-line-number="4"><span class="co">#&gt;           2.4758e-01, 4.3068e-01],</span></a>
<a class="sourceLine" id="cb139-5" data-line-number="5"><span class="co">#&gt;          [3.2518e-01, 6.7801e-01, 7.2160e-01,  ..., 9.2250e-01,</span></a>
<a class="sourceLine" id="cb139-6" data-line-number="6"><span class="co">#&gt;           6.9417e-01, 6.3049e-01],</span></a>
<a class="sourceLine" id="cb139-7" data-line-number="7"><span class="co">#&gt;          [4.8502e-01, 3.1521e-01, 9.1004e-02,  ..., 7.3325e-01,</span></a>
<a class="sourceLine" id="cb139-8" data-line-number="8"><span class="co">#&gt;           7.1481e-01, 4.9595e-01],</span></a>
<a class="sourceLine" id="cb139-9" data-line-number="9"><span class="co">#&gt;          ...,</span></a>
<a class="sourceLine" id="cb139-10" data-line-number="10"><span class="co">#&gt;          [4.5947e-01, 4.6499e-02, 3.6209e-01,  ..., 4.9285e-01,</span></a>
<a class="sourceLine" id="cb139-11" data-line-number="11"><span class="co">#&gt;           5.3635e-01, 7.5423e-01],</span></a>
<a class="sourceLine" id="cb139-12" data-line-number="12"><span class="co">#&gt;          [9.0498e-01, 5.0215e-01, 9.4646e-01,  ..., 4.5080e-01,</span></a>
<a class="sourceLine" id="cb139-13" data-line-number="13"><span class="co">#&gt;           9.5163e-01, 1.0610e-01],</span></a>
<a class="sourceLine" id="cb139-14" data-line-number="14"><span class="co">#&gt;          [1.7515e-01, 2.1939e-01, 8.6337e-01,  ..., 5.6108e-01,</span></a>
<a class="sourceLine" id="cb139-15" data-line-number="15"><span class="co">#&gt;           7.1970e-01, 7.2553e-01]],</span></a>
<a class="sourceLine" id="cb139-16" data-line-number="16"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb139-17" data-line-number="17"><span class="co">#&gt;         [[8.7039e-01, 1.9537e-01, 2.5732e-01,  ..., 5.6670e-01,</span></a>
<a class="sourceLine" id="cb139-18" data-line-number="18"><span class="co">#&gt;           2.7417e-01, 3.8252e-01],</span></a>
<a class="sourceLine" id="cb139-19" data-line-number="19"><span class="co">#&gt;          [1.1267e-01, 9.8972e-01, 8.9118e-01,  ..., 8.4189e-01,</span></a>
<a class="sourceLine" id="cb139-20" data-line-number="20"><span class="co">#&gt;           3.6573e-01, 7.6749e-01],</span></a>
<a class="sourceLine" id="cb139-21" data-line-number="21"><span class="co">#&gt;          [8.9792e-01, 3.5984e-01, 8.3035e-01,  ..., 7.3262e-01,</span></a>
<a class="sourceLine" id="cb139-22" data-line-number="22"><span class="co">#&gt;           5.9792e-01, 3.6532e-01],</span></a>
<a class="sourceLine" id="cb139-23" data-line-number="23"><span class="co">#&gt;          ...,</span></a>
<a class="sourceLine" id="cb139-24" data-line-number="24"><span class="co">#&gt;          [5.7248e-01, 7.5934e-01, 5.3420e-01,  ..., 6.5942e-01,</span></a>
<a class="sourceLine" id="cb139-25" data-line-number="25"><span class="co">#&gt;           5.9810e-01, 4.0073e-01],</span></a>
<a class="sourceLine" id="cb139-26" data-line-number="26"><span class="co">#&gt;          [4.6327e-01, 8.9703e-01, 1.5025e-02,  ..., 4.7061e-01,</span></a>
<a class="sourceLine" id="cb139-27" data-line-number="27"><span class="co">#&gt;           3.6548e-01, 4.1729e-04],</span></a>
<a class="sourceLine" id="cb139-28" data-line-number="28"><span class="co">#&gt;          [8.9610e-01, 2.6140e-01, 4.5616e-01,  ..., 1.1952e-01,</span></a>
<a class="sourceLine" id="cb139-29" data-line-number="29"><span class="co">#&gt;           1.6670e-01, 5.9445e-02]],</span></a>
<a class="sourceLine" id="cb139-30" data-line-number="30"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb139-31" data-line-number="31"><span class="co">#&gt;         [[8.8381e-01, 9.7859e-01, 1.6928e-01,  ..., 1.8248e-01,</span></a>
<a class="sourceLine" id="cb139-32" data-line-number="32"><span class="co">#&gt;           3.7392e-01, 7.0518e-01],</span></a>
<a class="sourceLine" id="cb139-33" data-line-number="33"><span class="co">#&gt;          [2.4729e-01, 5.3682e-01, 5.0760e-01,  ..., 8.5275e-01,</span></a>
<a class="sourceLine" id="cb139-34" data-line-number="34"><span class="co">#&gt;           6.6125e-01, 5.9745e-01],</span></a>
<a class="sourceLine" id="cb139-35" data-line-number="35"><span class="co">#&gt;          [4.7013e-02, 1.2857e-01, 5.2290e-03,  ..., 3.1945e-01,</span></a>
<a class="sourceLine" id="cb139-36" data-line-number="36"><span class="co">#&gt;           1.3336e-01, 6.9872e-01],</span></a>
<a class="sourceLine" id="cb139-37" data-line-number="37"><span class="co">#&gt;          ...,</span></a>
<a class="sourceLine" id="cb139-38" data-line-number="38"><span class="co">#&gt;          [4.9083e-01, 1.1735e-01, 8.1534e-01,  ..., 3.4907e-01,</span></a>
<a class="sourceLine" id="cb139-39" data-line-number="39"><span class="co">#&gt;           3.5142e-01, 4.6827e-01],</span></a>
<a class="sourceLine" id="cb139-40" data-line-number="40"><span class="co">#&gt;          [2.5672e-01, 2.5291e-01, 5.7967e-01,  ..., 4.4226e-01,</span></a>
<a class="sourceLine" id="cb139-41" data-line-number="41"><span class="co">#&gt;           2.8406e-02, 5.6944e-01],</span></a>
<a class="sourceLine" id="cb139-42" data-line-number="42"><span class="co">#&gt;          [5.7018e-01, 5.6662e-01, 3.6400e-03,  ..., 3.4394e-01,</span></a>
<a class="sourceLine" id="cb139-43" data-line-number="43"><span class="co">#&gt;           5.0076e-01, 7.9066e-01]]])</span></a>
<a class="sourceLine" id="cb139-44" data-line-number="44">img<span class="op">$</span>shape</a>
<a class="sourceLine" id="cb139-45" data-line-number="45"><span class="co">#&gt; torch.Size([3, 28, 28])</span></a></code></pre></div>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb140-1" data-line-number="1">img[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]</a>
<a class="sourceLine" id="cb140-2" data-line-number="2"><span class="co">#&gt; tensor(0.2320)</span></a>
<a class="sourceLine" id="cb140-3" data-line-number="3">img[<span class="dv">3</span>, <span class="dv">28</span>, <span class="dv">28</span>]</a>
<a class="sourceLine" id="cb140-4" data-line-number="4"><span class="co">#&gt; tensor(0.7907)</span></a></code></pre></div>
</div>
<div id="transpose-of-a-matrix" class="section level2">
<h2><span class="header-section-number">4.5</span> Transpose of a matrix</h2>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb141-1" data-line-number="1">(m3 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">25</span>, <span class="dt">ncol =</span> <span class="dv">5</span>))</a>
<a class="sourceLine" id="cb141-2" data-line-number="2"><span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5]</span></a>
<a class="sourceLine" id="cb141-3" data-line-number="3"><span class="co">#&gt; [1,]    1    6   11   16   21</span></a>
<a class="sourceLine" id="cb141-4" data-line-number="4"><span class="co">#&gt; [2,]    2    7   12   17   22</span></a>
<a class="sourceLine" id="cb141-5" data-line-number="5"><span class="co">#&gt; [3,]    3    8   13   18   23</span></a>
<a class="sourceLine" id="cb141-6" data-line-number="6"><span class="co">#&gt; [4,]    4    9   14   19   24</span></a>
<a class="sourceLine" id="cb141-7" data-line-number="7"><span class="co">#&gt; [5,]    5   10   15   20   25</span></a>
<a class="sourceLine" id="cb141-8" data-line-number="8"></a>
<a class="sourceLine" id="cb141-9" data-line-number="9"><span class="co"># transpose</span></a>
<a class="sourceLine" id="cb141-10" data-line-number="10"><span class="kw">message</span>(<span class="st">&quot;transpose&quot;</span>)</a>
<a class="sourceLine" id="cb141-11" data-line-number="11"><span class="co">#&gt; transpose</span></a>
<a class="sourceLine" id="cb141-12" data-line-number="12">tm3 &lt;-<span class="st"> </span><span class="kw">t</span>(m3)</a>
<a class="sourceLine" id="cb141-13" data-line-number="13">tm3</a>
<a class="sourceLine" id="cb141-14" data-line-number="14"><span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5]</span></a>
<a class="sourceLine" id="cb141-15" data-line-number="15"><span class="co">#&gt; [1,]    1    2    3    4    5</span></a>
<a class="sourceLine" id="cb141-16" data-line-number="16"><span class="co">#&gt; [2,]    6    7    8    9   10</span></a>
<a class="sourceLine" id="cb141-17" data-line-number="17"><span class="co">#&gt; [3,]   11   12   13   14   15</span></a>
<a class="sourceLine" id="cb141-18" data-line-number="18"><span class="co">#&gt; [4,]   16   17   18   19   20</span></a>
<a class="sourceLine" id="cb141-19" data-line-number="19"><span class="co">#&gt; [5,]   21   22   23   24   25</span></a></code></pre></div>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb142-1" data-line-number="1"><span class="kw">message</span>(<span class="st">&quot;as_tensor&quot;</span>)</a>
<a class="sourceLine" id="cb142-2" data-line-number="2"><span class="co">#&gt; as_tensor</span></a>
<a class="sourceLine" id="cb142-3" data-line-number="3">(t3 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(m3))</a>
<a class="sourceLine" id="cb142-4" data-line-number="4"><span class="co">#&gt; tensor([[ 1,  6, 11, 16, 21],</span></a>
<a class="sourceLine" id="cb142-5" data-line-number="5"><span class="co">#&gt;         [ 2,  7, 12, 17, 22],</span></a>
<a class="sourceLine" id="cb142-6" data-line-number="6"><span class="co">#&gt;         [ 3,  8, 13, 18, 23],</span></a>
<a class="sourceLine" id="cb142-7" data-line-number="7"><span class="co">#&gt;         [ 4,  9, 14, 19, 24],</span></a>
<a class="sourceLine" id="cb142-8" data-line-number="8"><span class="co">#&gt;         [ 5, 10, 15, 20, 25]], dtype=torch.int32)</span></a>
<a class="sourceLine" id="cb142-9" data-line-number="9"><span class="kw">message</span>(<span class="st">&quot;transpose&quot;</span>)</a>
<a class="sourceLine" id="cb142-10" data-line-number="10"><span class="co">#&gt; transpose</span></a>
<a class="sourceLine" id="cb142-11" data-line-number="11">tt3 &lt;-<span class="st"> </span>t3<span class="op">$</span><span class="kw">transpose</span>(<span class="dt">dim0 =</span> 0L, <span class="dt">dim1 =</span> 1L)</a>
<a class="sourceLine" id="cb142-12" data-line-number="12">tt3</a>
<a class="sourceLine" id="cb142-13" data-line-number="13"><span class="co">#&gt; tensor([[ 1,  2,  3,  4,  5],</span></a>
<a class="sourceLine" id="cb142-14" data-line-number="14"><span class="co">#&gt;         [ 6,  7,  8,  9, 10],</span></a>
<a class="sourceLine" id="cb142-15" data-line-number="15"><span class="co">#&gt;         [11, 12, 13, 14, 15],</span></a>
<a class="sourceLine" id="cb142-16" data-line-number="16"><span class="co">#&gt;         [16, 17, 18, 19, 20],</span></a>
<a class="sourceLine" id="cb142-17" data-line-number="17"><span class="co">#&gt;         [21, 22, 23, 24, 25]], dtype=torch.int32)</span></a></code></pre></div>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb143-1" data-line-number="1">tm3 <span class="op">==</span><span class="st"> </span>tt3<span class="op">$</span><span class="kw">numpy</span>()   <span class="co"># convert first the tensor to numpy</span></a>
<a class="sourceLine" id="cb143-2" data-line-number="2"><span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5]</span></a>
<a class="sourceLine" id="cb143-3" data-line-number="3"><span class="co">#&gt; [1,] TRUE TRUE TRUE TRUE TRUE</span></a>
<a class="sourceLine" id="cb143-4" data-line-number="4"><span class="co">#&gt; [2,] TRUE TRUE TRUE TRUE TRUE</span></a>
<a class="sourceLine" id="cb143-5" data-line-number="5"><span class="co">#&gt; [3,] TRUE TRUE TRUE TRUE TRUE</span></a>
<a class="sourceLine" id="cb143-6" data-line-number="6"><span class="co">#&gt; [4,] TRUE TRUE TRUE TRUE TRUE</span></a>
<a class="sourceLine" id="cb143-7" data-line-number="7"><span class="co">#&gt; [5,] TRUE TRUE TRUE TRUE TRUE</span></a></code></pre></div>
</div>
<div id="vectors-special-case-of-a-matrix" class="section level2">
<h2><span class="header-section-number">4.6</span> Vectors, special case of a matrix</h2>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb144-1" data-line-number="1"><span class="kw">message</span>(<span class="st">&quot;R matrix&quot;</span>)</a>
<a class="sourceLine" id="cb144-2" data-line-number="2"><span class="co">#&gt; R matrix</span></a>
<a class="sourceLine" id="cb144-3" data-line-number="3">m2 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">99</span>, <span class="dt">ncol =</span> <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb144-4" data-line-number="4"><span class="kw">message</span>(<span class="st">&quot;as_tensor&quot;</span>)</a>
<a class="sourceLine" id="cb144-5" data-line-number="5"><span class="co">#&gt; as_tensor</span></a>
<a class="sourceLine" id="cb144-6" data-line-number="6">(t2 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(m2))</a>
<a class="sourceLine" id="cb144-7" data-line-number="7"><span class="co">#&gt; tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90],</span></a>
<a class="sourceLine" id="cb144-8" data-line-number="8"><span class="co">#&gt;         [ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91],</span></a>
<a class="sourceLine" id="cb144-9" data-line-number="9"><span class="co">#&gt;         [ 2, 12, 22, 32, 42, 52, 62, 72, 82, 92],</span></a>
<a class="sourceLine" id="cb144-10" data-line-number="10"><span class="co">#&gt;         [ 3, 13, 23, 33, 43, 53, 63, 73, 83, 93],</span></a>
<a class="sourceLine" id="cb144-11" data-line-number="11"><span class="co">#&gt;         [ 4, 14, 24, 34, 44, 54, 64, 74, 84, 94],</span></a>
<a class="sourceLine" id="cb144-12" data-line-number="12"><span class="co">#&gt;         [ 5, 15, 25, 35, 45, 55, 65, 75, 85, 95],</span></a>
<a class="sourceLine" id="cb144-13" data-line-number="13"><span class="co">#&gt;         [ 6, 16, 26, 36, 46, 56, 66, 76, 86, 96],</span></a>
<a class="sourceLine" id="cb144-14" data-line-number="14"><span class="co">#&gt;         [ 7, 17, 27, 37, 47, 57, 67, 77, 87, 97],</span></a>
<a class="sourceLine" id="cb144-15" data-line-number="15"><span class="co">#&gt;         [ 8, 18, 28, 38, 48, 58, 68, 78, 88, 98],</span></a>
<a class="sourceLine" id="cb144-16" data-line-number="16"><span class="co">#&gt;         [ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]], dtype=torch.int32)</span></a>
<a class="sourceLine" id="cb144-17" data-line-number="17"></a>
<a class="sourceLine" id="cb144-18" data-line-number="18"><span class="co"># in R</span></a>
<a class="sourceLine" id="cb144-19" data-line-number="19"><span class="kw">message</span>(<span class="st">&quot;select column of matrix&quot;</span>)</a>
<a class="sourceLine" id="cb144-20" data-line-number="20"><span class="co">#&gt; select column of matrix</span></a>
<a class="sourceLine" id="cb144-21" data-line-number="21">(v1 &lt;-<span class="st"> </span>m2[, <span class="dv">1</span>])</a>
<a class="sourceLine" id="cb144-22" data-line-number="22"><span class="co">#&gt;  [1] 0 1 2 3 4 5 6 7 8 9</span></a>
<a class="sourceLine" id="cb144-23" data-line-number="23"><span class="kw">message</span>(<span class="st">&quot;select row of matrix&quot;</span>)</a>
<a class="sourceLine" id="cb144-24" data-line-number="24"><span class="co">#&gt; select row of matrix</span></a>
<a class="sourceLine" id="cb144-25" data-line-number="25">(v2 &lt;-<span class="st"> </span>m2[<span class="dv">10</span>, ])</a>
<a class="sourceLine" id="cb144-26" data-line-number="26"><span class="co">#&gt;  [1]  9 19 29 39 49 59 69 79 89 99</span></a></code></pre></div>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb145-1" data-line-number="1"><span class="co"># PyTorch</span></a>
<a class="sourceLine" id="cb145-2" data-line-number="2"><span class="kw">message</span>()</a>
<a class="sourceLine" id="cb145-3" data-line-number="3"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb145-4" data-line-number="4">t2c &lt;-<span class="st"> </span>t2[, <span class="dv">1</span>]</a>
<a class="sourceLine" id="cb145-5" data-line-number="5">t2r &lt;-<span class="st"> </span>t2[<span class="dv">10</span>, ]</a>
<a class="sourceLine" id="cb145-6" data-line-number="6"></a>
<a class="sourceLine" id="cb145-7" data-line-number="7">t2c</a>
<a class="sourceLine" id="cb145-8" data-line-number="8"><span class="co">#&gt; tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32)</span></a>
<a class="sourceLine" id="cb145-9" data-line-number="9">t2r</a>
<a class="sourceLine" id="cb145-10" data-line-number="10"><span class="co">#&gt; tensor([ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99], dtype=torch.int32)</span></a></code></pre></div>
<p>In vectors, the vector and its transpose are equal.</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb146-1" data-line-number="1">tt2r &lt;-<span class="st"> </span>t2r<span class="op">$</span><span class="kw">transpose</span>(<span class="dt">dim0 =</span> 0L, <span class="dt">dim1 =</span> 0L)</a>
<a class="sourceLine" id="cb146-2" data-line-number="2">tt2r</a>
<a class="sourceLine" id="cb146-3" data-line-number="3"><span class="co">#&gt; tensor([ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99], dtype=torch.int32)</span></a></code></pre></div>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb147-1" data-line-number="1"><span class="co"># a tensor of booleans. is vector equal to its transposed?</span></a>
<a class="sourceLine" id="cb147-2" data-line-number="2">t2r <span class="op">==</span><span class="st"> </span>tt2r</a>
<a class="sourceLine" id="cb147-3" data-line-number="3"><span class="co">#&gt; tensor([True, True, True, True, True, True, True, True, True, True],</span></a>
<a class="sourceLine" id="cb147-4" data-line-number="4"><span class="co">#&gt;        dtype=torch.bool)</span></a></code></pre></div>
</div>
<div id="tensor-arithmetic" class="section level2">
<h2><span class="header-section-number">4.7</span> Tensor arithmetic</h2>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb148-1" data-line-number="1"><span class="kw">message</span>(<span class="st">&quot;x&quot;</span>)</a>
<a class="sourceLine" id="cb148-2" data-line-number="2"><span class="co">#&gt; x</span></a>
<a class="sourceLine" id="cb148-3" data-line-number="3">(<span class="dt">x =</span> torch<span class="op">$</span><span class="kw">ones</span>(5L, 4L))</a>
<a class="sourceLine" id="cb148-4" data-line-number="4"><span class="co">#&gt; tensor([[1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb148-5" data-line-number="5"><span class="co">#&gt;         [1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb148-6" data-line-number="6"><span class="co">#&gt;         [1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb148-7" data-line-number="7"><span class="co">#&gt;         [1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb148-8" data-line-number="8"><span class="co">#&gt;         [1., 1., 1., 1.]])</span></a>
<a class="sourceLine" id="cb148-9" data-line-number="9"><span class="kw">message</span>(<span class="st">&quot;y&quot;</span>)</a>
<a class="sourceLine" id="cb148-10" data-line-number="10"><span class="co">#&gt; y</span></a>
<a class="sourceLine" id="cb148-11" data-line-number="11">(<span class="dt">y =</span> torch<span class="op">$</span><span class="kw">ones</span>(5L, 4L))</a>
<a class="sourceLine" id="cb148-12" data-line-number="12"><span class="co">#&gt; tensor([[1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb148-13" data-line-number="13"><span class="co">#&gt;         [1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb148-14" data-line-number="14"><span class="co">#&gt;         [1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb148-15" data-line-number="15"><span class="co">#&gt;         [1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb148-16" data-line-number="16"><span class="co">#&gt;         [1., 1., 1., 1.]])</span></a>
<a class="sourceLine" id="cb148-17" data-line-number="17"><span class="kw">message</span>(<span class="st">&quot;x+y&quot;</span>)</a>
<a class="sourceLine" id="cb148-18" data-line-number="18"><span class="co">#&gt; x+y</span></a>
<a class="sourceLine" id="cb148-19" data-line-number="19">x <span class="op">+</span><span class="st"> </span>y</a>
<a class="sourceLine" id="cb148-20" data-line-number="20"><span class="co">#&gt; tensor([[2., 2., 2., 2.],</span></a>
<a class="sourceLine" id="cb148-21" data-line-number="21"><span class="co">#&gt;         [2., 2., 2., 2.],</span></a>
<a class="sourceLine" id="cb148-22" data-line-number="22"><span class="co">#&gt;         [2., 2., 2., 2.],</span></a>
<a class="sourceLine" id="cb148-23" data-line-number="23"><span class="co">#&gt;         [2., 2., 2., 2.],</span></a>
<a class="sourceLine" id="cb148-24" data-line-number="24"><span class="co">#&gt;         [2., 2., 2., 2.]])</span></a></code></pre></div>
<p><span class="math display">\[A + B = B + A\]</span></p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb149-1" data-line-number="1">x <span class="op">+</span><span class="st"> </span>y <span class="op">==</span><span class="st"> </span>y <span class="op">+</span><span class="st"> </span>x</a>
<a class="sourceLine" id="cb149-2" data-line-number="2"><span class="co">#&gt; tensor([[True, True, True, True],</span></a>
<a class="sourceLine" id="cb149-3" data-line-number="3"><span class="co">#&gt;         [True, True, True, True],</span></a>
<a class="sourceLine" id="cb149-4" data-line-number="4"><span class="co">#&gt;         [True, True, True, True],</span></a>
<a class="sourceLine" id="cb149-5" data-line-number="5"><span class="co">#&gt;         [True, True, True, True],</span></a>
<a class="sourceLine" id="cb149-6" data-line-number="6"><span class="co">#&gt;         [True, True, True, True]], dtype=torch.bool)</span></a></code></pre></div>
</div>
<div id="add-a-scalar-to-a-tensor" class="section level2">
<h2><span class="header-section-number">4.8</span> Add a scalar to a tensor</h2>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb150-1" data-line-number="1">s &lt;-<span class="st"> </span><span class="fl">0.5</span>    <span class="co"># scalar</span></a>
<a class="sourceLine" id="cb150-2" data-line-number="2">x <span class="op">+</span><span class="st"> </span>s</a>
<a class="sourceLine" id="cb150-3" data-line-number="3"><span class="co">#&gt; tensor([[1.5000, 1.5000, 1.5000, 1.5000],</span></a>
<a class="sourceLine" id="cb150-4" data-line-number="4"><span class="co">#&gt;         [1.5000, 1.5000, 1.5000, 1.5000],</span></a>
<a class="sourceLine" id="cb150-5" data-line-number="5"><span class="co">#&gt;         [1.5000, 1.5000, 1.5000, 1.5000],</span></a>
<a class="sourceLine" id="cb150-6" data-line-number="6"><span class="co">#&gt;         [1.5000, 1.5000, 1.5000, 1.5000],</span></a>
<a class="sourceLine" id="cb150-7" data-line-number="7"><span class="co">#&gt;         [1.5000, 1.5000, 1.5000, 1.5000]])</span></a></code></pre></div>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb151-1" data-line-number="1"><span class="co"># scalar multiplying two tensors</span></a>
<a class="sourceLine" id="cb151-2" data-line-number="2">s <span class="op">*</span><span class="st"> </span>(x <span class="op">+</span><span class="st"> </span>y)</a>
<a class="sourceLine" id="cb151-3" data-line-number="3"><span class="co">#&gt; tensor([[1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb151-4" data-line-number="4"><span class="co">#&gt;         [1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb151-5" data-line-number="5"><span class="co">#&gt;         [1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb151-6" data-line-number="6"><span class="co">#&gt;         [1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb151-7" data-line-number="7"><span class="co">#&gt;         [1., 1., 1., 1.]])</span></a></code></pre></div>
</div>
<div id="multiplying-tensors" class="section level2">
<h2><span class="header-section-number">4.9</span> Multiplying tensors</h2>
<p><span class="math display">\[A * B = B * A\]</span></p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb152-1" data-line-number="1"><span class="kw">message</span>(<span class="st">&quot;x&quot;</span>)</a>
<a class="sourceLine" id="cb152-2" data-line-number="2"><span class="co">#&gt; x</span></a>
<a class="sourceLine" id="cb152-3" data-line-number="3">(<span class="dt">x =</span> torch<span class="op">$</span><span class="kw">ones</span>(5L, 4L))</a>
<a class="sourceLine" id="cb152-4" data-line-number="4"><span class="co">#&gt; tensor([[1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb152-5" data-line-number="5"><span class="co">#&gt;         [1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb152-6" data-line-number="6"><span class="co">#&gt;         [1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb152-7" data-line-number="7"><span class="co">#&gt;         [1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb152-8" data-line-number="8"><span class="co">#&gt;         [1., 1., 1., 1.]])</span></a>
<a class="sourceLine" id="cb152-9" data-line-number="9"><span class="kw">message</span>(<span class="st">&quot;y&quot;</span>)</a>
<a class="sourceLine" id="cb152-10" data-line-number="10"><span class="co">#&gt; y</span></a>
<a class="sourceLine" id="cb152-11" data-line-number="11">(<span class="dt">y =</span> torch<span class="op">$</span><span class="kw">ones</span>(5L, 4L))</a>
<a class="sourceLine" id="cb152-12" data-line-number="12"><span class="co">#&gt; tensor([[1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb152-13" data-line-number="13"><span class="co">#&gt;         [1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb152-14" data-line-number="14"><span class="co">#&gt;         [1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb152-15" data-line-number="15"><span class="co">#&gt;         [1., 1., 1., 1.],</span></a>
<a class="sourceLine" id="cb152-16" data-line-number="16"><span class="co">#&gt;         [1., 1., 1., 1.]])</span></a>
<a class="sourceLine" id="cb152-17" data-line-number="17"><span class="kw">message</span>(<span class="st">&quot;2x+4y&quot;</span>)</a>
<a class="sourceLine" id="cb152-18" data-line-number="18"><span class="co">#&gt; 2x+4y</span></a>
<a class="sourceLine" id="cb152-19" data-line-number="19">(<span class="dt">z =</span> <span class="dv">2</span> <span class="op">*</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span><span class="dv">4</span> <span class="op">*</span><span class="st"> </span>y)</a>
<a class="sourceLine" id="cb152-20" data-line-number="20"><span class="co">#&gt; tensor([[6., 6., 6., 6.],</span></a>
<a class="sourceLine" id="cb152-21" data-line-number="21"><span class="co">#&gt;         [6., 6., 6., 6.],</span></a>
<a class="sourceLine" id="cb152-22" data-line-number="22"><span class="co">#&gt;         [6., 6., 6., 6.],</span></a>
<a class="sourceLine" id="cb152-23" data-line-number="23"><span class="co">#&gt;         [6., 6., 6., 6.],</span></a>
<a class="sourceLine" id="cb152-24" data-line-number="24"><span class="co">#&gt;         [6., 6., 6., 6.]])</span></a></code></pre></div>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb153-1" data-line-number="1">x <span class="op">*</span><span class="st"> </span>y <span class="op">==</span><span class="st"> </span>y <span class="op">*</span><span class="st"> </span>x</a>
<a class="sourceLine" id="cb153-2" data-line-number="2"><span class="co">#&gt; tensor([[True, True, True, True],</span></a>
<a class="sourceLine" id="cb153-3" data-line-number="3"><span class="co">#&gt;         [True, True, True, True],</span></a>
<a class="sourceLine" id="cb153-4" data-line-number="4"><span class="co">#&gt;         [True, True, True, True],</span></a>
<a class="sourceLine" id="cb153-5" data-line-number="5"><span class="co">#&gt;         [True, True, True, True],</span></a>
<a class="sourceLine" id="cb153-6" data-line-number="6"><span class="co">#&gt;         [True, True, True, True]], dtype=torch.bool)</span></a></code></pre></div>
</div>
<div id="dot-product-1" class="section level2">
<h2><span class="header-section-number">4.10</span> Dot product</h2>
<p><span class="math display">\[dot(a,b)_{i,j,k,a,b,c} = \sum_m a_{i,j,k,m}b_{a,b,m,c}\]</span></p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb154-1" data-line-number="1">torch<span class="op">$</span><span class="kw">dot</span>(torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)), torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>)))</a>
<a class="sourceLine" id="cb154-2" data-line-number="2"><span class="co">#&gt; tensor(7.)</span></a></code></pre></div>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb155-1" data-line-number="1">a &lt;-<span class="st"> </span>np<span class="op">$</span><span class="kw">array</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">list</span>(<span class="dv">3</span>, <span class="dv">4</span>)))</a>
<a class="sourceLine" id="cb155-2" data-line-number="2">a</a>
<a class="sourceLine" id="cb155-3" data-line-number="3"><span class="co">#&gt;      [,1] [,2]</span></a>
<a class="sourceLine" id="cb155-4" data-line-number="4"><span class="co">#&gt; [1,]    1    2</span></a>
<a class="sourceLine" id="cb155-5" data-line-number="5"><span class="co">#&gt; [2,]    3    4</span></a>
<a class="sourceLine" id="cb155-6" data-line-number="6">b &lt;-<span class="st"> </span>np<span class="op">$</span><span class="kw">array</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">list</span>(<span class="dv">3</span>, <span class="dv">4</span>)))</a>
<a class="sourceLine" id="cb155-7" data-line-number="7">b</a>
<a class="sourceLine" id="cb155-8" data-line-number="8"><span class="co">#&gt;      [,1] [,2]</span></a>
<a class="sourceLine" id="cb155-9" data-line-number="9"><span class="co">#&gt; [1,]    1    2</span></a>
<a class="sourceLine" id="cb155-10" data-line-number="10"><span class="co">#&gt; [2,]    3    4</span></a>
<a class="sourceLine" id="cb155-11" data-line-number="11"></a>
<a class="sourceLine" id="cb155-12" data-line-number="12">np<span class="op">$</span><span class="kw">dot</span>(a, b)</a>
<a class="sourceLine" id="cb155-13" data-line-number="13"><span class="co">#&gt;      [,1] [,2]</span></a>
<a class="sourceLine" id="cb155-14" data-line-number="14"><span class="co">#&gt; [1,]    7   10</span></a>
<a class="sourceLine" id="cb155-15" data-line-number="15"><span class="co">#&gt; [2,]   15   22</span></a></code></pre></div>
<p><code>torch.dot()</code> treats both a and b as 1D vectors (irrespective of their original shape) and computes their inner product.</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb156-1" data-line-number="1">at &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(a)</a>
<a class="sourceLine" id="cb156-2" data-line-number="2">bt &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(b)</a>
<a class="sourceLine" id="cb156-3" data-line-number="3"></a>
<a class="sourceLine" id="cb156-4" data-line-number="4"><span class="co"># torch$dot(at, bt)  &lt;- RuntimeError: dot: Expected 1-D argument self, but got 2-D</span></a>
<a class="sourceLine" id="cb156-5" data-line-number="5"><span class="co"># at %.*% bt</span></a></code></pre></div>
<p>If we perform the same dot product operation in Python, we get the same error:</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb157-1" data-line-number="1"><span class="im">import</span> torch</a>
<a class="sourceLine" id="cb157-2" data-line-number="2"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb157-3" data-line-number="3"></a>
<a class="sourceLine" id="cb157-4" data-line-number="4">a <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>]])</a>
<a class="sourceLine" id="cb157-5" data-line-number="5">a</a>
<a class="sourceLine" id="cb157-6" data-line-number="6"><span class="co">#&gt; array([[1, 2],</span></a>
<a class="sourceLine" id="cb157-7" data-line-number="7"><span class="co">#&gt;        [3, 4]])</span></a>
<a class="sourceLine" id="cb157-8" data-line-number="8">b <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>]])</a>
<a class="sourceLine" id="cb157-9" data-line-number="9">b</a>
<a class="sourceLine" id="cb157-10" data-line-number="10"><span class="co">#&gt; array([[1, 2],</span></a>
<a class="sourceLine" id="cb157-11" data-line-number="11"><span class="co">#&gt;        [3, 4]])</span></a>
<a class="sourceLine" id="cb157-12" data-line-number="12">np.dot(a, b)</a>
<a class="sourceLine" id="cb157-13" data-line-number="13"><span class="co">#&gt; array([[ 7, 10],</span></a>
<a class="sourceLine" id="cb157-14" data-line-number="14"><span class="co">#&gt;        [15, 22]])</span></a>
<a class="sourceLine" id="cb157-15" data-line-number="15">at <span class="op">=</span> torch.as_tensor(a)</a>
<a class="sourceLine" id="cb157-16" data-line-number="16">bt <span class="op">=</span> torch.as_tensor(b)</a>
<a class="sourceLine" id="cb157-17" data-line-number="17"></a>
<a class="sourceLine" id="cb157-18" data-line-number="18">at</a>
<a class="sourceLine" id="cb157-19" data-line-number="19"><span class="co">#&gt; tensor([[1, 2],</span></a>
<a class="sourceLine" id="cb157-20" data-line-number="20"><span class="co">#&gt;         [3, 4]])</span></a>
<a class="sourceLine" id="cb157-21" data-line-number="21">bt</a>
<a class="sourceLine" id="cb157-22" data-line-number="22"><span class="co">#&gt; tensor([[1, 2],</span></a>
<a class="sourceLine" id="cb157-23" data-line-number="23"><span class="co">#&gt;         [3, 4]])</span></a>
<a class="sourceLine" id="cb157-24" data-line-number="24">torch.dot(at, bt)</a>
<a class="sourceLine" id="cb157-25" data-line-number="25"><span class="co">#&gt; Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: dot: Expected 1-D argument self, but got 2-D</span></a>
<a class="sourceLine" id="cb157-26" data-line-number="26"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb157-27" data-line-number="27"><span class="co">#&gt; Detailed traceback: </span></a>
<a class="sourceLine" id="cb157-28" data-line-number="28"><span class="co">#&gt;   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</span></a></code></pre></div>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb158-1" data-line-number="1">a &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">list</span>(<span class="dv">3</span>, <span class="dv">4</span>)))</a>
<a class="sourceLine" id="cb158-2" data-line-number="2">b &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">c</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">4</span>)))</a>
<a class="sourceLine" id="cb158-3" data-line-number="3">c &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">11</span>, <span class="dv">12</span>), <span class="kw">list</span>(<span class="dv">13</span>, <span class="dv">14</span>)))</a>
<a class="sourceLine" id="cb158-4" data-line-number="4"></a>
<a class="sourceLine" id="cb158-5" data-line-number="5">a</a>
<a class="sourceLine" id="cb158-6" data-line-number="6"><span class="co">#&gt; tensor([[1., 2.],</span></a>
<a class="sourceLine" id="cb158-7" data-line-number="7"><span class="co">#&gt;         [3., 4.]])</span></a>
<a class="sourceLine" id="cb158-8" data-line-number="8">b</a>
<a class="sourceLine" id="cb158-9" data-line-number="9"><span class="co">#&gt; tensor([1., 2., 3., 4.])</span></a>
<a class="sourceLine" id="cb158-10" data-line-number="10">torch<span class="op">$</span><span class="kw">dot</span>(a, b)</a>
<a class="sourceLine" id="cb158-11" data-line-number="11"><span class="co">#&gt; Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: dot: Expected 1-D argument self, but got 2-D</span></a>
<a class="sourceLine" id="cb158-12" data-line-number="12"></a>
<a class="sourceLine" id="cb158-13" data-line-number="13"><span class="co"># this is another way of performing dot product in PyTorch</span></a>
<a class="sourceLine" id="cb158-14" data-line-number="14"><span class="co"># a$dot(a)</span></a></code></pre></div>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb159-1" data-line-number="1">o1 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(2L, 2L)</a>
<a class="sourceLine" id="cb159-2" data-line-number="2">o2 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(2L, 2L)</a>
<a class="sourceLine" id="cb159-3" data-line-number="3"></a>
<a class="sourceLine" id="cb159-4" data-line-number="4">o1</a>
<a class="sourceLine" id="cb159-5" data-line-number="5"><span class="co">#&gt; tensor([[1., 1.],</span></a>
<a class="sourceLine" id="cb159-6" data-line-number="6"><span class="co">#&gt;         [1., 1.]])</span></a>
<a class="sourceLine" id="cb159-7" data-line-number="7">o2</a>
<a class="sourceLine" id="cb159-8" data-line-number="8"><span class="co">#&gt; tensor([[1., 1.],</span></a>
<a class="sourceLine" id="cb159-9" data-line-number="9"><span class="co">#&gt;         [1., 1.]])</span></a>
<a class="sourceLine" id="cb159-10" data-line-number="10"></a>
<a class="sourceLine" id="cb159-11" data-line-number="11">torch<span class="op">$</span><span class="kw">dot</span>(o1, o2)</a>
<a class="sourceLine" id="cb159-12" data-line-number="12"><span class="co">#&gt; Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: dot: Expected 1-D argument self, but got 2-D</span></a>
<a class="sourceLine" id="cb159-13" data-line-number="13">o1<span class="op">$</span><span class="kw">dot</span>(o2)</a>
<a class="sourceLine" id="cb159-14" data-line-number="14"><span class="co">#&gt; Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: dot: Expected 1-D argument self, but got 2-D</span></a></code></pre></div>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb160-1" data-line-number="1"><span class="co"># 1D tensors work fine</span></a>
<a class="sourceLine" id="cb160-2" data-line-number="2">r =<span class="st"> </span>torch<span class="op">$</span><span class="kw">dot</span>(torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(4L, 2L, 4L)), torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(3L, 4L, 1L)))</a>
<a class="sourceLine" id="cb160-3" data-line-number="3">r</a>
<a class="sourceLine" id="cb160-4" data-line-number="4"><span class="co">#&gt; tensor(24.)</span></a></code></pre></div>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb161-1" data-line-number="1"><span class="co">## mm and matmul seem to address the dot product we are looking for in tensors</span></a>
<a class="sourceLine" id="cb161-2" data-line-number="2">a =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(2L, 3L)</a>
<a class="sourceLine" id="cb161-3" data-line-number="3">b =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(3L, 4L)</a>
<a class="sourceLine" id="cb161-4" data-line-number="4"></a>
<a class="sourceLine" id="cb161-5" data-line-number="5">a<span class="op">$</span><span class="kw">mm</span>(b)</a>
<a class="sourceLine" id="cb161-6" data-line-number="6"><span class="co">#&gt; tensor([[ 0.0280, -2.1269, -0.3169,  0.1623],</span></a>
<a class="sourceLine" id="cb161-7" data-line-number="7"><span class="co">#&gt;         [-0.2900,  2.1708, -2.3575,  0.5110]])</span></a>
<a class="sourceLine" id="cb161-8" data-line-number="8">a<span class="op">$</span><span class="kw">matmul</span>(b)</a>
<a class="sourceLine" id="cb161-9" data-line-number="9"><span class="co">#&gt; tensor([[ 0.0280, -2.1269, -0.3169,  0.1623],</span></a>
<a class="sourceLine" id="cb161-10" data-line-number="10"><span class="co">#&gt;         [-0.2900,  2.1708, -2.3575,  0.5110]])</span></a></code></pre></div>
<p>Here is agood explanation: <a href="https://stackoverflow.com/a/44525687/5270873" class="uri">https://stackoverflow.com/a/44525687/5270873</a></p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb162-1" data-line-number="1">abt &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">mm</span>(a, b)<span class="op">$</span><span class="kw">transpose</span>(<span class="dt">dim0=</span>0L, <span class="dt">dim1=</span>1L)</a>
<a class="sourceLine" id="cb162-2" data-line-number="2">abt</a>
<a class="sourceLine" id="cb162-3" data-line-number="3"><span class="co">#&gt; tensor([[ 0.0280, -0.2900],</span></a>
<a class="sourceLine" id="cb162-4" data-line-number="4"><span class="co">#&gt;         [-2.1269,  2.1708],</span></a>
<a class="sourceLine" id="cb162-5" data-line-number="5"><span class="co">#&gt;         [-0.3169, -2.3575],</span></a>
<a class="sourceLine" id="cb162-6" data-line-number="6"><span class="co">#&gt;         [ 0.1623,  0.5110]])</span></a></code></pre></div>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb163-1" data-line-number="1">at &lt;-<span class="st"> </span>a<span class="op">$</span><span class="kw">transpose</span>(<span class="dt">dim0=</span>0L, <span class="dt">dim1=</span>1L)</a>
<a class="sourceLine" id="cb163-2" data-line-number="2">bt &lt;-<span class="st"> </span>b<span class="op">$</span><span class="kw">transpose</span>(<span class="dt">dim0=</span>0L, <span class="dt">dim1=</span>1L)</a>
<a class="sourceLine" id="cb163-3" data-line-number="3"></a>
<a class="sourceLine" id="cb163-4" data-line-number="4">btat &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">matmul</span>(bt, at)</a>
<a class="sourceLine" id="cb163-5" data-line-number="5">btat</a>
<a class="sourceLine" id="cb163-6" data-line-number="6"><span class="co">#&gt; tensor([[ 0.0280, -0.2900],</span></a>
<a class="sourceLine" id="cb163-7" data-line-number="7"><span class="co">#&gt;         [-2.1269,  2.1708],</span></a>
<a class="sourceLine" id="cb163-8" data-line-number="8"><span class="co">#&gt;         [-0.3169, -2.3575],</span></a>
<a class="sourceLine" id="cb163-9" data-line-number="9"><span class="co">#&gt;         [ 0.1623,  0.5110]])</span></a></code></pre></div>
<p><span class="math display">\[(A B)^T = B^T A^T\]</span></p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb164-1" data-line-number="1"><span class="co"># tolerance</span></a>
<a class="sourceLine" id="cb164-2" data-line-number="2">torch<span class="op">$</span><span class="kw">allclose</span>(abt, btat, <span class="dt">rtol=</span><span class="fl">0.0001</span>)</a>
<a class="sourceLine" id="cb164-3" data-line-number="3"><span class="co">#&gt; [1] TRUE</span></a></code></pre></div>

</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="tensors.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mnistdigits.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["rtorch-book.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

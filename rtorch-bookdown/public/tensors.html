<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Tensors | A Minimal rTorch Tutorial</title>
  <meta name="description" content="This is a minimal tutorial of using the rTorch package to have fun while doing machine learning. This book was produced with bookdown." />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Tensors | A Minimal rTorch Tutorial" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal tutorial of using the rTorch package to have fun while doing machine learning. This book was produced with bookdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Tensors | A Minimal rTorch Tutorial" />
  
  <meta name="twitter:description" content="This is a minimal tutorial of using the rTorch package to have fun while doing machine learning. This book was produced with bookdown." />
  

<meta name="author" content="Alfonso R. Reyes" />


<meta name="date" content="2019-09-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="rtorch-vs-pytorch-whats-different.html"/>
<link rel="next" href="linearalgebra.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal rTorch Tutorial</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#python-anaconda"><i class="fa fa-check"></i>Python Anaconda</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#example"><i class="fa fa-check"></i>Example</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#automatic-installation"><i class="fa fa-check"></i>Automatic installation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Getting Started</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#motivation"><i class="fa fa-check"></i><b>1.1</b> Motivation</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#how-do-we-start-using-rtorch"><i class="fa fa-check"></i><b>1.2</b> How do we start using <code>rTorch</code></a><ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#getting-the-pytorch-version"><i class="fa fa-check"></i><b>1.2.1</b> Getting the PyTorch version</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#pytorch-configuration"><i class="fa fa-check"></i><b>1.2.2</b> PyTorch configuration</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#what-can-you-do-with-rtorch"><i class="fa fa-check"></i><b>1.3</b> What can you do with <code>rTorch</code></a><ul>
<li class="chapter" data-level="1.3.1" data-path="intro.html"><a href="intro.html#the-torchvision-module"><i class="fa fa-check"></i><b>1.3.1</b> The <code>torchvision</code> module</a></li>
<li class="chapter" data-level="1.3.2" data-path="intro.html"><a href="intro.html#np-the-numpy-module"><i class="fa fa-check"></i><b>1.3.2</b> <code>np</code>: the <code>numpy</code> module</a></li>
<li class="chapter" data-level="1.3.3" data-path="intro.html"><a href="intro.html#python-built-in-functions"><i class="fa fa-check"></i><b>1.3.3</b> Python built-in functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html"><i class="fa fa-check"></i><b>2</b> rTorch vs PyTorch: Whatâ€™s different</a><ul>
<li class="chapter" data-level="2.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#calling-objects-from-pytorch"><i class="fa fa-check"></i><b>2.1</b> Calling objects from PyTorch</a></li>
<li class="chapter" data-level="2.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#call-a-module-from-pytorch"><i class="fa fa-check"></i><b>2.2</b> Call a module from PyTorch</a></li>
<li class="chapter" data-level="2.3" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#show-the-attributes-methods-of-a-class-or-pytorch-object"><i class="fa fa-check"></i><b>2.3</b> Show the attributes (methods) of a class or PyTorch object</a></li>
<li class="chapter" data-level="2.4" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#enumeration"><i class="fa fa-check"></i><b>2.4</b> Enumeration</a></li>
<li class="chapter" data-level="2.5" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#how-to-iterate"><i class="fa fa-check"></i><b>2.5</b> How to iterate</a><ul>
<li class="chapter" data-level="2.5.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#using-enumerate-and-iterate"><i class="fa fa-check"></i><b>2.5.1</b> Using <code>enumerate</code> and <code>iterate</code></a></li>
<li class="chapter" data-level="2.5.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#using-a-for-loop-to-iterate"><i class="fa fa-check"></i><b>2.5.2</b> Using a <code>for-loop</code> to iterate</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#zero-gradient"><i class="fa fa-check"></i><b>2.6</b> Zero gradient</a><ul>
<li class="chapter" data-level="2.6.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#version-in-python"><i class="fa fa-check"></i><b>2.6.1</b> Version in Python</a></li>
<li class="chapter" data-level="2.6.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#version-in-r"><i class="fa fa-check"></i><b>2.6.2</b> Version in R</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#transform-a-tensor"><i class="fa fa-check"></i><b>2.7</b> Transform a tensor</a></li>
<li class="chapter" data-level="2.8" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#build-a-model-class"><i class="fa fa-check"></i><b>2.8</b> Build a model class</a><ul>
<li class="chapter" data-level="2.8.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#example-1"><i class="fa fa-check"></i><b>2.8.1</b> Example 1</a></li>
<li class="chapter" data-level="2.8.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#example-2"><i class="fa fa-check"></i><b>2.8.2</b> Example 2</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#convert-a-tensor-to-numpy-object"><i class="fa fa-check"></i><b>2.9</b> Convert a tensor to <code>numpy</code> object</a></li>
<li class="chapter" data-level="2.10" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#convert-a-numpy-object-to-an-r-object"><i class="fa fa-check"></i><b>2.10</b> Convert a <code>numpy</code> object to an <code>R</code> object</a></li>
</ul></li>
<li class="part"><span><b>II Basic Tensor Operations</b></span></li>
<li class="chapter" data-level="3" data-path="tensors.html"><a href="tensors.html"><i class="fa fa-check"></i><b>3</b> Tensors</a><ul>
<li class="chapter" data-level="3.1" data-path="tensors.html"><a href="tensors.html#tensor-data-types"><i class="fa fa-check"></i><b>3.1</b> Tensor data types</a></li>
<li class="chapter" data-level="3.2" data-path="tensors.html"><a href="tensors.html#arithmetic-of-tensors"><i class="fa fa-check"></i><b>3.2</b> Arithmetic of tensors</a><ul>
<li class="chapter" data-level="3.2.1" data-path="tensors.html"><a href="tensors.html#add-tensors"><i class="fa fa-check"></i><b>3.2.1</b> Add tensors</a></li>
<li class="chapter" data-level="3.2.2" data-path="tensors.html"><a href="tensors.html#multiply-a-tensor-by-a-scalar"><i class="fa fa-check"></i><b>3.2.2</b> Multiply a tensor by a scalar</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="tensors.html"><a href="tensors.html#numpy-and-pytorch"><i class="fa fa-check"></i><b>3.3</b> NumPy and PyTorch</a><ul>
<li class="chapter" data-level="3.3.1" data-path="tensors.html"><a href="tensors.html#tuples-python-and-vectors-r"><i class="fa fa-check"></i><b>3.3.1</b> Tuples (Python) and vectors (R)</a></li>
<li class="chapter" data-level="3.3.2" data-path="tensors.html"><a href="tensors.html#make-a-numpy-array-a-tensor-with-as_tensor"><i class="fa fa-check"></i><b>3.3.2</b> Make a numpy array a tensor with <code>as_tensor()</code></a></li>
<li class="chapter" data-level="3.3.3" data-path="tensors.html"><a href="tensors.html#tensor-to-array-and-viceversa"><i class="fa fa-check"></i><b>3.3.3</b> Tensor to array, and viceversa</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="tensors.html"><a href="tensors.html#create-tensors"><i class="fa fa-check"></i><b>3.4</b> Create tensors</a></li>
<li class="chapter" data-level="3.5" data-path="tensors.html"><a href="tensors.html#tensor-resizing"><i class="fa fa-check"></i><b>3.5</b> Tensor resizing</a><ul>
<li class="chapter" data-level="3.5.1" data-path="tensors.html"><a href="tensors.html#concatenate-tensors"><i class="fa fa-check"></i><b>3.5.1</b> Concatenate tensors</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="tensors.html"><a href="tensors.html#reshape-tensors"><i class="fa fa-check"></i><b>3.6</b> Reshape tensors</a><ul>
<li class="chapter" data-level="3.6.1" data-path="tensors.html"><a href="tensors.html#with-function-chunk"><i class="fa fa-check"></i><b>3.6.1</b> With function <code>chunk()</code>:</a></li>
<li class="chapter" data-level="3.6.2" data-path="tensors.html"><a href="tensors.html#with-index_select"><i class="fa fa-check"></i><b>3.6.2</b> With <code>index_select()</code>:</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="tensors.html"><a href="tensors.html#special-tensors"><i class="fa fa-check"></i><b>3.7</b> Special tensors</a><ul>
<li class="chapter" data-level="3.7.1" data-path="tensors.html"><a href="tensors.html#identity-matrix"><i class="fa fa-check"></i><b>3.7.1</b> Identity matrix</a></li>
<li class="chapter" data-level="3.7.2" data-path="tensors.html"><a href="tensors.html#ones"><i class="fa fa-check"></i><b>3.7.2</b> Ones</a></li>
<li class="chapter" data-level="3.7.3" data-path="tensors.html"><a href="tensors.html#zeros"><i class="fa fa-check"></i><b>3.7.3</b> Zeros</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="tensors.html"><a href="tensors.html#tensor-fill"><i class="fa fa-check"></i><b>3.8</b> Tensor fill</a><ul>
<li class="chapter" data-level="3.8.1" data-path="tensors.html"><a href="tensors.html#initialize-a-linear-or-log-scale-tensor"><i class="fa fa-check"></i><b>3.8.1</b> Initialize a linear or log scale Tensor</a></li>
<li class="chapter" data-level="3.8.2" data-path="tensors.html"><a href="tensors.html#inplace-out-of-place"><i class="fa fa-check"></i><b>3.8.2</b> Inplace / Out-of-place</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="tensors.html"><a href="tensors.html#access-to-tensor-elements"><i class="fa fa-check"></i><b>3.9</b> Access to tensor elements</a></li>
<li class="chapter" data-level="3.10" data-path="tensors.html"><a href="tensors.html#tensor-operations"><i class="fa fa-check"></i><b>3.10</b> Tensor operations</a><ul>
<li class="chapter" data-level="3.10.1" data-path="tensors.html"><a href="tensors.html#cross-product"><i class="fa fa-check"></i><b>3.10.1</b> cross product</a></li>
<li class="chapter" data-level="3.10.2" data-path="tensors.html"><a href="tensors.html#dot-product"><i class="fa fa-check"></i><b>3.10.2</b> Dot product</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="tensors.html"><a href="tensors.html#logical-operations"><i class="fa fa-check"></i><b>3.11</b> Logical operations</a><ul>
<li class="chapter" data-level="3.11.1" data-path="tensors.html"><a href="tensors.html#logical-not"><i class="fa fa-check"></i><b>3.11.1</b> Logical NOT</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="tensors.html"><a href="tensors.html#distributions"><i class="fa fa-check"></i><b>3.12</b> Distributions</a><ul>
<li class="chapter" data-level="3.12.1" data-path="tensors.html"><a href="tensors.html#uniform-matrix"><i class="fa fa-check"></i><b>3.12.1</b> Uniform matrix</a></li>
<li class="chapter" data-level="3.12.2" data-path="tensors.html"><a href="tensors.html#binomial-distribution"><i class="fa fa-check"></i><b>3.12.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="3.12.3" data-path="tensors.html"><a href="tensors.html#exponential-distribution"><i class="fa fa-check"></i><b>3.12.3</b> Exponential distribution</a></li>
<li class="chapter" data-level="3.12.4" data-path="tensors.html"><a href="tensors.html#weibull-distribution"><i class="fa fa-check"></i><b>3.12.4</b> Weibull distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linearalgebra.html"><a href="linearalgebra.html"><i class="fa fa-check"></i><b>4</b> Linear Algebra with Torch</a><ul>
<li class="chapter" data-level="4.1" data-path="linearalgebra.html"><a href="linearalgebra.html#scalars"><i class="fa fa-check"></i><b>4.1</b> Scalars</a></li>
<li class="chapter" data-level="4.2" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors"><i class="fa fa-check"></i><b>4.2</b> Vectors</a></li>
<li class="chapter" data-level="4.3" data-path="linearalgebra.html"><a href="linearalgebra.html#matrices"><i class="fa fa-check"></i><b>4.3</b> Matrices</a></li>
<li class="chapter" data-level="4.4" data-path="linearalgebra.html"><a href="linearalgebra.html#d-tensors"><i class="fa fa-check"></i><b>4.4</b> 3D+ tensors</a></li>
<li class="chapter" data-level="4.5" data-path="linearalgebra.html"><a href="linearalgebra.html#transpose-of-a-matrix"><i class="fa fa-check"></i><b>4.5</b> Transpose of a matrix</a></li>
<li class="chapter" data-level="4.6" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors-special-case-of-a-matrix"><i class="fa fa-check"></i><b>4.6</b> Vectors, special case of a matrix</a></li>
<li class="chapter" data-level="4.7" data-path="linearalgebra.html"><a href="linearalgebra.html#tensor-arithmetic"><i class="fa fa-check"></i><b>4.7</b> Tensor arithmetic</a></li>
<li class="chapter" data-level="4.8" data-path="linearalgebra.html"><a href="linearalgebra.html#add-a-scalar-to-a-tensor"><i class="fa fa-check"></i><b>4.8</b> Add a scalar to a tensor</a></li>
<li class="chapter" data-level="4.9" data-path="linearalgebra.html"><a href="linearalgebra.html#multiplying-tensors"><i class="fa fa-check"></i><b>4.9</b> Multiplying tensors</a></li>
<li class="chapter" data-level="4.10" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-1"><i class="fa fa-check"></i><b>4.10</b> Dot product</a></li>
</ul></li>
<li class="part"><span><b>III Logistic Regression</b></span></li>
<li class="chapter" data-level="5" data-path="mnistdigits.html"><a href="mnistdigits.html"><i class="fa fa-check"></i><b>5</b> Example 1: MNIST handwritten digits</a><ul>
<li class="chapter" data-level="5.1" data-path="mnistdigits.html"><a href="mnistdigits.html#hyperparameters"><i class="fa fa-check"></i><b>5.1</b> Hyperparameters</a></li>
<li class="chapter" data-level="5.2" data-path="mnistdigits.html"><a href="mnistdigits.html#read-datasets"><i class="fa fa-check"></i><b>5.2</b> Read datasets</a></li>
<li class="chapter" data-level="5.3" data-path="mnistdigits.html"><a href="mnistdigits.html#define-the-model"><i class="fa fa-check"></i><b>5.3</b> Define the model</a></li>
<li class="chapter" data-level="5.4" data-path="mnistdigits.html"><a href="mnistdigits.html#training"><i class="fa fa-check"></i><b>5.4</b> Training</a></li>
<li class="chapter" data-level="5.5" data-path="mnistdigits.html"><a href="mnistdigits.html#prediction"><i class="fa fa-check"></i><b>5.5</b> Prediction</a></li>
<li class="chapter" data-level="5.6" data-path="mnistdigits.html"><a href="mnistdigits.html#save-the-model"><i class="fa fa-check"></i><b>5.6</b> Save the model</a></li>
</ul></li>
<li class="part"><span><b>IV Linear Regression</b></span></li>
<li class="chapter" data-level="6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>6</b> Simple linear regression</a><ul>
<li class="chapter" data-level="6.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#introduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#generate-the-dataset"><i class="fa fa-check"></i><b>6.2</b> Generate the dataset</a></li>
<li class="chapter" data-level="6.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#convert-arrays-to-tensors"><i class="fa fa-check"></i><b>6.3</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="6.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#converting-from-numpy-to-tensor"><i class="fa fa-check"></i><b>6.4</b> Converting from numpy to tensor</a></li>
<li class="chapter" data-level="6.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#creating-the-network-model"><i class="fa fa-check"></i><b>6.5</b> Creating the network model</a></li>
<li class="chapter" data-level="6.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#optimizer-and-loss"><i class="fa fa-check"></i><b>6.6</b> Optimizer and Loss</a></li>
<li class="chapter" data-level="6.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#training-1"><i class="fa fa-check"></i><b>6.7</b> Training</a></li>
<li class="chapter" data-level="6.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#results"><i class="fa fa-check"></i><b>6.8</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html"><i class="fa fa-check"></i><b>7</b> Rainfall. Linear Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#training-data"><i class="fa fa-check"></i><b>7.1</b> Training data</a></li>
<li class="chapter" data-level="7.2" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#convert-arrays-to-tensors-1"><i class="fa fa-check"></i><b>7.2</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="7.3" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#build-the-model"><i class="fa fa-check"></i><b>7.3</b> Build the model</a></li>
<li class="chapter" data-level="7.4" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#generate-predictions"><i class="fa fa-check"></i><b>7.4</b> Generate predictions</a></li>
<li class="chapter" data-level="7.5" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#loss-function"><i class="fa fa-check"></i><b>7.5</b> Loss Function</a></li>
<li class="chapter" data-level="7.6" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#step-by-step-process"><i class="fa fa-check"></i><b>7.6</b> Step by step process</a><ul>
<li class="chapter" data-level="7.6.1" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#compute-the-losses"><i class="fa fa-check"></i><b>7.6.1</b> Compute the losses</a></li>
<li class="chapter" data-level="7.6.2" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#compute-gradients"><i class="fa fa-check"></i><b>7.6.2</b> Compute Gradients</a></li>
<li class="chapter" data-level="7.6.3" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#reset-the-gradients"><i class="fa fa-check"></i><b>7.6.3</b> Reset the gradients</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#all-together-train-for-multiple-epochs"><i class="fa fa-check"></i><b>7.7</b> All together: train for multiple epochs</a></li>
</ul></li>
<li class="part"><span><b>V Neural Networks</b></span></li>
<li class="chapter" data-level="8" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html"><i class="fa fa-check"></i><b>8</b> A two-layer neural network</a><ul>
<li class="chapter" data-level="8.1" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#load-the-libraries"><i class="fa fa-check"></i><b>8.1</b> Load the libraries</a></li>
<li class="chapter" data-level="8.2" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#dataset"><i class="fa fa-check"></i><b>8.2</b> Dataset</a></li>
<li class="chapter" data-level="8.3" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#run-the-model-for-50-iterations"><i class="fa fa-check"></i><b>8.3</b> Run the model for 50 iterations</a></li>
<li class="chapter" data-level="8.4" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#run-it-at-100-iterations"><i class="fa fa-check"></i><b>8.4</b> Run it at 100 iterations</a></li>
<li class="chapter" data-level="8.5" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#original-pytorch-code"><i class="fa fa-check"></i><b>8.5</b> Original PyTorch code</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html"><i class="fa fa-check"></i><b>9</b> A very simple neural network</a><ul>
<li class="chapter" data-level="9.1" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#introduction-1"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#select-device"><i class="fa fa-check"></i><b>9.2</b> Select device</a></li>
<li class="chapter" data-level="9.3" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#create-the-dataset"><i class="fa fa-check"></i><b>9.3</b> Create the dataset</a></li>
<li class="chapter" data-level="9.4" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#define-the-model-1"><i class="fa fa-check"></i><b>9.4</b> Define the model</a></li>
<li class="chapter" data-level="9.5" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#loss-function-1"><i class="fa fa-check"></i><b>9.5</b> Loss function</a></li>
<li class="chapter" data-level="9.6" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#iterate-through-batches"><i class="fa fa-check"></i><b>9.6</b> Iterate through batches</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="neural-networks-2.html"><a href="neural-networks-2.html"><i class="fa fa-check"></i><b>10</b> Neural Networks 2</a><ul>
<li class="chapter" data-level="10.1" data-path="neural-networks-2.html"><a href="neural-networks-2.html#nn2-1"><i class="fa fa-check"></i><b>10.1</b> nn2 1</a></li>
<li class="chapter" data-level="10.2" data-path="neural-networks-2.html"><a href="neural-networks-2.html#nn2-2"><i class="fa fa-check"></i><b>10.2</b> nn2 2</a></li>
</ul></li>
<li class="part"><span><b>VI Image Recognition</b></span></li>
<li class="part"><span><b>VII PyTorch and R data structures</b></span></li>
<li class="chapter" data-level="11" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html"><i class="fa fa-check"></i><b>11</b> Working with data.frame</a><ul>
<li class="chapter" data-level="11.1" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#load-pytorch-libraries"><i class="fa fa-check"></i><b>11.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="11.2" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#dataset-iteration-batch-settings"><i class="fa fa-check"></i><b>11.2</b> Dataset iteration batch settings</a></li>
<li class="chapter" data-level="11.3" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#summary-statistics-for-tensors"><i class="fa fa-check"></i><b>11.3</b> Summary statistics for tensors</a></li>
<li class="chapter" data-level="11.4" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#using-data.frame"><i class="fa fa-check"></i><b>11.4</b> using <code>data.frame</code></a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="working-with-data-table.html"><a href="working-with-data-table.html"><i class="fa fa-check"></i><b>12</b> Working with data.table</a><ul>
<li class="chapter" data-level="12.1" data-path="working-with-data-table.html"><a href="working-with-data-table.html#load-pytorch-libraries-1"><i class="fa fa-check"></i><b>12.1</b> Load PyTorch libraries</a><ul>
<li class="chapter" data-level="12.1.1" data-path="working-with-data-table.html"><a href="working-with-data-table.html#using-data.table"><i class="fa fa-check"></i><b>12.1.1</b> Using `data.table</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendixA.html"><a href="appendixA.html"><i class="fa fa-check"></i><b>A</b> Statistical Background</a><ul>
<li class="chapter" data-level="A.1" data-path="appendixA.html"><a href="appendixA.html#basic-statistical-terms"><i class="fa fa-check"></i><b>A.1</b> Basic statistical terms</a><ul>
<li class="chapter" data-level="A.1.1" data-path="appendixA.html"><a href="appendixA.html#mean"><i class="fa fa-check"></i><b>A.1.1</b> Mean</a></li>
<li class="chapter" data-level="A.1.2" data-path="appendixA.html"><a href="appendixA.html#median"><i class="fa fa-check"></i><b>A.1.2</b> Median</a></li>
<li class="chapter" data-level="A.1.3" data-path="appendixA.html"><a href="appendixA.html#standard-deviation"><i class="fa fa-check"></i><b>A.1.3</b> Standard deviation</a></li>
<li class="chapter" data-level="A.1.4" data-path="appendixA.html"><a href="appendixA.html#five-number-summary"><i class="fa fa-check"></i><b>A.1.4</b> Five-number summary</a></li>
<li class="chapter" data-level="A.1.5" data-path="appendixA.html"><a href="appendixA.html#distribution"><i class="fa fa-check"></i><b>A.1.5</b> Distribution</a></li>
<li class="chapter" data-level="A.1.6" data-path="appendixA.html"><a href="appendixA.html#outliers"><i class="fa fa-check"></i><b>A.1.6</b> Outliers</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Minimal rTorch Tutorial</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tensors" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Tensors</h1>
<p>We describe the most important PyTorch methods in this chapter.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(rTorch)</a></code></pre></div>
<div id="tensor-data-types" class="section level2">
<h2><span class="header-section-number">3.1</span> Tensor data types</h2>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="co"># Default data type</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2">torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="fl">1.2</span>, <span class="dv">3</span>))<span class="op">$</span>dtype  <span class="co"># default for floating point is torch.float32</span></a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="co">#&gt; torch.float32</span></a></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="co"># change default data type to float64</span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2">torch<span class="op">$</span><span class="kw">set_default_dtype</span>(torch<span class="op">$</span>float64)</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="fl">1.2</span>, <span class="dv">3</span>))<span class="op">$</span>dtype         <span class="co"># a new floating point tensor</span></a>
<a class="sourceLine" id="cb3-4" data-line-number="4"><span class="co">#&gt; torch.float64</span></a></code></pre></div>
<p>There are five major type of Tensors in PyTorch</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw">library</span>(rTorch)</a>
<a class="sourceLine" id="cb4-2" data-line-number="2"></a>
<a class="sourceLine" id="cb4-3" data-line-number="3">byte    &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ByteTensor</span>(3L, 3L)</a>
<a class="sourceLine" id="cb4-4" data-line-number="4">float   &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(3L, 3L)</a>
<a class="sourceLine" id="cb4-5" data-line-number="5">double  &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">DoubleTensor</span>(3L, 3L)</a>
<a class="sourceLine" id="cb4-6" data-line-number="6">long    &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">LongTensor</span>(3L, 3L)</a>
<a class="sourceLine" id="cb4-7" data-line-number="7">boolean &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">BoolTensor</span>(5L, 5L)</a>
<a class="sourceLine" id="cb4-8" data-line-number="8"></a>
<a class="sourceLine" id="cb4-9" data-line-number="9"><span class="kw">message</span>(<span class="st">&quot;byte tensor&quot;</span>)</a>
<a class="sourceLine" id="cb4-10" data-line-number="10"><span class="co">#&gt; byte tensor</span></a>
<a class="sourceLine" id="cb4-11" data-line-number="11">byte</a>
<a class="sourceLine" id="cb4-12" data-line-number="12"><span class="co">#&gt; tensor([[0, 0, 0],</span></a>
<a class="sourceLine" id="cb4-13" data-line-number="13"><span class="co">#&gt;         [0, 0, 0],</span></a>
<a class="sourceLine" id="cb4-14" data-line-number="14"><span class="co">#&gt;         [0, 0, 0]], dtype=torch.uint8)</span></a>
<a class="sourceLine" id="cb4-15" data-line-number="15"></a>
<a class="sourceLine" id="cb4-16" data-line-number="16"><span class="kw">message</span>(<span class="st">&quot;float tensor&quot;</span>)</a>
<a class="sourceLine" id="cb4-17" data-line-number="17"><span class="co">#&gt; float tensor</span></a>
<a class="sourceLine" id="cb4-18" data-line-number="18">float</a>
<a class="sourceLine" id="cb4-19" data-line-number="19"><span class="co">#&gt; tensor([[0., 0., 0.],</span></a>
<a class="sourceLine" id="cb4-20" data-line-number="20"><span class="co">#&gt;         [0., 0., 0.],</span></a>
<a class="sourceLine" id="cb4-21" data-line-number="21"><span class="co">#&gt;         [0., 0., 0.]], dtype=torch.float32)</span></a>
<a class="sourceLine" id="cb4-22" data-line-number="22"></a>
<a class="sourceLine" id="cb4-23" data-line-number="23"><span class="kw">message</span>(<span class="st">&quot;double&quot;</span>)</a>
<a class="sourceLine" id="cb4-24" data-line-number="24"><span class="co">#&gt; double</span></a>
<a class="sourceLine" id="cb4-25" data-line-number="25">double</a>
<a class="sourceLine" id="cb4-26" data-line-number="26"><span class="co">#&gt; tensor([[ 0.0000e+00,  0.0000e+00, 9.5490e-313],</span></a>
<a class="sourceLine" id="cb4-27" data-line-number="27"><span class="co">#&gt;         [4.6567e-310, 4.9407e-324, 4.6567e-310],</span></a>
<a class="sourceLine" id="cb4-28" data-line-number="28"><span class="co">#&gt;         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]])</span></a>
<a class="sourceLine" id="cb4-29" data-line-number="29"></a>
<a class="sourceLine" id="cb4-30" data-line-number="30"><span class="kw">message</span>(<span class="st">&quot;long&quot;</span>)</a>
<a class="sourceLine" id="cb4-31" data-line-number="31"><span class="co">#&gt; long</span></a>
<a class="sourceLine" id="cb4-32" data-line-number="32">long</a>
<a class="sourceLine" id="cb4-33" data-line-number="33"><span class="co">#&gt; tensor([[0, 0, 0],</span></a>
<a class="sourceLine" id="cb4-34" data-line-number="34"><span class="co">#&gt;         [0, 0, 0],</span></a>
<a class="sourceLine" id="cb4-35" data-line-number="35"><span class="co">#&gt;         [0, 0, 0]])</span></a>
<a class="sourceLine" id="cb4-36" data-line-number="36"></a>
<a class="sourceLine" id="cb4-37" data-line-number="37"><span class="kw">message</span>(<span class="st">&quot;boolean&quot;</span>)</a>
<a class="sourceLine" id="cb4-38" data-line-number="38"><span class="co">#&gt; boolean</span></a>
<a class="sourceLine" id="cb4-39" data-line-number="39">boolean</a>
<a class="sourceLine" id="cb4-40" data-line-number="40"><span class="co">#&gt; tensor([[False, False, False, False, False],</span></a>
<a class="sourceLine" id="cb4-41" data-line-number="41"><span class="co">#&gt;         [False, False, False, False, False],</span></a>
<a class="sourceLine" id="cb4-42" data-line-number="42"><span class="co">#&gt;         [False, False, False, False, False],</span></a>
<a class="sourceLine" id="cb4-43" data-line-number="43"><span class="co">#&gt;         [False, False, False, False, False],</span></a>
<a class="sourceLine" id="cb4-44" data-line-number="44"><span class="co">#&gt;         [False, False, False, False, False]], dtype=torch.bool)</span></a></code></pre></div>
<p>A 4D tensor like in MNIST hand-written digits recognition dataset:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1">mnist_4d &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(60000L, 3L, 28L, 28L)</a>
<a class="sourceLine" id="cb5-2" data-line-number="2"></a>
<a class="sourceLine" id="cb5-3" data-line-number="3"><span class="kw">message</span>(<span class="st">&quot;size&quot;</span>)</a>
<a class="sourceLine" id="cb5-4" data-line-number="4"><span class="co">#&gt; size</span></a>
<a class="sourceLine" id="cb5-5" data-line-number="5">mnist_4d<span class="op">$</span><span class="kw">size</span>()</a>
<a class="sourceLine" id="cb5-6" data-line-number="6"><span class="co">#&gt; torch.Size([60000, 3, 28, 28])</span></a>
<a class="sourceLine" id="cb5-7" data-line-number="7"></a>
<a class="sourceLine" id="cb5-8" data-line-number="8"><span class="kw">message</span>(<span class="st">&quot;length&quot;</span>)</a>
<a class="sourceLine" id="cb5-9" data-line-number="9"><span class="co">#&gt; length</span></a>
<a class="sourceLine" id="cb5-10" data-line-number="10"><span class="kw">length</span>(mnist_4d)</a>
<a class="sourceLine" id="cb5-11" data-line-number="11"><span class="co">#&gt; [1] 141120000</span></a>
<a class="sourceLine" id="cb5-12" data-line-number="12"></a>
<a class="sourceLine" id="cb5-13" data-line-number="13"></a>
<a class="sourceLine" id="cb5-14" data-line-number="14"><span class="kw">message</span>(<span class="st">&quot;shape, like in numpy&quot;</span>)</a>
<a class="sourceLine" id="cb5-15" data-line-number="15"><span class="co">#&gt; shape, like in numpy</span></a>
<a class="sourceLine" id="cb5-16" data-line-number="16">mnist_4d<span class="op">$</span>shape</a>
<a class="sourceLine" id="cb5-17" data-line-number="17"><span class="co">#&gt; torch.Size([60000, 3, 28, 28])</span></a>
<a class="sourceLine" id="cb5-18" data-line-number="18"></a>
<a class="sourceLine" id="cb5-19" data-line-number="19"><span class="kw">message</span>(<span class="st">&quot;number of elements&quot;</span>)</a>
<a class="sourceLine" id="cb5-20" data-line-number="20"><span class="co">#&gt; number of elements</span></a>
<a class="sourceLine" id="cb5-21" data-line-number="21">mnist_4d<span class="op">$</span><span class="kw">numel</span>()</a>
<a class="sourceLine" id="cb5-22" data-line-number="22"><span class="co">#&gt; [1] 141120000</span></a></code></pre></div>
<p>A 3D tensor:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1">ft3d &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(4L, 3L, 2L)</a>
<a class="sourceLine" id="cb6-2" data-line-number="2">ft3d</a>
<a class="sourceLine" id="cb6-3" data-line-number="3"><span class="co">#&gt; tensor([[[ 0.0000,  4.1943],</span></a>
<a class="sourceLine" id="cb6-4" data-line-number="4"><span class="co">#&gt;          [ 0.0000, -4.1943],</span></a>
<a class="sourceLine" id="cb6-5" data-line-number="5"><span class="co">#&gt;          [ 0.0000,  0.0000]],</span></a>
<a class="sourceLine" id="cb6-6" data-line-number="6"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb6-7" data-line-number="7"><span class="co">#&gt;         [[ 0.0000,  4.5625],</span></a>
<a class="sourceLine" id="cb6-8" data-line-number="8"><span class="co">#&gt;          [ 0.0000,  4.1943],</span></a>
<a class="sourceLine" id="cb6-9" data-line-number="9"><span class="co">#&gt;          [ 0.0000, -4.1943]],</span></a>
<a class="sourceLine" id="cb6-10" data-line-number="10"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb6-11" data-line-number="11"><span class="co">#&gt;         [[ 0.0000,  0.0000],</span></a>
<a class="sourceLine" id="cb6-12" data-line-number="12"><span class="co">#&gt;          [ 0.0000,  4.5625],</span></a>
<a class="sourceLine" id="cb6-13" data-line-number="13"><span class="co">#&gt;          [ 0.0000,  4.1943]],</span></a>
<a class="sourceLine" id="cb6-14" data-line-number="14"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb6-15" data-line-number="15"><span class="co">#&gt;         [[ 0.0000, -4.1943],</span></a>
<a class="sourceLine" id="cb6-16" data-line-number="16"><span class="co">#&gt;          [ 0.0000,  0.0000],</span></a>
<a class="sourceLine" id="cb6-17" data-line-number="17"><span class="co">#&gt;          [ 0.0000,  0.0000]]], dtype=torch.float32)</span></a></code></pre></div>
</div>
<div id="arithmetic-of-tensors" class="section level2">
<h2><span class="header-section-number">3.2</span> Arithmetic of tensors</h2>
<div id="add-tensors" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Add tensors</h3>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="co"># add a scalar to a tensor</span></a>
<a class="sourceLine" id="cb7-2" data-line-number="2"><span class="co"># 3x5 matrix uniformly distributed between 0 and 1</span></a>
<a class="sourceLine" id="cb7-3" data-line-number="3">mat0 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(3L, 5L)<span class="op">$</span><span class="kw">uniform_</span>(0L, 1L)</a>
<a class="sourceLine" id="cb7-4" data-line-number="4">mat0 <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span></a>
<a class="sourceLine" id="cb7-5" data-line-number="5"><span class="co">#&gt; tensor([[0.8559, 0.5031, 0.1826, 0.8290, 0.4212],</span></a>
<a class="sourceLine" id="cb7-6" data-line-number="6"><span class="co">#&gt;         [0.9349, 1.0094, 0.7310, 0.8760, 0.7906],</span></a>
<a class="sourceLine" id="cb7-7" data-line-number="7"><span class="co">#&gt;         [0.5151, 1.0358, 0.3787, 0.8960, 0.4173]], dtype=torch.float32)</span></a></code></pre></div>
<blockquote>
<p>The expression <code>tensor.index(m)</code> is equivalent to <code>tensor[m]</code>.</p>
</blockquote>
<p>Add an element of tensor to a tensor:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="co"># fill a 3x5 matrix with 0.1</span></a>
<a class="sourceLine" id="cb8-2" data-line-number="2">mat1 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(3L, 5L)<span class="op">$</span><span class="kw">uniform_</span>(<span class="fl">0.1</span>, <span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb8-3" data-line-number="3"><span class="co"># a vector with all ones</span></a>
<a class="sourceLine" id="cb8-4" data-line-number="4">mat2 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(5L)<span class="op">$</span><span class="kw">uniform_</span>(<span class="dv">1</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb8-5" data-line-number="5">mat1[<span class="dv">1</span>, <span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>mat2</a>
<a class="sourceLine" id="cb8-6" data-line-number="6"><span class="co">#&gt; tensor([1.1000, 1.1000, 1.1000, 1.1000, 1.1000], dtype=torch.float32)</span></a></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="co"># add two tensors</span></a>
<a class="sourceLine" id="cb9-2" data-line-number="2">mat1 <span class="op">+</span><span class="st"> </span>mat0</a>
<a class="sourceLine" id="cb9-3" data-line-number="3"><span class="co">#&gt; tensor([[0.8559, 0.5031, 0.1826, 0.8290, 0.4212],</span></a>
<a class="sourceLine" id="cb9-4" data-line-number="4"><span class="co">#&gt;         [0.9349, 1.0094, 0.7310, 0.8760, 0.7906],</span></a>
<a class="sourceLine" id="cb9-5" data-line-number="5"><span class="co">#&gt;         [0.5151, 1.0358, 0.3787, 0.8960, 0.4173]], dtype=torch.float32)</span></a></code></pre></div>
<p>Add two tensors using the function <code>add()</code>:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="co"># PyTorch add two tensors</span></a>
<a class="sourceLine" id="cb10-2" data-line-number="2">x =<span class="st"> </span>torch<span class="op">$</span><span class="kw">rand</span>(5L, 4L)</a>
<a class="sourceLine" id="cb10-3" data-line-number="3">y =<span class="st"> </span>torch<span class="op">$</span><span class="kw">rand</span>(5L, 4L)</a>
<a class="sourceLine" id="cb10-4" data-line-number="4"></a>
<a class="sourceLine" id="cb10-5" data-line-number="5"><span class="kw">print</span>(x<span class="op">$</span><span class="kw">add</span>(y))</a>
<a class="sourceLine" id="cb10-6" data-line-number="6"><span class="co">#&gt; tensor([[0.7763, 0.9629, 0.3306, 1.3451],</span></a>
<a class="sourceLine" id="cb10-7" data-line-number="7"><span class="co">#&gt;         [0.3908, 1.4633, 1.5120, 0.4097],</span></a>
<a class="sourceLine" id="cb10-8" data-line-number="8"><span class="co">#&gt;         [0.8677, 0.9853, 0.5796, 1.0712],</span></a>
<a class="sourceLine" id="cb10-9" data-line-number="9"><span class="co">#&gt;         [0.2441, 0.9713, 1.2918, 0.5715],</span></a>
<a class="sourceLine" id="cb10-10" data-line-number="10"><span class="co">#&gt;         [0.7170, 1.0671, 1.3257, 0.7402]])</span></a></code></pre></div>
<p>Add two tensors using the generic <code>+</code>:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="kw">print</span>(x <span class="op">+</span><span class="st"> </span>y)</a>
<a class="sourceLine" id="cb11-2" data-line-number="2"><span class="co">#&gt; tensor([[0.7763, 0.9629, 0.3306, 1.3451],</span></a>
<a class="sourceLine" id="cb11-3" data-line-number="3"><span class="co">#&gt;         [0.3908, 1.4633, 1.5120, 0.4097],</span></a>
<a class="sourceLine" id="cb11-4" data-line-number="4"><span class="co">#&gt;         [0.8677, 0.9853, 0.5796, 1.0712],</span></a>
<a class="sourceLine" id="cb11-5" data-line-number="5"><span class="co">#&gt;         [0.2441, 0.9713, 1.2918, 0.5715],</span></a>
<a class="sourceLine" id="cb11-6" data-line-number="6"><span class="co">#&gt;         [0.7170, 1.0671, 1.3257, 0.7402]])</span></a></code></pre></div>
</div>
<div id="multiply-a-tensor-by-a-scalar" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Multiply a tensor by a scalar</h3>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="co"># Multiply tensor by scalar</span></a>
<a class="sourceLine" id="cb12-2" data-line-number="2">tensor =<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(4L, <span class="dt">dtype=</span>torch<span class="op">$</span>float64)</a>
<a class="sourceLine" id="cb12-3" data-line-number="3">scalar =<span class="st"> </span>np<span class="op">$</span><span class="kw">float64</span>(<span class="fl">4.321</span>)</a>
<a class="sourceLine" id="cb12-4" data-line-number="4"><span class="kw">print</span>(scalar)</a>
<a class="sourceLine" id="cb12-5" data-line-number="5"><span class="co">#&gt; [1] 4.32</span></a>
<a class="sourceLine" id="cb12-6" data-line-number="6"><span class="kw">print</span>(torch<span class="op">$</span><span class="kw">scalar_tensor</span>(scalar))</a>
<a class="sourceLine" id="cb12-7" data-line-number="7"><span class="co">#&gt; tensor(4.3210)</span></a></code></pre></div>
<p>Multiply two tensors using the function <code>mul</code>:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1">(<span class="dt">prod =</span> torch<span class="op">$</span><span class="kw">mul</span>(tensor, torch<span class="op">$</span><span class="kw">scalar_tensor</span>(scalar)))</a>
<a class="sourceLine" id="cb13-2" data-line-number="2"><span class="co">#&gt; tensor([4.3210, 4.3210, 4.3210, 4.3210])</span></a></code></pre></div>
<p>Short version using generics</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1">(<span class="dt">prod =</span> tensor <span class="op">*</span><span class="st"> </span>scalar)</a>
<a class="sourceLine" id="cb14-2" data-line-number="2"><span class="co">#&gt; tensor([4.3210, 4.3210, 4.3210, 4.3210])</span></a></code></pre></div>
</div>
</div>
<div id="numpy-and-pytorch" class="section level2">
<h2><span class="header-section-number">3.3</span> NumPy and PyTorch</h2>
<p><code>numpy</code> has been made available as a module in <code>rTorch</code>. We can call functions from <code>numpy</code> refrerring to it as <code>np$_a_function</code>. Examples:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1"><span class="co"># a 2D numpy array  </span></a>
<a class="sourceLine" id="cb15-2" data-line-number="2">syn0 &lt;-<span class="st"> </span>np<span class="op">$</span>random<span class="op">$</span><span class="kw">rand</span>(3L, 5L)</a>
<a class="sourceLine" id="cb15-3" data-line-number="3"><span class="kw">print</span>(syn0)</a>
<a class="sourceLine" id="cb15-4" data-line-number="4"><span class="co">#&gt;       [,1]  [,2]  [,3]  [,4]  [,5]</span></a>
<a class="sourceLine" id="cb15-5" data-line-number="5"><span class="co">#&gt; [1,] 0.359 0.839 0.734 0.166 0.792</span></a>
<a class="sourceLine" id="cb15-6" data-line-number="6"><span class="co">#&gt; [2,] 0.973 0.178 0.588 0.978 0.323</span></a>
<a class="sourceLine" id="cb15-7" data-line-number="7"><span class="co">#&gt; [3,] 0.413 0.813 0.762 0.572 0.945</span></a></code></pre></div>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1"><span class="co"># numpy arrays of zeros</span></a>
<a class="sourceLine" id="cb16-2" data-line-number="2">syn1 &lt;-<span class="st"> </span>np<span class="op">$</span><span class="kw">zeros</span>(<span class="kw">c</span>(5L, 10L))</a>
<a class="sourceLine" id="cb16-3" data-line-number="3"><span class="kw">print</span>(syn1)</a>
<a class="sourceLine" id="cb16-4" data-line-number="4"><span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]</span></a>
<a class="sourceLine" id="cb16-5" data-line-number="5"><span class="co">#&gt; [1,]    0    0    0    0    0    0    0    0    0     0</span></a>
<a class="sourceLine" id="cb16-6" data-line-number="6"><span class="co">#&gt; [2,]    0    0    0    0    0    0    0    0    0     0</span></a>
<a class="sourceLine" id="cb16-7" data-line-number="7"><span class="co">#&gt; [3,]    0    0    0    0    0    0    0    0    0     0</span></a>
<a class="sourceLine" id="cb16-8" data-line-number="8"><span class="co">#&gt; [4,]    0    0    0    0    0    0    0    0    0     0</span></a>
<a class="sourceLine" id="cb16-9" data-line-number="9"><span class="co">#&gt; [5,]    0    0    0    0    0    0    0    0    0     0</span></a></code></pre></div>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1"><span class="co"># add a scalar to a numpy array</span></a>
<a class="sourceLine" id="cb17-2" data-line-number="2">syn1 =<span class="st"> </span>syn1 <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span></a>
<a class="sourceLine" id="cb17-3" data-line-number="3"><span class="kw">print</span>(syn1)</a>
<a class="sourceLine" id="cb17-4" data-line-number="4"><span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]</span></a>
<a class="sourceLine" id="cb17-5" data-line-number="5"><span class="co">#&gt; [1,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1</span></a>
<a class="sourceLine" id="cb17-6" data-line-number="6"><span class="co">#&gt; [2,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1</span></a>
<a class="sourceLine" id="cb17-7" data-line-number="7"><span class="co">#&gt; [3,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1</span></a>
<a class="sourceLine" id="cb17-8" data-line-number="8"><span class="co">#&gt; [4,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1</span></a>
<a class="sourceLine" id="cb17-9" data-line-number="9"><span class="co">#&gt; [5,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1</span></a></code></pre></div>
<div id="tuples-python-and-vectors-r" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Tuples (Python) and vectors (R)</h3>
<p>In numpy a multidimensional array needs to be defined with a tuple
in R we do it with a vector.</p>
<p>In Python, we use a tuple, <code>(5, 5)</code></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb18-2" data-line-number="2"></a>
<a class="sourceLine" id="cb18-3" data-line-number="3"><span class="bu">print</span>(np.ones((<span class="dv">5</span>, <span class="dv">5</span>)))</a>
<a class="sourceLine" id="cb18-4" data-line-number="4"><span class="co">#&gt; [[1. 1. 1. 1. 1.]</span></a>
<a class="sourceLine" id="cb18-5" data-line-number="5"><span class="co">#&gt;  [1. 1. 1. 1. 1.]</span></a>
<a class="sourceLine" id="cb18-6" data-line-number="6"><span class="co">#&gt;  [1. 1. 1. 1. 1.]</span></a>
<a class="sourceLine" id="cb18-7" data-line-number="7"><span class="co">#&gt;  [1. 1. 1. 1. 1.]</span></a>
<a class="sourceLine" id="cb18-8" data-line-number="8"><span class="co">#&gt;  [1. 1. 1. 1. 1.]]</span></a></code></pre></div>
<p>In R, we use a vector <code>c(5L, 5L)</code>. The <code>L</code> indicates an integer.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1">l1 &lt;-<span class="st"> </span>np<span class="op">$</span><span class="kw">ones</span>(<span class="kw">c</span>(5L, 5L))</a>
<a class="sourceLine" id="cb19-2" data-line-number="2"><span class="kw">print</span>(l1)</a>
<a class="sourceLine" id="cb19-3" data-line-number="3"><span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5]</span></a>
<a class="sourceLine" id="cb19-4" data-line-number="4"><span class="co">#&gt; [1,]    1    1    1    1    1</span></a>
<a class="sourceLine" id="cb19-5" data-line-number="5"><span class="co">#&gt; [2,]    1    1    1    1    1</span></a>
<a class="sourceLine" id="cb19-6" data-line-number="6"><span class="co">#&gt; [3,]    1    1    1    1    1</span></a>
<a class="sourceLine" id="cb19-7" data-line-number="7"><span class="co">#&gt; [4,]    1    1    1    1    1</span></a>
<a class="sourceLine" id="cb19-8" data-line-number="8"><span class="co">#&gt; [5,]    1    1    1    1    1</span></a></code></pre></div>
<p>Vector-matrix multiplication in numpy:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1">np<span class="op">$</span><span class="kw">dot</span>(syn0, syn1)</a>
<a class="sourceLine" id="cb20-2" data-line-number="2"><span class="co">#&gt;       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]</span></a>
<a class="sourceLine" id="cb20-3" data-line-number="3"><span class="co">#&gt; [1,] 0.289 0.289 0.289 0.289 0.289 0.289 0.289 0.289 0.289 0.289</span></a>
<a class="sourceLine" id="cb20-4" data-line-number="4"><span class="co">#&gt; [2,] 0.304 0.304 0.304 0.304 0.304 0.304 0.304 0.304 0.304 0.304</span></a>
<a class="sourceLine" id="cb20-5" data-line-number="5"><span class="co">#&gt; [3,] 0.350 0.350 0.350 0.350 0.350 0.350 0.350 0.350 0.350 0.350</span></a></code></pre></div>
<p>Build a numpy array from three R vectors:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1">X &lt;-<span class="st"> </span>np<span class="op">$</span><span class="kw">array</span>(<span class="kw">rbind</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>), <span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>), <span class="kw">c</span>(<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>)))</a>
<a class="sourceLine" id="cb21-2" data-line-number="2"><span class="kw">print</span>(X)</a>
<a class="sourceLine" id="cb21-3" data-line-number="3"><span class="co">#&gt;      [,1] [,2] [,3]</span></a>
<a class="sourceLine" id="cb21-4" data-line-number="4"><span class="co">#&gt; [1,]    1    2    3</span></a>
<a class="sourceLine" id="cb21-5" data-line-number="5"><span class="co">#&gt; [2,]    4    5    6</span></a>
<a class="sourceLine" id="cb21-6" data-line-number="6"><span class="co">#&gt; [3,]    7    8    9</span></a></code></pre></div>
<p>And transpose the array:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1">np<span class="op">$</span><span class="kw">transpose</span>(X)</a>
<a class="sourceLine" id="cb22-2" data-line-number="2"><span class="co">#&gt;      [,1] [,2] [,3]</span></a>
<a class="sourceLine" id="cb22-3" data-line-number="3"><span class="co">#&gt; [1,]    1    4    7</span></a>
<a class="sourceLine" id="cb22-4" data-line-number="4"><span class="co">#&gt; [2,]    2    5    8</span></a>
<a class="sourceLine" id="cb22-5" data-line-number="5"><span class="co">#&gt; [3,]    3    6    9</span></a></code></pre></div>
</div>
<div id="make-a-numpy-array-a-tensor-with-as_tensor" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Make a numpy array a tensor with <code>as_tensor()</code></h3>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1">a =<span class="st"> </span>np<span class="op">$</span><span class="kw">array</span>(<span class="kw">list</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>))   <span class="co"># a numpy array</span></a>
<a class="sourceLine" id="cb23-2" data-line-number="2">t =<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(a)        <span class="co"># convert it to tensor</span></a>
<a class="sourceLine" id="cb23-3" data-line-number="3"><span class="kw">print</span>(t)</a>
<a class="sourceLine" id="cb23-4" data-line-number="4"><span class="co">#&gt; tensor([1., 2., 3.])</span></a></code></pre></div>
<p>We can create the tensor directly from R using <code>tensor()</code>:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" data-line-number="1">torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>( <span class="dv">1</span>,  <span class="dv">2</span>,  <span class="dv">3</span>))   <span class="co"># create a tensor</span></a>
<a class="sourceLine" id="cb24-2" data-line-number="2"><span class="co">#&gt; tensor([1., 2., 3.])</span></a>
<a class="sourceLine" id="cb24-3" data-line-number="3">t[1L]<span class="op">$</span><span class="kw">fill_</span>(<span class="op">-</span><span class="dv">1</span>)                  <span class="co"># fill element with -1</span></a>
<a class="sourceLine" id="cb24-4" data-line-number="4"><span class="co">#&gt; tensor(-1.)</span></a>
<a class="sourceLine" id="cb24-5" data-line-number="5"><span class="kw">print</span>(a)</a>
<a class="sourceLine" id="cb24-6" data-line-number="6"><span class="co">#&gt; [1] -1  2  3</span></a></code></pre></div>
</div>
<div id="tensor-to-array-and-viceversa" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Tensor to array, and viceversa</h3>
<p>This is a very common operation in machine learning:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1"><span class="co"># convert tensor to a numpy array</span></a>
<a class="sourceLine" id="cb25-2" data-line-number="2">a =<span class="st"> </span>torch<span class="op">$</span><span class="kw">rand</span>(5L, 4L)</a>
<a class="sourceLine" id="cb25-3" data-line-number="3">b =<span class="st"> </span>a<span class="op">$</span><span class="kw">numpy</span>()</a>
<a class="sourceLine" id="cb25-4" data-line-number="4"><span class="kw">print</span>(b)</a>
<a class="sourceLine" id="cb25-5" data-line-number="5"><span class="co">#&gt;       [,1]   [,2]  [,3]   [,4]</span></a>
<a class="sourceLine" id="cb25-6" data-line-number="6"><span class="co">#&gt; [1,] 0.783 0.0854 0.229 0.4130</span></a>
<a class="sourceLine" id="cb25-7" data-line-number="7"><span class="co">#&gt; [2,] 0.584 0.5031 0.265 0.7569</span></a>
<a class="sourceLine" id="cb25-8" data-line-number="8"><span class="co">#&gt; [3,] 0.860 0.7648 0.326 0.4584</span></a>
<a class="sourceLine" id="cb25-9" data-line-number="9"><span class="co">#&gt; [4,] 0.655 0.4866 0.329 0.0065</span></a>
<a class="sourceLine" id="cb25-10" data-line-number="10"><span class="co">#&gt; [5,] 0.597 0.7838 0.581 0.7187</span></a></code></pre></div>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" data-line-number="1"><span class="co"># convert a numpy array to a tensor</span></a>
<a class="sourceLine" id="cb26-2" data-line-number="2">np_a =<span class="st"> </span>np<span class="op">$</span><span class="kw">array</span>(<span class="kw">c</span>(<span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">4</span>), <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">6</span>)))</a>
<a class="sourceLine" id="cb26-3" data-line-number="3">t_a =<span class="st"> </span>torch<span class="op">$</span><span class="kw">from_numpy</span>(np_a)</a>
<a class="sourceLine" id="cb26-4" data-line-number="4"><span class="kw">print</span>(t_a)</a>
<a class="sourceLine" id="cb26-5" data-line-number="5"><span class="co">#&gt; tensor([3., 4., 3., 6.])</span></a></code></pre></div>
</div>
</div>
<div id="create-tensors" class="section level2">
<h2><span class="header-section-number">3.4</span> Create tensors</h2>
<p>A random 1D tensor:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" data-line-number="1">ft1 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(np<span class="op">$</span>random<span class="op">$</span><span class="kw">rand</span>(5L))</a>
<a class="sourceLine" id="cb27-2" data-line-number="2"><span class="kw">print</span>(ft1)</a>
<a class="sourceLine" id="cb27-3" data-line-number="3"><span class="co">#&gt; tensor([0.1971, 0.1743, 0.7566, 0.3904, 0.0470], dtype=torch.float32)</span></a></code></pre></div>
<p>Force a tensor as a float of 64-bits:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" data-line-number="1">ft2 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(np<span class="op">$</span>random<span class="op">$</span><span class="kw">rand</span>(5L), <span class="dt">dtype=</span> torch<span class="op">$</span>float64)</a>
<a class="sourceLine" id="cb28-2" data-line-number="2"><span class="kw">print</span>(ft2)</a>
<a class="sourceLine" id="cb28-3" data-line-number="3"><span class="co">#&gt; tensor([0.6348, 0.5046, 0.0657, 0.7648, 0.2858])</span></a></code></pre></div>
<p>Convert the tensor to float 16-bits:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" data-line-number="1">ft2_dbl &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(ft2, <span class="dt">dtype =</span> torch<span class="op">$</span>float16)</a>
<a class="sourceLine" id="cb29-2" data-line-number="2">ft2_dbl</a>
<a class="sourceLine" id="cb29-3" data-line-number="3"><span class="co">#&gt; tensor([0.6348, 0.5044, 0.0657, 0.7646, 0.2856], dtype=torch.float16)</span></a></code></pre></div>
<p>Create a tensor of size (5 x 7) with uninitialized memory:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" data-line-number="1">a &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(5L, 7L)</a>
<a class="sourceLine" id="cb30-2" data-line-number="2"><span class="kw">print</span>(a)</a>
<a class="sourceLine" id="cb30-3" data-line-number="3"><span class="co">#&gt; tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4013e-45, 0.0000e+00,</span></a>
<a class="sourceLine" id="cb30-4" data-line-number="4"><span class="co">#&gt;          0.0000e+00],</span></a>
<a class="sourceLine" id="cb30-5" data-line-number="5"><span class="co">#&gt;         [0.0000e+00, 0.0000e+00, 4.2039e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00,</span></a>
<a class="sourceLine" id="cb30-6" data-line-number="6"><span class="co">#&gt;          0.0000e+00],</span></a>
<a class="sourceLine" id="cb30-7" data-line-number="7"><span class="co">#&gt;         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,</span></a>
<a class="sourceLine" id="cb30-8" data-line-number="8"><span class="co">#&gt;          3.0737e-12],</span></a>
<a class="sourceLine" id="cb30-9" data-line-number="9"><span class="co">#&gt;         [4.5783e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,</span></a>
<a class="sourceLine" id="cb30-10" data-line-number="10"><span class="co">#&gt;          0.0000e+00],</span></a>
<a class="sourceLine" id="cb30-11" data-line-number="11"><span class="co">#&gt;         [1.1057e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6143e-42, 9.9632e-43,</span></a>
<a class="sourceLine" id="cb30-12" data-line-number="12"><span class="co">#&gt;          2.8617e-25]], dtype=torch.float32)</span></a></code></pre></div>
<p>Using arange to create a tensor. Start from 0:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" data-line-number="1">v =<span class="st"> </span>torch<span class="op">$</span><span class="kw">arange</span>(9L)</a>
<a class="sourceLine" id="cb31-2" data-line-number="2">(<span class="dt">v =</span> v<span class="op">$</span><span class="kw">view</span>(3L, 3L))</a>
<a class="sourceLine" id="cb31-3" data-line-number="3"><span class="co">#&gt; tensor([[0, 1, 2],</span></a>
<a class="sourceLine" id="cb31-4" data-line-number="4"><span class="co">#&gt;         [3, 4, 5],</span></a>
<a class="sourceLine" id="cb31-5" data-line-number="5"><span class="co">#&gt;         [6, 7, 8]])</span></a></code></pre></div>
</div>
<div id="tensor-resizing" class="section level2">
<h2><span class="header-section-number">3.5</span> Tensor resizing</h2>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" data-line-number="1">x =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(2L, 3L)            <span class="co"># Size 2x3</span></a>
<a class="sourceLine" id="cb32-2" data-line-number="2">y =<span class="st"> </span>x<span class="op">$</span><span class="kw">view</span>(6L)                     <span class="co"># Resize x to size 6</span></a>
<a class="sourceLine" id="cb32-3" data-line-number="3">z =<span class="st"> </span>x<span class="op">$</span><span class="kw">view</span>(<span class="op">-</span>1L, 2L)                <span class="co"># Size 3x2</span></a>
<a class="sourceLine" id="cb32-4" data-line-number="4"><span class="kw">print</span>(y)</a>
<a class="sourceLine" id="cb32-5" data-line-number="5"><span class="co">#&gt; tensor([-0.3777, -0.5176,  1.0271, -1.0346,  0.9460, -0.1984])</span></a>
<a class="sourceLine" id="cb32-6" data-line-number="6"><span class="kw">print</span>(z)</a>
<a class="sourceLine" id="cb32-7" data-line-number="7"><span class="co">#&gt; tensor([[-0.3777, -0.5176],</span></a>
<a class="sourceLine" id="cb32-8" data-line-number="8"><span class="co">#&gt;         [ 1.0271, -1.0346],</span></a>
<a class="sourceLine" id="cb32-9" data-line-number="9"><span class="co">#&gt;         [ 0.9460, -0.1984]])</span></a></code></pre></div>
<p>Reproduce this tensor:</p>
<pre><code> 0 1 2
 3 4 5
 6 7 8</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" data-line-number="1">v =<span class="st"> </span>torch<span class="op">$</span><span class="kw">arange</span>(9L)</a>
<a class="sourceLine" id="cb34-2" data-line-number="2">(<span class="dt">v =</span> v<span class="op">$</span><span class="kw">view</span>(3L, 3L))</a>
<a class="sourceLine" id="cb34-3" data-line-number="3"><span class="co">#&gt; tensor([[0, 1, 2],</span></a>
<a class="sourceLine" id="cb34-4" data-line-number="4"><span class="co">#&gt;         [3, 4, 5],</span></a>
<a class="sourceLine" id="cb34-5" data-line-number="5"><span class="co">#&gt;         [6, 7, 8]])</span></a></code></pre></div>
<div id="concatenate-tensors" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Concatenate tensors</h3>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" data-line-number="1">x =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(2L, 3L)</a>
<a class="sourceLine" id="cb35-2" data-line-number="2"><span class="kw">print</span>(x)</a>
<a class="sourceLine" id="cb35-3" data-line-number="3"><span class="co">#&gt; tensor([[-1.2650,  0.9662, -1.0920],</span></a>
<a class="sourceLine" id="cb35-4" data-line-number="4"><span class="co">#&gt;         [-1.0054, -0.4196,  0.6683]])</span></a></code></pre></div>
<p>Concatenate tensors by <code>dim=0</code>:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb36-1" data-line-number="1">torch<span class="op">$</span><span class="kw">cat</span>(<span class="kw">list</span>(x, x, x), 0L)</a>
<a class="sourceLine" id="cb36-2" data-line-number="2"><span class="co">#&gt; tensor([[-1.2650,  0.9662, -1.0920],</span></a>
<a class="sourceLine" id="cb36-3" data-line-number="3"><span class="co">#&gt;         [-1.0054, -0.4196,  0.6683],</span></a>
<a class="sourceLine" id="cb36-4" data-line-number="4"><span class="co">#&gt;         [-1.2650,  0.9662, -1.0920],</span></a>
<a class="sourceLine" id="cb36-5" data-line-number="5"><span class="co">#&gt;         [-1.0054, -0.4196,  0.6683],</span></a>
<a class="sourceLine" id="cb36-6" data-line-number="6"><span class="co">#&gt;         [-1.2650,  0.9662, -1.0920],</span></a>
<a class="sourceLine" id="cb36-7" data-line-number="7"><span class="co">#&gt;         [-1.0054, -0.4196,  0.6683]])</span></a></code></pre></div>
<p>Concatenate tensors by <code>dim=1</code>:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" data-line-number="1">torch<span class="op">$</span><span class="kw">cat</span>(<span class="kw">list</span>(x, x, x), 1L)</a>
<a class="sourceLine" id="cb37-2" data-line-number="2"><span class="co">#&gt; tensor([[-1.2650,  0.9662, -1.0920, -1.2650,  0.9662, -1.0920, -1.2650,  0.9662,</span></a>
<a class="sourceLine" id="cb37-3" data-line-number="3"><span class="co">#&gt;          -1.0920],</span></a>
<a class="sourceLine" id="cb37-4" data-line-number="4"><span class="co">#&gt;         [-1.0054, -0.4196,  0.6683, -1.0054, -0.4196,  0.6683, -1.0054, -0.4196,</span></a>
<a class="sourceLine" id="cb37-5" data-line-number="5"><span class="co">#&gt;           0.6683]])</span></a></code></pre></div>
</div>
</div>
<div id="reshape-tensors" class="section level2">
<h2><span class="header-section-number">3.6</span> Reshape tensors</h2>
<div id="with-function-chunk" class="section level3">
<h3><span class="header-section-number">3.6.1</span> With function <code>chunk()</code>:</h3>
<p>Letâ€™s say this is an image tensor with the 3-channels and 28x28 pixels</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb38-1" data-line-number="1"><span class="co"># ----- Reshape tensors -----</span></a>
<a class="sourceLine" id="cb38-2" data-line-number="2">img &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(3L, 28L, 28L)  <span class="co"># Create the tensor of ones</span></a>
<a class="sourceLine" id="cb38-3" data-line-number="3"><span class="kw">print</span>(img<span class="op">$</span><span class="kw">size</span>())</a>
<a class="sourceLine" id="cb38-4" data-line-number="4"><span class="co">#&gt; torch.Size([3, 28, 28])</span></a></code></pre></div>
<p>On the first dimension <code>dim = 0L</code>, reshape the tensor:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb39-1" data-line-number="1">img_chunks &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">chunk</span>(img, <span class="dt">chunks =</span> 3L, <span class="dt">dim =</span> 0L)</a>
<a class="sourceLine" id="cb39-2" data-line-number="2"><span class="kw">print</span>(<span class="kw">length</span>(img_chunks))</a>
<a class="sourceLine" id="cb39-3" data-line-number="3"><span class="co">#&gt; [1] 3</span></a></code></pre></div>
<p>The first chunk member:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb40-1" data-line-number="1"><span class="co"># 1st chunk member</span></a>
<a class="sourceLine" id="cb40-2" data-line-number="2">img_chunk &lt;-<span class="st"> </span>img_chunks[[<span class="dv">1</span>]]</a>
<a class="sourceLine" id="cb40-3" data-line-number="3"><span class="kw">print</span>(img_chunk<span class="op">$</span><span class="kw">size</span>())</a>
<a class="sourceLine" id="cb40-4" data-line-number="4"><span class="co">#&gt; torch.Size([1, 28, 28])</span></a>
<a class="sourceLine" id="cb40-5" data-line-number="5"><span class="kw">print</span>(img_chunk<span class="op">$</span><span class="kw">sum</span>())      <span class="co"># if the tensor had all ones, what is the sum?</span></a>
<a class="sourceLine" id="cb40-6" data-line-number="6"><span class="co">#&gt; tensor(784.)</span></a></code></pre></div>
<p>The second chunk member:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb41-1" data-line-number="1"><span class="co"># 2nd chunk member</span></a>
<a class="sourceLine" id="cb41-2" data-line-number="2">img_chunk &lt;-<span class="st"> </span>img_chunks[[<span class="dv">2</span>]]</a>
<a class="sourceLine" id="cb41-3" data-line-number="3"><span class="kw">print</span>(img_chunk<span class="op">$</span><span class="kw">size</span>())</a>
<a class="sourceLine" id="cb41-4" data-line-number="4"><span class="co">#&gt; torch.Size([1, 28, 28])</span></a>
<a class="sourceLine" id="cb41-5" data-line-number="5"><span class="kw">print</span>(img_chunk<span class="op">$</span><span class="kw">sum</span>())        <span class="co"># if the tensor had all ones, what is the sum?</span></a>
<a class="sourceLine" id="cb41-6" data-line-number="6"><span class="co">#&gt; tensor(784.)</span></a></code></pre></div>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb42-1" data-line-number="1"><span class="co"># 3rd chunk member</span></a>
<a class="sourceLine" id="cb42-2" data-line-number="2">img_chunk &lt;-<span class="st"> </span>img_chunks[[<span class="dv">3</span>]]</a>
<a class="sourceLine" id="cb42-3" data-line-number="3"><span class="kw">print</span>(img_chunk<span class="op">$</span><span class="kw">size</span>())</a>
<a class="sourceLine" id="cb42-4" data-line-number="4"><span class="co">#&gt; torch.Size([1, 28, 28])</span></a>
<a class="sourceLine" id="cb42-5" data-line-number="5"><span class="kw">print</span>(img_chunk<span class="op">$</span><span class="kw">sum</span>())        <span class="co"># if the tensor had all ones, what is the sum?</span></a>
<a class="sourceLine" id="cb42-6" data-line-number="6"><span class="co">#&gt; tensor(784.)</span></a></code></pre></div>
</div>
<div id="with-index_select" class="section level3">
<h3><span class="header-section-number">3.6.2</span> With <code>index_select()</code>:</h3>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb43-1" data-line-number="1">img &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(3L, 28L, 28L)  <span class="co"># Create the tensor of ones</span></a></code></pre></div>
<p>This is the layer 1:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" data-line-number="1"><span class="co"># index_select. get layer 1</span></a>
<a class="sourceLine" id="cb44-2" data-line-number="2">indices =<span class="st"> </span>torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">c</span>(0L))</a>
<a class="sourceLine" id="cb44-3" data-line-number="3">img_layer &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">index_select</span>(img, <span class="dt">dim =</span> 0L, <span class="dt">index =</span> indices)</a></code></pre></div>
<p>The size of the layer:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" data-line-number="1"><span class="kw">print</span>(img_layer<span class="op">$</span><span class="kw">size</span>())</a>
<a class="sourceLine" id="cb45-2" data-line-number="2"><span class="co">#&gt; torch.Size([1, 28, 28])</span></a></code></pre></div>
<p>The sum of all elements in that layer:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" data-line-number="1"><span class="kw">print</span>(img_layer<span class="op">$</span><span class="kw">sum</span>())</a>
<a class="sourceLine" id="cb46-2" data-line-number="2"><span class="co">#&gt; tensor(784.)</span></a></code></pre></div>
<p>This is the layer 2:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" data-line-number="1"><span class="co"># index_select. get layer 2</span></a>
<a class="sourceLine" id="cb47-2" data-line-number="2">indices =<span class="st"> </span>torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">c</span>(1L))</a>
<a class="sourceLine" id="cb47-3" data-line-number="3">img_layer &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">index_select</span>(img, <span class="dt">dim =</span> 0L, <span class="dt">index =</span> indices)</a>
<a class="sourceLine" id="cb47-4" data-line-number="4"><span class="kw">print</span>(img_layer<span class="op">$</span><span class="kw">size</span>())</a>
<a class="sourceLine" id="cb47-5" data-line-number="5"><span class="co">#&gt; torch.Size([1, 28, 28])</span></a>
<a class="sourceLine" id="cb47-6" data-line-number="6"><span class="kw">print</span>(img_layer<span class="op">$</span><span class="kw">sum</span>())</a>
<a class="sourceLine" id="cb47-7" data-line-number="7"><span class="co">#&gt; tensor(784.)</span></a></code></pre></div>
<p>This is the layer 3:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" data-line-number="1"><span class="co"># index_select. get layer 3</span></a>
<a class="sourceLine" id="cb48-2" data-line-number="2">indices =<span class="st"> </span>torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">c</span>(2L))</a>
<a class="sourceLine" id="cb48-3" data-line-number="3">img_layer &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">index_select</span>(img, <span class="dt">dim =</span> 0L, <span class="dt">index =</span> indices)</a>
<a class="sourceLine" id="cb48-4" data-line-number="4"><span class="kw">print</span>(img_layer<span class="op">$</span><span class="kw">size</span>())</a>
<a class="sourceLine" id="cb48-5" data-line-number="5"><span class="co">#&gt; torch.Size([1, 28, 28])</span></a>
<a class="sourceLine" id="cb48-6" data-line-number="6"><span class="kw">print</span>(img_layer<span class="op">$</span><span class="kw">sum</span>())</a>
<a class="sourceLine" id="cb48-7" data-line-number="7"><span class="co">#&gt; tensor(784.)</span></a></code></pre></div>
</div>
</div>
<div id="special-tensors" class="section level2">
<h2><span class="header-section-number">3.7</span> Special tensors</h2>
<div id="identity-matrix" class="section level3">
<h3><span class="header-section-number">3.7.1</span> Identity matrix</h3>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb49-1" data-line-number="1"><span class="co"># identity matrix</span></a>
<a class="sourceLine" id="cb49-2" data-line-number="2">eye =<span class="st"> </span>torch<span class="op">$</span><span class="kw">eye</span>(3L)              <span class="co"># Create an identity 3x3 tensor</span></a>
<a class="sourceLine" id="cb49-3" data-line-number="3"><span class="kw">print</span>(eye)</a>
<a class="sourceLine" id="cb49-4" data-line-number="4"><span class="co">#&gt; tensor([[1., 0., 0.],</span></a>
<a class="sourceLine" id="cb49-5" data-line-number="5"><span class="co">#&gt;         [0., 1., 0.],</span></a>
<a class="sourceLine" id="cb49-6" data-line-number="6"><span class="co">#&gt;         [0., 0., 1.]])</span></a></code></pre></div>
</div>
<div id="ones" class="section level3">
<h3><span class="header-section-number">3.7.2</span> Ones</h3>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb50-1" data-line-number="1">(<span class="dt">v =</span> torch<span class="op">$</span><span class="kw">ones</span>(10L))              <span class="co"># A tensor of size 10 containing all ones</span></a>
<a class="sourceLine" id="cb50-2" data-line-number="2"><span class="co">#&gt; tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])</span></a>
<a class="sourceLine" id="cb50-3" data-line-number="3">(<span class="dt">v =</span> torch<span class="op">$</span><span class="kw">ones</span>(2L, 1L, 2L, 1L))      <span class="co"># Size 2x1x2x1</span></a>
<a class="sourceLine" id="cb50-4" data-line-number="4"><span class="co">#&gt; tensor([[[[1.],</span></a>
<a class="sourceLine" id="cb50-5" data-line-number="5"><span class="co">#&gt;           [1.]]],</span></a>
<a class="sourceLine" id="cb50-6" data-line-number="6"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb50-7" data-line-number="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb50-8" data-line-number="8"><span class="co">#&gt;         [[[1.],</span></a>
<a class="sourceLine" id="cb50-9" data-line-number="9"><span class="co">#&gt;           [1.]]]])</span></a></code></pre></div>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb51-1" data-line-number="1">v =<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones_like</span>(eye)     <span class="co"># A tensor with same shape as eye. Fill it with 1.</span></a>
<a class="sourceLine" id="cb51-2" data-line-number="2">v</a>
<a class="sourceLine" id="cb51-3" data-line-number="3"><span class="co">#&gt; tensor([[1., 1., 1.],</span></a>
<a class="sourceLine" id="cb51-4" data-line-number="4"><span class="co">#&gt;         [1., 1., 1.],</span></a>
<a class="sourceLine" id="cb51-5" data-line-number="5"><span class="co">#&gt;         [1., 1., 1.]])</span></a></code></pre></div>
</div>
<div id="zeros" class="section level3">
<h3><span class="header-section-number">3.7.3</span> Zeros</h3>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" data-line-number="1">(<span class="dt">z =</span> torch<span class="op">$</span><span class="kw">zeros</span>(10L))             <span class="co"># A tensor of size 10 containing all zeros</span></a>
<a class="sourceLine" id="cb52-2" data-line-number="2"><span class="co">#&gt; tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])</span></a></code></pre></div>
</div>
</div>
<div id="tensor-fill" class="section level2">
<h2><span class="header-section-number">3.8</span> Tensor fill</h2>
<p>On this tensor:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb53-1" data-line-number="1">(<span class="dt">v =</span> torch<span class="op">$</span><span class="kw">ones</span>(3L, 3L))</a>
<a class="sourceLine" id="cb53-2" data-line-number="2"><span class="co">#&gt; tensor([[1., 1., 1.],</span></a>
<a class="sourceLine" id="cb53-3" data-line-number="3"><span class="co">#&gt;         [1., 1., 1.],</span></a>
<a class="sourceLine" id="cb53-4" data-line-number="4"><span class="co">#&gt;         [1., 1., 1.]])</span></a></code></pre></div>
<p>Fill row 1 with 2s:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" data-line-number="1">v[1L, ]<span class="op">$</span><span class="kw">fill_</span>(2L)         </a>
<a class="sourceLine" id="cb54-2" data-line-number="2"><span class="co">#&gt; tensor([2., 2., 2.])</span></a>
<a class="sourceLine" id="cb54-3" data-line-number="3"><span class="kw">print</span>(v)</a>
<a class="sourceLine" id="cb54-4" data-line-number="4"><span class="co">#&gt; tensor([[2., 2., 2.],</span></a>
<a class="sourceLine" id="cb54-5" data-line-number="5"><span class="co">#&gt;         [1., 1., 1.],</span></a>
<a class="sourceLine" id="cb54-6" data-line-number="6"><span class="co">#&gt;         [1., 1., 1.]])</span></a></code></pre></div>
<p>Fill row 2 with 3s:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb55-1" data-line-number="1">v[2L, ]<span class="op">$</span><span class="kw">fill_</span>(3L)       </a>
<a class="sourceLine" id="cb55-2" data-line-number="2"><span class="co">#&gt; tensor([3., 3., 3.])</span></a>
<a class="sourceLine" id="cb55-3" data-line-number="3"><span class="kw">print</span>(v)</a>
<a class="sourceLine" id="cb55-4" data-line-number="4"><span class="co">#&gt; tensor([[2., 2., 2.],</span></a>
<a class="sourceLine" id="cb55-5" data-line-number="5"><span class="co">#&gt;         [3., 3., 3.],</span></a>
<a class="sourceLine" id="cb55-6" data-line-number="6"><span class="co">#&gt;         [1., 1., 1.]])</span></a></code></pre></div>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" data-line-number="1"><span class="co"># Initialize Tensor with a range of value</span></a>
<a class="sourceLine" id="cb56-2" data-line-number="2">v =<span class="st"> </span>torch<span class="op">$</span><span class="kw">arange</span>(10L)             <span class="co"># similar to range(5) but creating a Tensor</span></a>
<a class="sourceLine" id="cb56-3" data-line-number="3">(<span class="dt">v =</span> torch<span class="op">$</span><span class="kw">arange</span>(0L, 10L, <span class="dt">step =</span> 1L))  <span class="co"># Size 5. Similar to range(0, 5, 1)</span></a>
<a class="sourceLine" id="cb56-4" data-line-number="4"><span class="co">#&gt; tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</span></a></code></pre></div>
<div id="initialize-a-linear-or-log-scale-tensor" class="section level3">
<h3><span class="header-section-number">3.8.1</span> Initialize a linear or log scale Tensor</h3>
<p>Create a tensor with 10 linear points for (1, 10) inclusive:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb57-1" data-line-number="1">(<span class="dt">v =</span> torch<span class="op">$</span><span class="kw">linspace</span>(1L, 10L, <span class="dt">steps =</span> 10L)) </a>
<a class="sourceLine" id="cb57-2" data-line-number="2"><span class="co">#&gt; tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])</span></a></code></pre></div>
<p>Create a tensor with 10 logarithmic points for (1, 10) inclusive:</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb58-1" data-line-number="1">(<span class="dt">v =</span> torch<span class="op">$</span><span class="kw">logspace</span>(<span class="dt">start=</span><span class="op">-</span>10L, <span class="dt">end =</span> 10L, <span class="dt">steps =</span> 5L)) </a>
<a class="sourceLine" id="cb58-2" data-line-number="2"><span class="co">#&gt; tensor([1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10])</span></a></code></pre></div>
</div>
<div id="inplace-out-of-place" class="section level3">
<h3><span class="header-section-number">3.8.2</span> Inplace / Out-of-place</h3>
<p>On this tensor:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb59-1" data-line-number="1">(a &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(5L, 7L))</a>
<a class="sourceLine" id="cb59-2" data-line-number="2"><span class="co">#&gt; tensor([[2.4335e-26, 3.0751e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,</span></a>
<a class="sourceLine" id="cb59-3" data-line-number="3"><span class="co">#&gt;          0.0000e+00],</span></a>
<a class="sourceLine" id="cb59-4" data-line-number="4"><span class="co">#&gt;         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4335e-26,</span></a>
<a class="sourceLine" id="cb59-5" data-line-number="5"><span class="co">#&gt;          3.0751e-41],</span></a>
<a class="sourceLine" id="cb59-6" data-line-number="6"><span class="co">#&gt;         [2.4335e-26, 3.0751e-41, 2.4335e-26, 3.0751e-41, 1.4013e-45, 0.0000e+00,</span></a>
<a class="sourceLine" id="cb59-7" data-line-number="7"><span class="co">#&gt;          0.0000e+00],</span></a>
<a class="sourceLine" id="cb59-8" data-line-number="8"><span class="co">#&gt;         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,</span></a>
<a class="sourceLine" id="cb59-9" data-line-number="9"><span class="co">#&gt;          0.0000e+00],</span></a>
<a class="sourceLine" id="cb59-10" data-line-number="10"><span class="co">#&gt;         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6388e-26, 4.5783e-41,</span></a>
<a class="sourceLine" id="cb59-11" data-line-number="11"><span class="co">#&gt;          1.4013e-45]], dtype=torch.float32)</span></a></code></pre></div>
<p>Fill the tensor with the value 3.5:</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb60-1" data-line-number="1">a<span class="op">$</span><span class="kw">fill_</span>(<span class="fl">3.5</span>)</a>
<a class="sourceLine" id="cb60-2" data-line-number="2"><span class="co">#&gt; tensor([[3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],</span></a>
<a class="sourceLine" id="cb60-3" data-line-number="3"><span class="co">#&gt;         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],</span></a>
<a class="sourceLine" id="cb60-4" data-line-number="4"><span class="co">#&gt;         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],</span></a>
<a class="sourceLine" id="cb60-5" data-line-number="5"><span class="co">#&gt;         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],</span></a>
<a class="sourceLine" id="cb60-6" data-line-number="6"><span class="co">#&gt;         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000]],</span></a>
<a class="sourceLine" id="cb60-7" data-line-number="7"><span class="co">#&gt;        dtype=torch.float32)</span></a></code></pre></div>
<p>Add a scalar to the tensor:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb61-1" data-line-number="1">b &lt;-<span class="st"> </span>a<span class="op">$</span><span class="kw">add</span>(<span class="fl">4.0</span>)</a></code></pre></div>
<p>The tensor <code>a</code> is still filled with 3.5.
A new tensor <code>b</code> is returned with values 3.5 + 4.0 = 7.5</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb62-1" data-line-number="1"><span class="kw">print</span>(a)</a>
<a class="sourceLine" id="cb62-2" data-line-number="2"><span class="co">#&gt; tensor([[3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],</span></a>
<a class="sourceLine" id="cb62-3" data-line-number="3"><span class="co">#&gt;         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],</span></a>
<a class="sourceLine" id="cb62-4" data-line-number="4"><span class="co">#&gt;         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],</span></a>
<a class="sourceLine" id="cb62-5" data-line-number="5"><span class="co">#&gt;         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],</span></a>
<a class="sourceLine" id="cb62-6" data-line-number="6"><span class="co">#&gt;         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000]],</span></a>
<a class="sourceLine" id="cb62-7" data-line-number="7"><span class="co">#&gt;        dtype=torch.float32)</span></a>
<a class="sourceLine" id="cb62-8" data-line-number="8"><span class="kw">print</span>(b)</a>
<a class="sourceLine" id="cb62-9" data-line-number="9"><span class="co">#&gt; tensor([[7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000],</span></a>
<a class="sourceLine" id="cb62-10" data-line-number="10"><span class="co">#&gt;         [7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000],</span></a>
<a class="sourceLine" id="cb62-11" data-line-number="11"><span class="co">#&gt;         [7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000],</span></a>
<a class="sourceLine" id="cb62-12" data-line-number="12"><span class="co">#&gt;         [7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000],</span></a>
<a class="sourceLine" id="cb62-13" data-line-number="13"><span class="co">#&gt;         [7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000]],</span></a>
<a class="sourceLine" id="cb62-14" data-line-number="14"><span class="co">#&gt;        dtype=torch.float32)</span></a></code></pre></div>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb63-1" data-line-number="1"><span class="co"># this will throw an error because we don&#39;t still have a function for assignment</span></a>
<a class="sourceLine" id="cb63-2" data-line-number="2">a[<span class="dv">1</span>, <span class="dv">1</span>] &lt;-<span class="st"> </span><span class="fl">7.7</span></a>
<a class="sourceLine" id="cb63-3" data-line-number="3"><span class="kw">print</span>(a)</a>
<a class="sourceLine" id="cb63-4" data-line-number="4"><span class="co"># Error in a[1, 1] &lt;- 7.7 : object of type &#39;environment&#39; is not subsettable</span></a></code></pre></div>
<p>Some operations like<code>narrow</code> do not have in-place versions, and hence, <code>.narrow_</code> does not exist. Similarly, some operations like <code>fill_</code> do not have an out-of-place version, so <code>.fill</code> does not exist.</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb64-1" data-line-number="1"><span class="co"># a[[0L, 3L]]</span></a>
<a class="sourceLine" id="cb64-2" data-line-number="2">a[<span class="dv">1</span>, <span class="dv">4</span>]</a>
<a class="sourceLine" id="cb64-3" data-line-number="3"><span class="co">#&gt; tensor(3.5000, dtype=torch.float32)</span></a></code></pre></div>
</div>
</div>
<div id="access-to-tensor-elements" class="section level2">
<h2><span class="header-section-number">3.9</span> Access to tensor elements</h2>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb65-1" data-line-number="1"><span class="co"># replace an element at position 0, 0</span></a>
<a class="sourceLine" id="cb65-2" data-line-number="2">(<span class="dt">new_tensor =</span> torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">list</span>(<span class="dv">3</span>, <span class="dv">4</span>))))</a>
<a class="sourceLine" id="cb65-3" data-line-number="3"><span class="co">#&gt; tensor([[1., 2.],</span></a>
<a class="sourceLine" id="cb65-4" data-line-number="4"><span class="co">#&gt;         [3., 4.]])</span></a>
<a class="sourceLine" id="cb65-5" data-line-number="5"></a>
<a class="sourceLine" id="cb65-6" data-line-number="6"><span class="kw">print</span>(new_tensor[1L, 1L])</a>
<a class="sourceLine" id="cb65-7" data-line-number="7"><span class="co">#&gt; tensor(1.)</span></a>
<a class="sourceLine" id="cb65-8" data-line-number="8">new_tensor[1L, 1L]<span class="op">$</span><span class="kw">fill_</span>(<span class="dv">5</span>)</a>
<a class="sourceLine" id="cb65-9" data-line-number="9"><span class="co">#&gt; tensor(5.)</span></a>
<a class="sourceLine" id="cb65-10" data-line-number="10"><span class="kw">print</span>(new_tensor)   <span class="co"># tensor([[ 5.,  2.],[ 3.,  4.]])</span></a>
<a class="sourceLine" id="cb65-11" data-line-number="11"><span class="co">#&gt; tensor([[5., 2.],</span></a>
<a class="sourceLine" id="cb65-12" data-line-number="12"><span class="co">#&gt;         [3., 4.]])</span></a></code></pre></div>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb66-1" data-line-number="1"><span class="co"># access an element at position 1, 0</span></a>
<a class="sourceLine" id="cb66-2" data-line-number="2"><span class="kw">print</span>(new_tensor[2L, 1L])           <span class="co"># tensor([ 3.])</span></a>
<a class="sourceLine" id="cb66-3" data-line-number="3"><span class="co">#&gt; tensor(3.)</span></a>
<a class="sourceLine" id="cb66-4" data-line-number="4"><span class="kw">print</span>(new_tensor[2L, 1L]<span class="op">$</span><span class="kw">item</span>())    <span class="co"># 3.</span></a>
<a class="sourceLine" id="cb66-5" data-line-number="5"><span class="co">#&gt; [1] 3</span></a></code></pre></div>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb67-1" data-line-number="1"><span class="co"># Select indices</span></a>
<a class="sourceLine" id="cb67-2" data-line-number="2">x =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(3L, 4L)</a>
<a class="sourceLine" id="cb67-3" data-line-number="3"><span class="kw">print</span>(x)</a>
<a class="sourceLine" id="cb67-4" data-line-number="4"><span class="co">#&gt; tensor([[ 0.3853,  1.0263,  1.3462, -1.7773],</span></a>
<a class="sourceLine" id="cb67-5" data-line-number="5"><span class="co">#&gt;         [ 0.1090, -0.7245, -2.1815, -0.0951],</span></a>
<a class="sourceLine" id="cb67-6" data-line-number="6"><span class="co">#&gt;         [-0.6262,  0.0293, -0.6820, -1.9108]])</span></a>
<a class="sourceLine" id="cb67-7" data-line-number="7"></a>
<a class="sourceLine" id="cb67-8" data-line-number="8"><span class="co"># Select indices, dim=0</span></a>
<a class="sourceLine" id="cb67-9" data-line-number="9">indices =<span class="st"> </span>torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(0L, 2L))</a>
<a class="sourceLine" id="cb67-10" data-line-number="10">torch<span class="op">$</span><span class="kw">index_select</span>(x, 0L, indices)</a>
<a class="sourceLine" id="cb67-11" data-line-number="11"><span class="co">#&gt; tensor([[ 0.3853,  1.0263,  1.3462, -1.7773],</span></a>
<a class="sourceLine" id="cb67-12" data-line-number="12"><span class="co">#&gt;         [-0.6262,  0.0293, -0.6820, -1.9108]])</span></a>
<a class="sourceLine" id="cb67-13" data-line-number="13"></a>
<a class="sourceLine" id="cb67-14" data-line-number="14"><span class="co"># &quot;Select indices, dim=1</span></a>
<a class="sourceLine" id="cb67-15" data-line-number="15">torch<span class="op">$</span><span class="kw">index_select</span>(x, 1L, indices)</a>
<a class="sourceLine" id="cb67-16" data-line-number="16"><span class="co">#&gt; tensor([[ 0.3853,  1.3462],</span></a>
<a class="sourceLine" id="cb67-17" data-line-number="17"><span class="co">#&gt;         [ 0.1090, -2.1815],</span></a>
<a class="sourceLine" id="cb67-18" data-line-number="18"><span class="co">#&gt;         [-0.6262, -0.6820]])</span></a></code></pre></div>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb68-1" data-line-number="1"><span class="co"># Take by indices</span></a>
<a class="sourceLine" id="cb68-2" data-line-number="2">src =<span class="st"> </span>torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">5</span>),</a>
<a class="sourceLine" id="cb68-3" data-line-number="3">                        <span class="kw">list</span>(<span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>)) )</a>
<a class="sourceLine" id="cb68-4" data-line-number="4"><span class="kw">print</span>(src)</a>
<a class="sourceLine" id="cb68-5" data-line-number="5"><span class="co">#&gt; tensor([[4., 3., 5.],</span></a>
<a class="sourceLine" id="cb68-6" data-line-number="6"><span class="co">#&gt;         [6., 7., 8.]])</span></a>
<a class="sourceLine" id="cb68-7" data-line-number="7"><span class="kw">print</span>( torch<span class="op">$</span><span class="kw">take</span>(src, torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(0L, 2L, 5L))) )</a>
<a class="sourceLine" id="cb68-8" data-line-number="8"><span class="co">#&gt; tensor([4., 5., 8.])</span></a></code></pre></div>
</div>
<div id="tensor-operations" class="section level2">
<h2><span class="header-section-number">3.10</span> Tensor operations</h2>
<div id="cross-product" class="section level3">
<h3><span class="header-section-number">3.10.1</span> cross product</h3>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb69-1" data-line-number="1">m1 =<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(3L, 5L)</a>
<a class="sourceLine" id="cb69-2" data-line-number="2">m2 =<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(3L, 5L)</a>
<a class="sourceLine" id="cb69-3" data-line-number="3">v1 =<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(3L)</a>
<a class="sourceLine" id="cb69-4" data-line-number="4"><span class="co"># Cross product</span></a>
<a class="sourceLine" id="cb69-5" data-line-number="5"><span class="co"># Size 3x5</span></a>
<a class="sourceLine" id="cb69-6" data-line-number="6">(<span class="dt">r =</span> torch<span class="op">$</span><span class="kw">cross</span>(m1, m2))</a>
<a class="sourceLine" id="cb69-7" data-line-number="7"><span class="co">#&gt; tensor([[0., 0., 0., 0., 0.],</span></a>
<a class="sourceLine" id="cb69-8" data-line-number="8"><span class="co">#&gt;         [0., 0., 0., 0., 0.],</span></a>
<a class="sourceLine" id="cb69-9" data-line-number="9"><span class="co">#&gt;         [0., 0., 0., 0., 0.]])</span></a></code></pre></div>
</div>
<div id="dot-product" class="section level3">
<h3><span class="header-section-number">3.10.2</span> Dot product</h3>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb70-1" data-line-number="1"><span class="co"># Dot product of 2 tensors</span></a>
<a class="sourceLine" id="cb70-2" data-line-number="2"><span class="co"># Dot product of 2 tensors</span></a>
<a class="sourceLine" id="cb70-3" data-line-number="3"></a>
<a class="sourceLine" id="cb70-4" data-line-number="4">p &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(4L, 2L))</a>
<a class="sourceLine" id="cb70-5" data-line-number="5">q &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(3L, 1L))                   </a>
<a class="sourceLine" id="cb70-6" data-line-number="6"></a>
<a class="sourceLine" id="cb70-7" data-line-number="7">(<span class="dt">r =</span> torch<span class="op">$</span><span class="kw">dot</span>(p, q)) <span class="co"># 14</span></a>
<a class="sourceLine" id="cb70-8" data-line-number="8"><span class="co">#&gt; tensor(14.)</span></a>
<a class="sourceLine" id="cb70-9" data-line-number="9">(r &lt;-<span class="st"> </span>p <span class="op">%.*%</span><span class="st"> </span>q)</a>
<a class="sourceLine" id="cb70-10" data-line-number="10"><span class="co">#&gt; tensor(14.)</span></a></code></pre></div>
</div>
</div>
<div id="logical-operations" class="section level2">
<h2><span class="header-section-number">3.11</span> Logical operations</h2>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" data-line-number="1">m0 =<span class="st"> </span>torch<span class="op">$</span><span class="kw">zeros</span>(3L, 5L)</a>
<a class="sourceLine" id="cb71-2" data-line-number="2">m1 =<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(3L, 5L)</a>
<a class="sourceLine" id="cb71-3" data-line-number="3">m2 =<span class="st"> </span>torch<span class="op">$</span><span class="kw">eye</span>(3L, 5L)</a>
<a class="sourceLine" id="cb71-4" data-line-number="4"></a>
<a class="sourceLine" id="cb71-5" data-line-number="5"><span class="kw">print</span>(m1 <span class="op">==</span><span class="st"> </span>m0)</a>
<a class="sourceLine" id="cb71-6" data-line-number="6"><span class="co">#&gt; tensor([[False, False, False, False, False],</span></a>
<a class="sourceLine" id="cb71-7" data-line-number="7"><span class="co">#&gt;         [False, False, False, False, False],</span></a>
<a class="sourceLine" id="cb71-8" data-line-number="8"><span class="co">#&gt;         [False, False, False, False, False]], dtype=torch.bool)</span></a></code></pre></div>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb72-1" data-line-number="1"><span class="kw">print</span>(m1 <span class="op">!=</span><span class="st"> </span>m1)</a>
<a class="sourceLine" id="cb72-2" data-line-number="2"><span class="co">#&gt; tensor([[False, False, False, False, False],</span></a>
<a class="sourceLine" id="cb72-3" data-line-number="3"><span class="co">#&gt;         [False, False, False, False, False],</span></a>
<a class="sourceLine" id="cb72-4" data-line-number="4"><span class="co">#&gt;         [False, False, False, False, False]], dtype=torch.bool)</span></a></code></pre></div>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb73-1" data-line-number="1"><span class="kw">print</span>(m2 <span class="op">==</span><span class="st"> </span>m2)</a>
<a class="sourceLine" id="cb73-2" data-line-number="2"><span class="co">#&gt; tensor([[True, True, True, True, True],</span></a>
<a class="sourceLine" id="cb73-3" data-line-number="3"><span class="co">#&gt;         [True, True, True, True, True],</span></a>
<a class="sourceLine" id="cb73-4" data-line-number="4"><span class="co">#&gt;         [True, True, True, True, True]], dtype=torch.bool)</span></a></code></pre></div>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb74-1" data-line-number="1"><span class="co"># AND</span></a>
<a class="sourceLine" id="cb74-2" data-line-number="2">m1 <span class="op">&amp;</span><span class="st"> </span>m1</a>
<a class="sourceLine" id="cb74-3" data-line-number="3"><span class="co">#&gt; tensor([[True, True, True, True, True],</span></a>
<a class="sourceLine" id="cb74-4" data-line-number="4"><span class="co">#&gt;         [True, True, True, True, True],</span></a>
<a class="sourceLine" id="cb74-5" data-line-number="5"><span class="co">#&gt;         [True, True, True, True, True]], dtype=torch.bool)</span></a></code></pre></div>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb75-1" data-line-number="1"><span class="co"># OR</span></a>
<a class="sourceLine" id="cb75-2" data-line-number="2">m0 <span class="op">|</span><span class="st"> </span>m2</a>
<a class="sourceLine" id="cb75-3" data-line-number="3"><span class="co">#&gt; tensor([[ True, False, False, False, False],</span></a>
<a class="sourceLine" id="cb75-4" data-line-number="4"><span class="co">#&gt;         [False,  True, False, False, False],</span></a>
<a class="sourceLine" id="cb75-5" data-line-number="5"><span class="co">#&gt;         [False, False,  True, False, False]], dtype=torch.bool)</span></a></code></pre></div>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb76-1" data-line-number="1"><span class="co"># OR</span></a>
<a class="sourceLine" id="cb76-2" data-line-number="2">m1 <span class="op">|</span><span class="st"> </span>m2</a>
<a class="sourceLine" id="cb76-3" data-line-number="3"><span class="co">#&gt; tensor([[True, True, True, True, True],</span></a>
<a class="sourceLine" id="cb76-4" data-line-number="4"><span class="co">#&gt;         [True, True, True, True, True],</span></a>
<a class="sourceLine" id="cb76-5" data-line-number="5"><span class="co">#&gt;         [True, True, True, True, True]], dtype=torch.bool)</span></a></code></pre></div>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb77-1" data-line-number="1"><span class="co"># all_boolean &lt;- function(x) {</span></a>
<a class="sourceLine" id="cb77-2" data-line-number="2"><span class="co">#   # convert tensor of 1s and 0s to a unique boolean</span></a>
<a class="sourceLine" id="cb77-3" data-line-number="3"><span class="co">#   as.logical(torch$all(x)$numpy())</span></a>
<a class="sourceLine" id="cb77-4" data-line-number="4"><span class="co"># }</span></a>
<a class="sourceLine" id="cb77-5" data-line-number="5"></a>
<a class="sourceLine" id="cb77-6" data-line-number="6"><span class="co"># tensor is less than</span></a>
<a class="sourceLine" id="cb77-7" data-line-number="7">A &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(60000L, 1L, 28L, 28L)</a>
<a class="sourceLine" id="cb77-8" data-line-number="8">C &lt;-<span class="st"> </span>A <span class="op">*</span><span class="st"> </span><span class="fl">0.5</span></a>
<a class="sourceLine" id="cb77-9" data-line-number="9"></a>
<a class="sourceLine" id="cb77-10" data-line-number="10"><span class="co"># is C &lt; A</span></a>
<a class="sourceLine" id="cb77-11" data-line-number="11"><span class="kw">all</span>(torch<span class="op">$</span><span class="kw">lt</span>(C, A))</a>
<a class="sourceLine" id="cb77-12" data-line-number="12"><span class="co">#&gt; tensor(1, dtype=torch.uint8)</span></a>
<a class="sourceLine" id="cb77-13" data-line-number="13"><span class="kw">all</span>(C <span class="op">&lt;</span><span class="st"> </span>A)</a>
<a class="sourceLine" id="cb77-14" data-line-number="14"><span class="co">#&gt; tensor(1, dtype=torch.uint8)</span></a>
<a class="sourceLine" id="cb77-15" data-line-number="15"><span class="co"># is A &lt; C</span></a>
<a class="sourceLine" id="cb77-16" data-line-number="16"><span class="kw">all</span>(A <span class="op">&lt;</span><span class="st"> </span>C)</a>
<a class="sourceLine" id="cb77-17" data-line-number="17"><span class="co">#&gt; tensor(0, dtype=torch.uint8)</span></a></code></pre></div>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" data-line-number="1"><span class="co"># tensor is greater than</span></a>
<a class="sourceLine" id="cb78-2" data-line-number="2">A &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(60000L, 1L, 28L, 28L)</a>
<a class="sourceLine" id="cb78-3" data-line-number="3">D &lt;-<span class="st"> </span>A <span class="op">*</span><span class="st"> </span><span class="fl">2.0</span></a>
<a class="sourceLine" id="cb78-4" data-line-number="4"><span class="kw">all</span>(torch<span class="op">$</span><span class="kw">gt</span>(D, A))</a>
<a class="sourceLine" id="cb78-5" data-line-number="5"><span class="co">#&gt; tensor(1, dtype=torch.uint8)</span></a>
<a class="sourceLine" id="cb78-6" data-line-number="6"><span class="kw">all</span>(torch<span class="op">$</span><span class="kw">gt</span>(A, D))</a>
<a class="sourceLine" id="cb78-7" data-line-number="7"><span class="co">#&gt; tensor(0, dtype=torch.uint8)</span></a></code></pre></div>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb79-1" data-line-number="1"><span class="co"># tensor is less than or equal</span></a>
<a class="sourceLine" id="cb79-2" data-line-number="2">A1 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(60000L, 1L, 28L, 28L)</a>
<a class="sourceLine" id="cb79-3" data-line-number="3"><span class="kw">all</span>(torch<span class="op">$</span><span class="kw">le</span>(A1, A1))</a>
<a class="sourceLine" id="cb79-4" data-line-number="4"><span class="co">#&gt; tensor(1, dtype=torch.uint8)</span></a>
<a class="sourceLine" id="cb79-5" data-line-number="5"><span class="kw">all</span>(A1 <span class="op">&lt;=</span><span class="st"> </span>A1)</a>
<a class="sourceLine" id="cb79-6" data-line-number="6"><span class="co">#&gt; tensor(1, dtype=torch.uint8)</span></a>
<a class="sourceLine" id="cb79-7" data-line-number="7"></a>
<a class="sourceLine" id="cb79-8" data-line-number="8"><span class="co"># tensor is greater than or equal</span></a>
<a class="sourceLine" id="cb79-9" data-line-number="9">A0 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">zeros</span>(60000L, 1L, 28L, 28L)</a>
<a class="sourceLine" id="cb79-10" data-line-number="10"><span class="kw">all</span>(torch<span class="op">$</span><span class="kw">ge</span>(A0, A0))</a>
<a class="sourceLine" id="cb79-11" data-line-number="11"><span class="co">#&gt; tensor(1, dtype=torch.uint8)</span></a>
<a class="sourceLine" id="cb79-12" data-line-number="12"><span class="kw">all</span>(A0 <span class="op">&gt;=</span><span class="st"> </span>A0)</a>
<a class="sourceLine" id="cb79-13" data-line-number="13"><span class="co">#&gt; tensor(1, dtype=torch.uint8)</span></a>
<a class="sourceLine" id="cb79-14" data-line-number="14"></a>
<a class="sourceLine" id="cb79-15" data-line-number="15"><span class="kw">all</span>(A1 <span class="op">&gt;=</span><span class="st"> </span>A0)</a>
<a class="sourceLine" id="cb79-16" data-line-number="16"><span class="co">#&gt; tensor(1, dtype=torch.uint8)</span></a>
<a class="sourceLine" id="cb79-17" data-line-number="17"><span class="kw">all</span>(A1 <span class="op">&lt;=</span><span class="st"> </span>A0)</a>
<a class="sourceLine" id="cb79-18" data-line-number="18"><span class="co">#&gt; tensor(0, dtype=torch.uint8)</span></a></code></pre></div>
<div id="logical-not" class="section level3">
<h3><span class="header-section-number">3.11.1</span> Logical NOT</h3>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" data-line-number="1">all_true &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">BoolTensor</span>(<span class="kw">list</span>(<span class="ot">TRUE</span>, <span class="ot">TRUE</span>, <span class="ot">TRUE</span>, <span class="ot">TRUE</span>))</a>
<a class="sourceLine" id="cb80-2" data-line-number="2">all_true</a>
<a class="sourceLine" id="cb80-3" data-line-number="3"><span class="co">#&gt; tensor([True, True, True, True], dtype=torch.bool)</span></a>
<a class="sourceLine" id="cb80-4" data-line-number="4"></a>
<a class="sourceLine" id="cb80-5" data-line-number="5"><span class="co"># logical NOT</span></a>
<a class="sourceLine" id="cb80-6" data-line-number="6">not_all_true &lt;-<span class="st"> </span><span class="op">!</span>all_true</a>
<a class="sourceLine" id="cb80-7" data-line-number="7">not_all_true</a>
<a class="sourceLine" id="cb80-8" data-line-number="8"><span class="co">#&gt; tensor([False, False, False, False], dtype=torch.bool)</span></a></code></pre></div>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb81-1" data-line-number="1">diag &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">eye</span>(5L)</a>
<a class="sourceLine" id="cb81-2" data-line-number="2">diag</a>
<a class="sourceLine" id="cb81-3" data-line-number="3"><span class="co">#&gt; tensor([[1., 0., 0., 0., 0.],</span></a>
<a class="sourceLine" id="cb81-4" data-line-number="4"><span class="co">#&gt;         [0., 1., 0., 0., 0.],</span></a>
<a class="sourceLine" id="cb81-5" data-line-number="5"><span class="co">#&gt;         [0., 0., 1., 0., 0.],</span></a>
<a class="sourceLine" id="cb81-6" data-line-number="6"><span class="co">#&gt;         [0., 0., 0., 1., 0.],</span></a>
<a class="sourceLine" id="cb81-7" data-line-number="7"><span class="co">#&gt;         [0., 0., 0., 0., 1.]])</span></a>
<a class="sourceLine" id="cb81-8" data-line-number="8"></a>
<a class="sourceLine" id="cb81-9" data-line-number="9"><span class="co"># logical NOT</span></a>
<a class="sourceLine" id="cb81-10" data-line-number="10">not_diag &lt;-<span class="st"> </span><span class="op">!</span>diag</a>
<a class="sourceLine" id="cb81-11" data-line-number="11"></a>
<a class="sourceLine" id="cb81-12" data-line-number="12"><span class="co"># convert to integer</span></a>
<a class="sourceLine" id="cb81-13" data-line-number="13">not_diag<span class="op">$</span><span class="kw">to</span>(<span class="dt">dtype=</span>torch<span class="op">$</span>uint8)</a>
<a class="sourceLine" id="cb81-14" data-line-number="14"><span class="co">#&gt; tensor([[0, 1, 1, 1, 1],</span></a>
<a class="sourceLine" id="cb81-15" data-line-number="15"><span class="co">#&gt;         [1, 0, 1, 1, 1],</span></a>
<a class="sourceLine" id="cb81-16" data-line-number="16"><span class="co">#&gt;         [1, 1, 0, 1, 1],</span></a>
<a class="sourceLine" id="cb81-17" data-line-number="17"><span class="co">#&gt;         [1, 1, 1, 0, 1],</span></a>
<a class="sourceLine" id="cb81-18" data-line-number="18"><span class="co">#&gt;         [1, 1, 1, 1, 0]], dtype=torch.uint8)</span></a></code></pre></div>
</div>
</div>
<div id="distributions" class="section level2">
<h2><span class="header-section-number">3.12</span> Distributions</h2>
<p>Initialize a tensor randomized with a normal distribution with mean=0, var=1:</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" data-line-number="1">a  &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(5L, 7L)</a>
<a class="sourceLine" id="cb82-2" data-line-number="2"><span class="kw">print</span>(a)</a>
<a class="sourceLine" id="cb82-3" data-line-number="3"><span class="co">#&gt; tensor([[ 0.3970, -0.0727, -0.6636, -0.2650,  1.0648,  0.2308,  0.8708],</span></a>
<a class="sourceLine" id="cb82-4" data-line-number="4"><span class="co">#&gt;         [-1.0863,  0.7509, -0.9871,  0.3882,  0.3168,  0.1138,  0.3047],</span></a>
<a class="sourceLine" id="cb82-5" data-line-number="5"><span class="co">#&gt;         [-0.1241,  0.4293,  1.3854,  0.5286, -1.0976, -2.1033,  1.4287],</span></a>
<a class="sourceLine" id="cb82-6" data-line-number="6"><span class="co">#&gt;         [ 0.8094, -0.4282, -0.9040, -0.0884,  0.8569, -0.4058, -0.2331],</span></a>
<a class="sourceLine" id="cb82-7" data-line-number="7"><span class="co">#&gt;         [ 0.3012, -0.4967,  0.3690, -2.5040,  0.4126,  1.1259, -2.3249]])</span></a>
<a class="sourceLine" id="cb82-8" data-line-number="8"><span class="kw">print</span>(a<span class="op">$</span><span class="kw">size</span>())</a>
<a class="sourceLine" id="cb82-9" data-line-number="9"><span class="co">#&gt; torch.Size([5, 7])</span></a></code></pre></div>
<div id="uniform-matrix" class="section level3">
<h3><span class="header-section-number">3.12.1</span> Uniform matrix</h3>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb83-1" data-line-number="1"><span class="kw">library</span>(rTorch)</a>
<a class="sourceLine" id="cb83-2" data-line-number="2"></a>
<a class="sourceLine" id="cb83-3" data-line-number="3"><span class="co"># 3x5 matrix uniformly distributed between 0 and 1</span></a>
<a class="sourceLine" id="cb83-4" data-line-number="4">mat0 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(3L, 5L)<span class="op">$</span><span class="kw">uniform_</span>(0L, 1L)</a>
<a class="sourceLine" id="cb83-5" data-line-number="5"></a>
<a class="sourceLine" id="cb83-6" data-line-number="6"><span class="co"># fill a 3x5 matrix with 0.1</span></a>
<a class="sourceLine" id="cb83-7" data-line-number="7">mat1 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(3L, 5L)<span class="op">$</span><span class="kw">uniform_</span>(<span class="fl">0.1</span>, <span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb83-8" data-line-number="8"></a>
<a class="sourceLine" id="cb83-9" data-line-number="9"><span class="co"># a vector with all ones</span></a>
<a class="sourceLine" id="cb83-10" data-line-number="10">mat2 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(5L)<span class="op">$</span><span class="kw">uniform_</span>(<span class="dv">1</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb83-11" data-line-number="11"></a>
<a class="sourceLine" id="cb83-12" data-line-number="12">mat0</a>
<a class="sourceLine" id="cb83-13" data-line-number="13"><span class="co">#&gt; tensor([[0.5594, 0.7595, 0.2015, 0.5077, 0.0408],</span></a>
<a class="sourceLine" id="cb83-14" data-line-number="14"><span class="co">#&gt;         [0.4292, 0.2146, 0.2577, 0.1257, 0.8347],</span></a>
<a class="sourceLine" id="cb83-15" data-line-number="15"><span class="co">#&gt;         [0.7706, 0.2137, 0.3253, 0.0543, 0.3078]], dtype=torch.float32)</span></a>
<a class="sourceLine" id="cb83-16" data-line-number="16">mat1</a>
<a class="sourceLine" id="cb83-17" data-line-number="17"><span class="co">#&gt; tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000],</span></a>
<a class="sourceLine" id="cb83-18" data-line-number="18"><span class="co">#&gt;         [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],</span></a>
<a class="sourceLine" id="cb83-19" data-line-number="19"><span class="co">#&gt;         [0.1000, 0.1000, 0.1000, 0.1000, 0.1000]], dtype=torch.float32)</span></a></code></pre></div>
</div>
<div id="binomial-distribution" class="section level3">
<h3><span class="header-section-number">3.12.2</span> Binomial distribution</h3>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" data-line-number="1">Binomial &lt;-<span class="st"> </span>torch<span class="op">$</span>distributions<span class="op">$</span>binomial<span class="op">$</span>Binomial</a>
<a class="sourceLine" id="cb84-2" data-line-number="2"></a>
<a class="sourceLine" id="cb84-3" data-line-number="3">m =<span class="st"> </span><span class="kw">Binomial</span>(<span class="dv">100</span>, torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="dv">0</span> , <span class="fl">.2</span>, <span class="fl">.8</span>, <span class="dv">1</span>)))</a>
<a class="sourceLine" id="cb84-4" data-line-number="4">(<span class="dt">x =</span> m<span class="op">$</span><span class="kw">sample</span>())</a>
<a class="sourceLine" id="cb84-5" data-line-number="5"><span class="co">#&gt; tensor([  0.,  21.,  76., 100.])</span></a></code></pre></div>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb85-1" data-line-number="1">m =<span class="st"> </span><span class="kw">Binomial</span>(torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="fl">5.</span>), <span class="kw">list</span>(<span class="fl">10.</span>))), </a>
<a class="sourceLine" id="cb85-2" data-line-number="2">             torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="fl">0.5</span>, <span class="fl">0.8</span>)))</a>
<a class="sourceLine" id="cb85-3" data-line-number="3">(<span class="dt">x =</span> m<span class="op">$</span><span class="kw">sample</span>())</a>
<a class="sourceLine" id="cb85-4" data-line-number="4"><span class="co">#&gt; tensor([[5., 4.],</span></a>
<a class="sourceLine" id="cb85-5" data-line-number="5"><span class="co">#&gt;         [8., 7.]])</span></a></code></pre></div>
</div>
<div id="exponential-distribution" class="section level3">
<h3><span class="header-section-number">3.12.3</span> Exponential distribution</h3>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" data-line-number="1">Exponential &lt;-<span class="st"> </span>torch<span class="op">$</span>distributions<span class="op">$</span>exponential<span class="op">$</span>Exponential</a>
<a class="sourceLine" id="cb86-2" data-line-number="2"></a>
<a class="sourceLine" id="cb86-3" data-line-number="3">m =<span class="st"> </span><span class="kw">Exponential</span>(torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="fl">1.0</span>)))</a>
<a class="sourceLine" id="cb86-4" data-line-number="4">m<span class="op">$</span><span class="kw">sample</span>()  <span class="co"># Exponential distributed with rate=1</span></a>
<a class="sourceLine" id="cb86-5" data-line-number="5"><span class="co">#&gt; tensor([4.5677])</span></a></code></pre></div>
</div>
<div id="weibull-distribution" class="section level3">
<h3><span class="header-section-number">3.12.4</span> Weibull distribution</h3>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb87-1" data-line-number="1">Weibull &lt;-<span class="st"> </span>torch<span class="op">$</span>distributions<span class="op">$</span>weibull<span class="op">$</span>Weibull</a>
<a class="sourceLine" id="cb87-2" data-line-number="2"></a>
<a class="sourceLine" id="cb87-3" data-line-number="3">m =<span class="st"> </span><span class="kw">Weibull</span>(torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="fl">1.0</span>)), torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="fl">1.0</span>)))</a>
<a class="sourceLine" id="cb87-4" data-line-number="4">m<span class="op">$</span><span class="kw">sample</span>()  <span class="co"># sample from a Weibull distribution with scale=1, concentration=1</span></a>
<a class="sourceLine" id="cb87-5" data-line-number="5"><span class="co">#&gt; tensor([2.0707])</span></a></code></pre></div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="rtorch-vs-pytorch-whats-different.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="linearalgebra.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["rtorch-book.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
